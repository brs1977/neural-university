{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"02_mnist_kaggle_opt_v.1.ipynb","version":"0.3.2","provenance":[{"file_id":"1eEkK505oGmViUpEerz68CEBkx8bRnib7","timestamp":1550919136658},{"file_id":"1repZ8czDxWDXlqdp4sCbYvMN4xWJYYWn","timestamp":1550823937061}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"QL3xDPPAVm3F","colab_type":"text"},"cell_type":"markdown","source":["###подключить google drive"]},{"metadata":{"id":"tKomYOh7pt79","colab_type":"code","outputId":"1bc86343-149e-4916-e432-41ad04ae6097","executionInfo":{"status":"ok","timestamp":1551243741700,"user_tz":-180,"elapsed":23262,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"metadata":{"id":"cXk2ikNaV3TN","colab_type":"text"},"cell_type":"markdown","source":["###Kaggle API"]},{"metadata":{"id":"swrVb-VWp4P1","colab_type":"code","outputId":"5e3b1de3-c531-45ff-fbdf-74fc31de720e","executionInfo":{"status":"ok","timestamp":1551243763341,"user_tz":-180,"elapsed":8778,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["#from google.colab import files\n","#file = files.upload()\n","\n","\n","!mkdir ~/.kaggle\n","!cp /content/drive/My\\ Drive/kaggle.json ~/.kaggle\n","!ls ~/.kaggle\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["kaggle.json\n"],"name":"stdout"}]},{"metadata":{"id":"Lz_7_JqOqRxu","colab_type":"code","outputId":"02b91ea4-1b6f-46ed-d277-0ac037ca316d","executionInfo":{"status":"ok","timestamp":1551243765564,"user_tz":-180,"elapsed":8021,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["import random\n","import numpy as np\n","import os\n","from keras import backend as K\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, BatchNormalization \n","from tensorflow.keras import utils\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.optimizers import RMSprop\n","from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from google.colab import files\n","import matplotlib.pyplot as plt\n","%matplotlib inline \n","\n","from hyperopt import hp, fmin, tpe, hp, STATUS_OK, Trials, space_eval\n","from hyperopt.mongoexp import MongoTrials\n","\n","from yellowbrick.classifier import ClassificationReport, ClassPredictionError\n","from sklearn.base import BaseEstimator, RegressorMixin, ClassifierMixin\n","from keras.wrappers.scikit_learn import  KerasRegressor, KerasClassifier\n","from sklearn.metrics import classification_report, confusion_matrix\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"777iAO-KVbkl","colab_type":"text"},"cell_type":"markdown","source":["###Загрузим данные с kaggle и сохраним "]},{"metadata":{"id":"L35YXrnsrBI1","colab_type":"code","colab":{}},"cell_type":"code","source":["#!kaggle competitions download -c digit-recognizer\n","#!ls\n","\n","!mv test.csv /content/drive/My\\ Drive/test.csv  \n","!mv train.csv /content/drive/My\\ Drive/train.csv  \n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ld8uTig1uMrF","colab_type":"text"},"cell_type":"markdown","source":["#Загрузка и подготовка данных"]},{"metadata":{"id":"MmDVLp0RqZ2-","colab_type":"code","colab":{}},"cell_type":"code","source":["from numpy.random import seed\n","seed(13)\n","from tensorflow import set_random_seed\n","set_random_seed(666)\n","\n","fn_train = '/content/drive/My Drive/train.csv'\n","fn_test = '/content/drive/My Drive/test.csv'\n","\n","batch_size=256\n","\n","#prepare train, val, test\n","train_dataset = np.loadtxt(fn_train, skiprows=1, delimiter=',')\n","x_train = train_dataset[:, 1:]\n","y_train = train_dataset[:, 0]\n","# Переформатируем данные в 2D, бэкенд TensorFlow\n","x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n","input_shape = (28, 28, 1)\n","x_train /= 255.0\n","y_train = utils.to_categorical(y_train)\n","\n","random_seed = 2\n","X_train, X_val, Y_train, Y_val = train_test_split(x_train, y_train, test_size = 0.1, random_state=random_seed)\n","\n","#для tpu кратно batch_size\n","#X_train = np.resize(X_train,(X_train.shape[0]//batch_size)*batch_size, 28, 28, 1)\n","#Y_train = np.resize(X_train,(X_train.shape[0]//batch_size)*batch_size, 10)\n","\n","test_dataset = np.loadtxt(fn_test, skiprows=1, delimiter=\",\")\n","x_test = test_dataset.reshape(test_dataset.shape[0], 28, 28, 1)\n","x_test = x_test / 255.0\n","\n","#augmentation\n","datagen = ImageDataGenerator(\n","        rotation_range=10,  \n","        zoom_range = 0.10,  \n","        width_shift_range=0.1, \n","        height_shift_range=0.1)\n","\n","aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n","\theight_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n","\thorizontal_flip=True, fill_mode=\"nearest\")\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"aTNC_tvPu9OA","colab_type":"code","outputId":"764de0e1-7d27-4e24-b8a4-106b402d788c","executionInfo":{"status":"ok","timestamp":1550922238319,"user_tz":-180,"elapsed":703,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}},"colab":{"base_uri":"https://localhost:8080/","height":67}},"cell_type":"code","source":["print(x_train.shape)\n","print(y_train.shape)\n","print(x_test.shape)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(42000, 28, 28, 1)\n","(42000, 10)\n","(28000, 28, 28, 1)\n"],"name":"stdout"}]},{"metadata":{"id":"iMRZQ6NPACd6","colab_type":"text"},"cell_type":"markdown","source":["#Вспомогательные функции"]},{"metadata":{"id":"d3HgGyHUZ9hY","colab_type":"code","colab":{}},"cell_type":"code","source":["#параметры оптимизации\n","space = { 'batch_size' : hp.choice('batch_size', [128,256]), \n","          'activation' : hp.choice('activation', ['relu','elu']), \n","          'optimizer' : hp.choice('optimizer', ['nadam', 'rmsprop']), \n","          'drop1' : hp.choice('drop1', [.3,.4,.5]), \n","          'drop2' : hp.choice('drop2', [.3,.4,.5]), \n","          'nb_neurons' : hp.choice('nb_neurons', [128,192,224,256]), \n","        }\n","\n","def callbacks():\n","  сheckpoint = ModelCheckpoint('mnist-cnn.hdf5', \n","                                monitor='val_acc', \n","                                save_best_only=True,\n","                                verbose=0)\n","  learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n","                                              patience=3, \n","                                              verbose=0, \n","                                              factor=0.5, \n","                                              min_lr=0.00001)\n","  earlystop = EarlyStopping(monitor='val_acc', min_delta=0.001, patience=5,verbose=0, mode='auto')\n","  \n","  return [сheckpoint,learning_rate_reduction,earlystop]\n","\n","#модель сети\n","def create_model(params, nb_classes=10, TPU=False):\n","  model = Sequential()\n","  model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation =params['activation'], input_shape = (28,28,1)))\n","  model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation =params['activation']))\n","  model.add(MaxPooling2D(pool_size=(2,2)))\n","  model.add(Dropout(params['drop1']))\n","\n","\n","  model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation =params['activation']))\n","  model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation =params['activation']))\n","  model.add(BatchNormalization())\n","  model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n","  model.add(Dropout(params['drop1']))\n","\n","  model.add(Flatten())\n","  model.add(Dense(params['nb_neurons'], activation = params['activation']))\n","  model.add(Dropout(params['drop2']))\n","  model.add(Dense(nb_classes, activation = \"softmax\"))\n","\n","  if TPU == True:\n","    model = tf.contrib.tpu.keras_to_tpu_model(\n","          model,\n","          strategy=tf.contrib.tpu.TPUDistributionStrategy(\n","              tf.contrib.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n","          )\n","      )\n","\n","  model.compile(loss=\"categorical_crossentropy\", optimizer=params['optimizer'], metrics=[\"accuracy\"])  \n","  \n","  return model\n","\n","#целевая функция минимизации (для поиска гиперпараметров)\n","def objective(params):\n","  model = create_model(params)\n","  \n","\n","  if os.path.isfile('mnist-cnn.hdf5'):\n","    os.remove('mnist-cnn.hdf5')  \n","\n","\n","  #augmentation\n","  datagen = ImageDataGenerator(\n","        rotation_range=10,  \n","        zoom_range = 0.10,  \n","        width_shift_range=0.1, \n","        height_shift_range=0.1)\n","  \n","\n","  model.fit(datagen.flow(X_train, Y_train, batch_size=params['batch_size']),\n","          epochs=10000,  # using early stopping, so no real limit\n","          verbose=1,\n","          validation_data=(X_val, Y_val),\n","          callbacks=callbacks())\n","            \n","  model.load_weights('mnist-cnn.hdf5')\n","\n","            \n","  score = model.evaluate(X_val, Y_val, verbose=0)\n","\n","  validation_acc = score[1]\n","  print(params)\n","  print('validation acc:', validation_acc)\n","  return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}                    \n","\n","\n","#для воспроизводимости, хотя и не работает для GPU\n","# https://keras.io/getting-started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development\n","def setseed(seed=13):\n","  os.environ['PYTHONHASHSEED']=str(0)\n","  \n","  # The below is necessary for starting Numpy generated random numbers\n","  # in a well-defined initial state.\n","\n","  np.random.seed(42)\n","\n","  # The below is necessary for starting core Python generated random numbers\n","  # in a well-defined state.\n","\n","  random.seed(seed)\n","\n","  # Force TensorFlow to use single thread.\n","  # Multiple threads are a potential source of non-reproducible results.\n","  # For further details, see: https://stackoverflow.com/questions/42022950/\n","\n","  session_conf = tf.ConfigProto(intra_op_parallelism_threads=1,\n","                                inter_op_parallelism_threads=1)\n","\n","  from keras import backend as K\n","\n","  # The below tf.set_random_seed() will make random number generation\n","  # in the TensorFlow backend have a well-defined initial state.\n","  # For further details, see:\n","  # https://www.tensorflow.org/api_docs/python/tf/set_random_seed\n","\n","  tf.set_random_seed(seed)\n","\n","  sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n","  K.set_session(sess)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ufW1UIylANIy","colab_type":"text"},"cell_type":"markdown","source":["#Поиск гиперпараметров"]},{"metadata":{"id":"pgBcEchPaiMj","colab_type":"code","outputId":"c2081741-a97e-4e53-ad35-a5a23dd16d79","colab":{"base_uri":"https://localhost:8080/","height":2218}},"cell_type":"code","source":["\n","setseed()\n","trials = Trials()\n","best = fmin(objective, space, algo=tpe.suggest, trials=trials, max_evals=30)\n","\n","print (best)\n","print (trials.best_trial)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/10000\n","4200/4200 [==============================] - 1s 124us/sample - loss: 0.1348 - acc: 0.9574\n","148/148 [==============================] - 16s 111ms/step - loss: 0.9513 - acc: 0.7790 - val_loss: 0.1339 - val_acc: 0.9574\n","Epoch 2/10000\n","4200/4200 [==============================] - 0s 57us/sample - loss: 0.1075 - acc: 0.9698\n","148/148 [==============================] - 13s 86ms/step - loss: 0.2330 - acc: 0.9313 - val_loss: 0.1059 - val_acc: 0.9698\n","Epoch 3/10000\n","4200/4200 [==============================] - 0s 66us/sample - loss: 0.0487 - acc: 0.9840\n","148/148 [==============================] - 13s 88ms/step - loss: 0.1706 - acc: 0.9490 - val_loss: 0.0474 - val_acc: 0.9840\n","Epoch 4/10000\n","4200/4200 [==============================] - 0s 59us/sample - loss: 0.0562 - acc: 0.9810\n","148/148 [==============================] - 13s 89ms/step - loss: 0.1396 - acc: 0.9590 - val_loss: 0.0557 - val_acc: 0.9810\n","Epoch 5/10000\n","4200/4200 [==============================] - 0s 77us/sample - loss: 0.0566 - acc: 0.9836\n","148/148 [==============================] - 14s 93ms/step - loss: 0.1284 - acc: 0.9625 - val_loss: 0.0563 - val_acc: 0.9836\n","Epoch 6/10000\n","4200/4200 [==============================] - 0s 69us/sample - loss: 0.0406 - acc: 0.9855\n","148/148 [==============================] - 13s 91ms/step - loss: 0.1102 - acc: 0.9682 - val_loss: 0.0399 - val_acc: 0.9855\n","Epoch 7/10000\n","4200/4200 [==============================] - 0s 66us/sample - loss: 0.0503 - acc: 0.9845\n","148/148 [==============================] - 13s 89ms/step - loss: 0.0978 - acc: 0.9716 - val_loss: 0.0488 - val_acc: 0.9845\n","Epoch 8/10000\n","4200/4200 [==============================] - 0s 81us/sample - loss: 0.0423 - acc: 0.9862\n","148/148 [==============================] - 14s 92ms/step - loss: 0.0898 - acc: 0.9737 - val_loss: 0.0428 - val_acc: 0.9862\n","Epoch 9/10000\n","4200/4200 [==============================] - 0s 67us/sample - loss: 0.0318 - acc: 0.9919\n","148/148 [==============================] - 13s 90ms/step - loss: 0.0833 - acc: 0.9749 - val_loss: 0.0309 - val_acc: 0.9919\n","Epoch 10/10000\n","4200/4200 [==============================] - 0s 60us/sample - loss: 0.0330 - acc: 0.9893\n","148/148 [==============================] - 13s 90ms/step - loss: 0.0765 - acc: 0.9770 - val_loss: 0.0326 - val_acc: 0.9893\n","Epoch 11/10000\n","4200/4200 [==============================] - 0s 64us/sample - loss: 0.0366 - acc: 0.9898\n","148/148 [==============================] - 13s 89ms/step - loss: 0.0740 - acc: 0.9783 - val_loss: 0.0364 - val_acc: 0.9898\n","Epoch 12/10000\n","4200/4200 [==============================] - 0s 78us/sample - loss: 0.0316 - acc: 0.9890\n","148/148 [==============================] - 14s 93ms/step - loss: 0.0742 - acc: 0.9782 - val_loss: 0.0317 - val_acc: 0.9890\n","Epoch 13/10000\n","4200/4200 [==============================] - 0s 65us/sample - loss: 0.0239 - acc: 0.9926\n","148/148 [==============================] - 13s 89ms/step - loss: 0.0560 - acc: 0.9831 - val_loss: 0.0234 - val_acc: 0.9926\n","Epoch 14/10000\n","4200/4200 [==============================] - 0s 66us/sample - loss: 0.0238 - acc: 0.9919\n","148/148 [==============================] - 13s 89ms/step - loss: 0.0476 - acc: 0.9854 - val_loss: 0.0240 - val_acc: 0.9919\n","{'activation': 'elu', 'batch_size': 256, 'drop1': 0.3, 'drop2': 0.4, 'nb_neurons': 192, 'optimizer': 'nadam'}\n","validation acc: 0.99261904\n","Epoch 1/10000\n","4200/4200 [==============================] - 1s 123us/sample - loss: 1.0851 - acc: 0.9607\n","148/148 [==============================] - 14s 97ms/step - loss: 0.5423 - acc: 0.8248 - val_loss: 1.0834 - val_acc: 0.9607\n","Epoch 2/10000\n","4200/4200 [==============================] - 0s 54us/sample - loss: 0.3542 - acc: 0.9800\n","148/148 [==============================] - 13s 85ms/step - loss: 0.1511 - acc: 0.9534 - val_loss: 0.3533 - val_acc: 0.9800\n","Epoch 3/10000\n","4200/4200 [==============================] - 0s 61us/sample - loss: 0.1101 - acc: 0.9888\n","148/148 [==============================] - 13s 89ms/step - loss: 0.1189 - acc: 0.9639 - val_loss: 0.1089 - val_acc: 0.9888\n","Epoch 4/10000\n","4200/4200 [==============================] - 0s 60us/sample - loss: 0.0469 - acc: 0.9862\n","148/148 [==============================] - 13s 88ms/step - loss: 0.0990 - acc: 0.9704 - val_loss: 0.0460 - val_acc: 0.9862\n","Epoch 5/10000\n","4200/4200 [==============================] - 0s 78us/sample - loss: 0.0322 - acc: 0.9910\n","148/148 [==============================] - 14s 91ms/step - loss: 0.0902 - acc: 0.9726 - val_loss: 0.0316 - val_acc: 0.9910\n","Epoch 6/10000\n","4200/4200 [==============================] - 0s 69us/sample - loss: 0.0475 - acc: 0.9857\n","148/148 [==============================] - 13s 89ms/step - loss: 0.0816 - acc: 0.9748 - val_loss: 0.0464 - val_acc: 0.9857\n","Epoch 7/10000\n","4200/4200 [==============================] - 0s 68us/sample - loss: 0.0336 - acc: 0.9895\n","148/148 [==============================] - 13s 90ms/step - loss: 0.0807 - acc: 0.9761 - val_loss: 0.0334 - val_acc: 0.9895\n","Epoch 8/10000\n","4200/4200 [==============================] - 0s 79us/sample - loss: 0.0345 - acc: 0.9902\n","148/148 [==============================] - 14s 93ms/step - loss: 0.0746 - acc: 0.9778 - val_loss: 0.0349 - val_acc: 0.9902\n","Epoch 9/10000\n","4200/4200 [==============================] - 0s 66us/sample - loss: 0.0221 - acc: 0.9933\n","148/148 [==============================] - 13s 88ms/step - loss: 0.0598 - acc: 0.9809 - val_loss: 0.0217 - val_acc: 0.9933\n","Epoch 10/10000\n","4200/4200 [==============================] - 0s 62us/sample - loss: 0.0235 - acc: 0.9929\n","148/148 [==============================] - 13s 89ms/step - loss: 0.0535 - acc: 0.9841 - val_loss: 0.0236 - val_acc: 0.9929\n","Epoch 11/10000\n","4200/4200 [==============================] - 0s 58us/sample - loss: 0.0228 - acc: 0.9910\n","148/148 [==============================] - 13s 89ms/step - loss: 0.0534 - acc: 0.9840 - val_loss: 0.0226 - val_acc: 0.9910\n","Epoch 12/10000\n","4200/4200 [==============================] - 0s 76us/sample - loss: 0.0206 - acc: 0.9926\n","148/148 [==============================] - 14s 92ms/step - loss: 0.0493 - acc: 0.9850 - val_loss: 0.0201 - val_acc: 0.9926\n","Epoch 13/10000\n","4200/4200 [==============================] - 0s 65us/sample - loss: 0.0223 - acc: 0.9936\n","148/148 [==============================] - 13s 90ms/step - loss: 0.0443 - acc: 0.9863 - val_loss: 0.0218 - val_acc: 0.9936\n","Epoch 14/10000\n","4200/4200 [==============================] - 0s 60us/sample - loss: 0.0214 - acc: 0.9936\n","148/148 [==============================] - 13s 87ms/step - loss: 0.0449 - acc: 0.9863 - val_loss: 0.0208 - val_acc: 0.9936\n","{'activation': 'relu', 'batch_size': 256, 'drop1': 0.5, 'drop2': 0.3, 'nb_neurons': 192, 'optimizer': 'nadam'}\n","validation acc: 0.9935714\n","Epoch 1/10000\n","4200/4200 [==============================] - 1s 133us/sample - loss: 0.6879 - acc: 0.9774\n","296/296 [==============================] - 15s 52ms/step - loss: 0.4669 - acc: 0.8513 - val_loss: 0.6876 - val_acc: 0.9774\n","Epoch 2/10000\n","4200/4200 [==============================] - 0s 82us/sample - loss: 0.0636 - acc: 0.9833\n","296/296 [==============================] - 14s 47ms/step - loss: 0.1498 - acc: 0.9553 - val_loss: 0.0634 - val_acc: 0.9833\n","Epoch 3/10000\n","4200/4200 [==============================] - 0s 81us/sample - loss: 0.0521 - acc: 0.9874\n","296/296 [==============================] - 14s 48ms/step - loss: 0.1176 - acc: 0.9666 - val_loss: 0.0522 - val_acc: 0.9874\n","Epoch 4/10000\n","4200/4200 [==============================] - 0s 95us/sample - loss: 0.0690 - acc: 0.9802\n","296/296 [==============================] - 14s 48ms/step - loss: 0.1055 - acc: 0.9701 - val_loss: 0.0687 - val_acc: 0.9802\n","Epoch 5/10000\n","4200/4200 [==============================] - 0s 85us/sample - loss: 0.0448 - acc: 0.9886\n","296/296 [==============================] - 14s 48ms/step - loss: 0.1011 - acc: 0.9734 - val_loss: 0.0446 - val_acc: 0.9886\n","Epoch 6/10000\n","4200/4200 [==============================] - 0s 87us/sample - loss: 0.0421 - acc: 0.9910\n","296/296 [==============================] - 14s 48ms/step - loss: 0.0932 - acc: 0.9751 - val_loss: 0.0419 - val_acc: 0.9910\n","Epoch 7/10000\n","4200/4200 [==============================] - 0s 83us/sample - loss: 0.0870 - acc: 0.9829\n","296/296 [==============================] - 14s 47ms/step - loss: 0.0949 - acc: 0.9745 - val_loss: 0.0865 - val_acc: 0.9829\n","Epoch 8/10000\n","4200/4200 [==============================] - 0s 95us/sample - loss: 0.0465 - acc: 0.9917\n","296/296 [==============================] - 15s 50ms/step - loss: 0.0898 - acc: 0.9755 - val_loss: 0.0462 - val_acc: 0.9917\n","Epoch 9/10000\n","4200/4200 [==============================] - 0s 83us/sample - loss: 0.0475 - acc: 0.9871\n","296/296 [==============================] - 14s 48ms/step - loss: 0.0941 - acc: 0.9766 - val_loss: 0.0475 - val_acc: 0.9871\n","Epoch 10/10000\n","4200/4200 [==============================] - 0s 83us/sample - loss: 0.0503 - acc: 0.9910\n","296/296 [==============================] - 14s 48ms/step - loss: 0.0979 - acc: 0.9760 - val_loss: 0.0501 - val_acc: 0.9910\n","Epoch 11/10000\n","4200/4200 [==============================] - 0s 97us/sample - loss: 0.0478 - acc: 0.9895\n","296/296 [==============================] - 15s 51ms/step - loss: 0.0904 - acc: 0.9775 - val_loss: 0.0476 - val_acc: 0.9895\n","{'activation': 'relu', 'batch_size': 128, 'drop1': 0.3, 'drop2': 0.5, 'nb_neurons': 192, 'optimizer': 'rmsprop'}\n","validation acc: 0.9916667\n","Epoch 1/10000\n","4200/4200 [==============================] - 0s 116us/sample - loss: 0.1515 - acc: 0.9517\n","148/148 [==============================] - 14s 97ms/step - loss: 1.1529 - acc: 0.7601 - val_loss: 0.1507 - val_acc: 0.9517\n","Epoch 2/10000\n","4200/4200 [==============================] - 0s 64us/sample - loss: 0.1222 - acc: 0.9626\n","148/148 [==============================] - 12s 83ms/step - loss: 0.2535 - acc: 0.9252 - val_loss: 0.1207 - val_acc: 0.9626\n","Epoch 3/10000\n","135/148 [==========================>...] - ETA: 1s - loss: 0.1877 - acc: 0.9431"],"name":"stdout"}]},{"metadata":{"id":"NVaKTK64AZMY","colab_type":"text"},"cell_type":"markdown","source":["#Сохранение оптимальной модели"]},{"metadata":{"id":"oPjdBocfnlo7","colab_type":"code","colab":{}},"cell_type":"code","source":["fn_best_model = '/content/drive/My Drive/best-mnist-cnn.hdf5'\n","\n","trials.best_trial['result']['model'].save_weights(fn_best_model)\n","\n","model = create_model(space_eval(space, best))\n","model.load_weights(fn_best_model)\n","score = model.evaluate(X_val, Y_val, verbose=0)\n","\n","validation_acc = score[1]\n","print('validation acc:', validation_acc)\n","\n","#trials.best_trial\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fRFRCLNhAor6","colab_type":"text"},"cell_type":"markdown","source":["#Визуализация ошибки распознавания по классам"]},{"metadata":{"id":"uJIpxmMiqI4h","colab_type":"code","colab":{}},"cell_type":"code","source":["def keras_model():\n","  model = create_model(params)\n","  return model\n","\n","\n","class KerasClf(BaseEstimator, ClassifierMixin, KerasClassifier):\n","    def __init__(self, build_fn, **kwargs):\n","        super(KerasClassifier, self).__init__(build_fn,  **kwargs)\n","        \n","    def load_model(self, fn_model, classes):          \n","      self.classes_ = np.array(classes)\n","      self.n_classes_ = len(self.classes_)      \n","      \n","      self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n","      self.model.load_weights(fn_model)\n","      \n","      \n","    def fit(self, x, y, sample_weight=None, **kwargs):    \n","      y = np.array(y)\n","      if len(y.shape) == 2 and y.shape[1] > 1:\n","          self.classes_ = np.arange(y.shape[1])\n","      elif (len(y.shape) == 2 and y.shape[1] == 1) or len(y.shape) == 1:\n","          self.classes_ = np.unique(y)\n","          y = np.searchsorted(self.classes_, y)\n","      else:\n","          raise ValueError('Invalid shape for y: ' + str(y.shape))\n","      self.n_classes_ = len(self.classes_)      \n","      \n","      self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n","      \n","      loss_name = self.model.loss\n","      if hasattr(loss_name, '__name__'):\n","        loss_name = loss_name.__name__\n","      if loss_name == 'categorical_crossentropy' and len(y.shape) != 2:\n","        y = to_categorical(y)\n","\n","      \n","      datagen = ImageDataGenerator(\n","        rotation_range=10,  \n","        zoom_range = 0.10,  \n","        width_shift_range=0.1, \n","        height_shift_range=0.1)\n","      \n","      history = self.model.fit(datagen.flow(x, y, batch_size=params['batch_size']),      \n","          epochs=100,  # using early stopping, so no real limit\n","          verbose=1,\n","          validation_data=(X_val, Y_val),\n","          callbacks=callbacks())\n","      self.model.load_weights('mnist-cnn02.hdf5')\n","      \n","      return history\n","            "],"execution_count":0,"outputs":[]},{"metadata":{"id":"k_wE6dERp0OM","colab_type":"code","colab":{}},"cell_type":"code","source":["#параметры модели выбранные оптимизацией\n","params = {'activation': 'relu', 'batch_size': 256, 'drop1': 0.5, 'drop2': 0.4, 'nb_neurons': 128, 'optimizer': 'nadam'}\n","      \n","      \n","def tf_model():\n","  model = create_model(params)\n","  return model\n","\n","classes=[0,1,2,3,4,5,6,7,8,9]\n","kf = KerasClf(tf_model)\n","visualizer = ClassPredictionError(kf)\n","#visualizer = ClassificationReport(kf, classes=[0,1,2,3,4,5,6,7,8,9])\n","\n","#setseed()\n","#np.random()\n","#history = visualizer.fit(X_train, Y_train)\n","fn_best_model = '/content/drive/My Drive/best-mnist-cnn.hdf5'\n","visualizer.load_model(fn_model=fn_best_model, classes= classes)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2k4bVuL0ZKpM","colab_type":"code","outputId":"d615b0aa-525e-493f-8e76-8c630b517f9b","executionInfo":{"status":"ok","timestamp":1551248234773,"user_tz":-180,"elapsed":8815,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}},"colab":{"base_uri":"https://localhost:8080/","height":401}},"cell_type":"code","source":["#visualizer.score(X_val, np.argmax(Y_val,axis=1))  # Evaluate the model on the test data\n","#g = visualizer.poof()\n","\n","visualizer.score(np.append(X_train,X_val,axis=0), np.argmax(np.append(Y_train,Y_val,axis=0),axis=1))  # Evaluate the model on the test data\n","g = visualizer.poof()\n"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAdoAAAGACAYAAAAK8aM+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRCSi/w8wrMinxSEaUQAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 576x396 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"jzu7uatuyACQ","colab_type":"text"},"cell_type":"markdown","source":["#Матрица ошибок\n"]},{"metadata":{"id":"31hrwyzBrk9S","colab_type":"code","outputId":"b9dd6a38-b17d-43dd-b81d-b5df300b7f88","executionInfo":{"status":"ok","timestamp":1551248289046,"user_tz":-180,"elapsed":4377,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}},"colab":{"base_uri":"https://localhost:8080/","height":476}},"cell_type":"code","source":["y_true = np.argmax(np.append(Y_train,Y_val,axis=0), axis=1)\n","predicted_classes = visualizer.estimator.model.predict_classes(np.append(X_train,X_val,axis=0))\n","\n","from sklearn.metrics import classification_report, confusion_matrix\n","target_names = [\"Class {}\".format(i) for i in range(10)]\n","print(classification_report(y_true, predicted_classes, target_names=target_names))\n","print(confusion_matrix(y_true=y_true, y_pred=predicted_classes, labels=visualizer.classes_))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     Class 0       1.00      1.00      1.00      4132\n","     Class 1       1.00      1.00      1.00      4684\n","     Class 2       1.00      1.00      1.00      4177\n","     Class 3       1.00      1.00      1.00      4351\n","     Class 4       1.00      1.00      1.00      4072\n","     Class 5       1.00      1.00      1.00      3795\n","     Class 6       1.00      1.00      1.00      4137\n","     Class 7       1.00      1.00      1.00      4401\n","     Class 8       1.00      1.00      1.00      4063\n","     Class 9       1.00      0.99      0.99      4188\n","\n","   micro avg       1.00      1.00      1.00     42000\n","   macro avg       1.00      1.00      1.00     42000\n","weighted avg       1.00      1.00      1.00     42000\n","\n","[[4131    0    0    0    0    0    1    0    0    0]\n"," [   0 4669    1    1    1    0    1    9    2    0]\n"," [   0    1 4171    0    0    0    0    3    2    0]\n"," [   0    0    2 4339    0    5    0    1    3    1]\n"," [   0    2    0    0 4056    0    2    1    0   11]\n"," [   1    0    0    2    0 3783    6    0    3    0]\n"," [   1    1    0    0    1    1 4132    0    1    0]\n"," [   0    5    4    0    0    0    0 4390    0    2]\n"," [   1    0    2    2    0    1    2    1 4049    5]\n"," [   1    0    1    1   13    1    0    5    3 4163]]\n"],"name":"stdout"}]},{"metadata":{"id":"OEiLuKUTmqpJ","colab_type":"code","outputId":"87c9af4a-a880-4e05-c1d1-9727846363ce","executionInfo":{"status":"ok","timestamp":1551254496938,"user_tz":-180,"elapsed":1305,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["predicted_classes"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([8, 7, 9, ..., 2, 2, 6])"]},"metadata":{"tags":[]},"execution_count":129}]},{"metadata":{"id":"WSgvg0FG_yH0","colab_type":"text"},"cell_type":"markdown","source":["#Ошибки по классам"]},{"metadata":{"id":"tZc5OuSKrlAY","colab_type":"code","outputId":"e1c3b1a9-d257-4ec6-d841-1ea895e41aae","executionInfo":{"status":"ok","timestamp":1551248322954,"user_tz":-180,"elapsed":1707,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}},"colab":{"base_uri":"https://localhost:8080/","height":374}},"cell_type":"code","source":["correct = np.nonzero(predicted_classes==y_true)[0]\n","incorrect = np.nonzero(predicted_classes!=y_true)[0]\n","true_cl = y_true[incorrect]\n","false_cl = predicted_classes[incorrect]\n","#print(true_cl)\n","#print(false_cl)\n","#\n","for cl in visualizer.classes_:\n","  print('expected:',cl,' predicted:',false_cl[np.where(true_cl==cl)])\n","  \n","print()\n","\n","for cl in visualizer.classes_:\n","  print('predicted:',cl,' expected:',true_cl[np.where(false_cl==cl)])\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["expected: 0  predicted: [6]\n","expected: 1  predicted: [7 7 7 7 6 4 7 7 7 2 7 8 7 3 8]\n","expected: 2  predicted: [8 7 7 1 8 7]\n","expected: 3  predicted: [5 2 7 5 5 8 5 9 2 5 8 8]\n","expected: 4  predicted: [9 6 1 9 9 9 9 9 9 9 1 7 9 9 9 6]\n","expected: 5  predicted: [8 8 3 6 6 0 6 6 8 6 3 6]\n","expected: 6  predicted: [8 5 4 0 1]\n","expected: 7  predicted: [1 1 2 9 2 2 1 9 1 2 1]\n","expected: 8  predicted: [6 2 9 9 3 2 3 7 9 0 6 5 9 9]\n","expected: 9  predicted: [4 7 3 4 4 7 4 5 4 4 4 8 4 4 4 2 8 4 7 0 7 8 7 4 4]\n","\n","predicted: 0  expected: [6 8 5 9]\n","predicted: 1  expected: [7 4 7 7 4 2 7 7 6]\n","predicted: 2  expected: [8 7 7 7 3 8 9 1 7 3]\n","predicted: 3  expected: [9 5 8 8 1 5]\n","predicted: 4  expected: [9 9 9 9 9 6 9 9 1 9 9 9 9 9 9]\n","predicted: 5  expected: [3 9 6 3 3 3 8 3]\n","predicted: 6  expected: [8 4 5 1 5 5 8 0 5 5 5 4]\n","predicted: 7  expected: [1 9 1 1 9 3 2 8 1 4 2 1 1 1 2 1 9 1 9 9]\n","predicted: 8  expected: [6 5 5 2 3 9 2 9 1 5 9 1 3 3]\n","predicted: 9  expected: [4 4 4 4 4 7 4 4 8 8 4 8 7 4 3 8 8 4 4]\n"],"name":"stdout"}]},{"metadata":{"id":"0XeUa9GdA5_R","colab_type":"text"},"cell_type":"markdown","source":["\n","###класс 1 неправильно классифицируется с классом 7\n","###неправильно распознаются между собой классы 4 и 9 \n"]},{"metadata":{"id":"Q00ysX0SsF5L","colab_type":"text"},"cell_type":"markdown","source":["#Классифицируем тестовые данные"]},{"metadata":{"id":"LrqN1geik-SI","colab_type":"code","colab":{}},"cell_type":"code","source":["'''\n","model = create_model(params)\n","history = model.fit(datagen.flow(X_train, Y_train, batch_size=params['batch_size']),      \n","    epochs=100,  # using early stopping, so no real limit\n","    verbose=1,\n","    validation_data=(X_val, Y_val),\n","    callbacks=callbacks())\n","\n","model.load_weights('mnist-cnn02.hdf5')  \n","model.evaluate(X_val, Y_val)\n","predictions = model.predict_classes(x_test)\n","'''\n","\n","predictions = visualizer.estimator.model.predict_classes(x_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KCA-Reg_r9eI","colab_type":"code","outputId":"81dd91e1-8a58-4d0c-f8d2-7fb94bb20553","executionInfo":{"status":"ok","timestamp":1551254558336,"user_tz":-180,"elapsed":1364,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["predictions[0:10]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([2, 0, 9, 0, 3, 7, 0, 3, 0, 3])"]},"metadata":{"tags":[]},"execution_count":131}]},{"metadata":{"id":"d77mhepykw1m","colab_type":"code","colab":{}},"cell_type":"code","source":["#ф вырезает из тренировочных данных 2 класса, тренирует на них модель и предсказывает эти классы на тестовых данных\n","#return (индексы предсказанных классов, класс) для тестовой выборки\n","def fit_predict(ix_train,ix_val,cond_args,nb_classes= 2, params=params, len_seed = 10):\n","  print(params)\n","  from shutil import copyfile\n","    \n","  #вырезаем данные по данным классам\n","  x = X_train[ix_train]\n","  y = np.argmax(Y_train[ix_train],axis=1)\n","  \n","  #преобразуем в категориальные данные вектор правильных ответов\n","  conditions = [y == cond_args[0], y == cond_args[1]]\n","  choices = [0,1]\n","  y = utils.to_categorical(np.select(conditions, choices))\n","  \n","  #тоже самое для валидационной выборки\n","  xv = X_val[ix_val]\n","  yv = np.argmax(Y_val[ix_val],axis=1)\n","\n","  conditions = [yv == cond_args[0], yv == cond_args[1]]\n","  yv = utils.to_categorical(np.select(conditions, choices))\n","  \n","  #подбор seed\n","  setseed()\n","  seeds = np.random.randint(0,100000000,len_seed)\n","  max_acc = 0\n","  train_acc = 0\n","  #тренируем модель делаем предсказание  \n","  for i in range(len(seeds)):\n","    model = create_model(params, nb_classes= nb_classes)\n","    setseed(seeds[i])\n","    history = model.fit(datagen.flow(x, y, batch_size=params['batch_size']),      \n","        epochs=100,  # using early stopping, so no real limit\n","        verbose=1,\n","        validation_data=(xv, yv),\n","        callbacks=callbacks())\n","    #сохраним лучшую модель\n","    mx = np.argmax(history.history['val_acc'])\n","    if (history.history['val_acc'][mx] >= max_acc) & (history.history['acc'][mx] > train_acc):\n","      max_acc = history.history['val_acc'][mx]\n","      train_acc = history.history['acc'][mx]\n","      print('max accuracy:',max_acc)\n","      copyfile('mnist-cnn.hdf5', 'bs_mnist-cnn.hdf5')\n","  \n","  model = create_model(params, nb_classes= nb_classes)\n","  model.load_weights('bs_mnist-cnn.hdf5')  \n","  \n","  ix_pred = np.where(np.isin(predictions, cond_args))\n","  return (ix_pred,model.predict_classes(x_test[ix_pred]))\n","\n"," "],"execution_count":0,"outputs":[]},{"metadata":{"id":"pjVbpo0fo_bY","colab_type":"text"},"cell_type":"markdown","source":["###индексы неправильно распознанных классов обучающей выборки"]},{"metadata":{"id":"HCvgwL3aou2U","colab_type":"code","colab":{}},"cell_type":"code","source":["ix17_train = np.where(np.isin(np.argmax(Y_train,axis=1), [1,7]))\n","ix17_val = np.where(np.isin(np.argmax(Y_val,axis=1), [1,7]))\n","\n","ix49_train = np.where(np.isin(np.argmax(Y_train,axis=1), [4,9]))\n","ix49_val = np.where(np.isin(np.argmax(Y_val,axis=1), [4,9]))\n","\n","print(np.argmax(Y_train,axis=1)[ix49_train])\n","print(np.argmax(Y_val,axis=1)[ix49_val])\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YTAEz_3upOzK","colab_type":"text"},"cell_type":"markdown","source":["#Строим модели на основе неправильно классифицированных данных"]},{"metadata":{"id":"ZgIZsTBJ7Kwj","colab_type":"text"},"cell_type":"markdown","source":["##Предсказываем класс 1 на тренировочных данных класса 1 и 7"]},{"metadata":{"id":"Aqm2BWWVVb_D","colab_type":"code","outputId":"4288bb14-0afb-4c6a-cfbc-254755520a55","executionInfo":{"status":"ok","timestamp":1551262813372,"user_tz":-180,"elapsed":1047816,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}},"colab":{"base_uri":"https://localhost:8080/","height":5593}},"cell_type":"code","source":["\n","ix, pred = fit_predict(ix17_train,ix17_val,[1,7])\n","\n","conditions = [pred == 0, pred == 1]\n","pred17 = np.select(conditions, [1,7])\n","predictions[ix[0][pred17==1]] = 1\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["{'activation': 'relu', 'batch_size': 256, 'drop1': 0.5, 'drop2': 0.4, 'nb_neurons': 192, 'optimizer': 'nadam'}\n","Epoch 1/100\n","931/931 [==============================] - 2s 2ms/sample - loss: 0.4375 - acc: 0.9925\n","32/32 [==============================] - 24s 752ms/step - loss: 0.3504 - acc: 0.9306 - val_loss: 0.4386 - val_acc: 0.9925\n","Epoch 2/100\n","931/931 [==============================] - 0s 82us/sample - loss: 0.3987 - acc: 0.9850\n","32/32 [==============================] - 2s 72ms/step - loss: 0.0241 - acc: 0.9910 - val_loss: 0.3995 - val_acc: 0.9850\n","Epoch 3/100\n","931/931 [==============================] - 0s 65us/sample - loss: 0.3334 - acc: 0.9979\n","32/32 [==============================] - 3s 93ms/step - loss: 0.0195 - acc: 0.9936 - val_loss: 0.3344 - val_acc: 0.9979\n","Epoch 4/100\n","931/931 [==============================] - 0s 69us/sample - loss: 0.2888 - acc: 0.9893\n","32/32 [==============================] - 3s 89ms/step - loss: 0.0180 - acc: 0.9944 - val_loss: 0.2898 - val_acc: 0.9893\n","Epoch 5/100\n","931/931 [==============================] - 0s 67us/sample - loss: 0.2161 - acc: 0.9968\n","32/32 [==============================] - 3s 90ms/step - loss: 0.0202 - acc: 0.9941 - val_loss: 0.2170 - val_acc: 0.9968\n","Epoch 6/100\n","931/931 [==============================] - 0s 75us/sample - loss: 0.1723 - acc: 0.9989\n","32/32 [==============================] - 3s 92ms/step - loss: 0.0241 - acc: 0.9902 - val_loss: 0.1734 - val_acc: 0.9989\n","Epoch 7/100\n","931/931 [==============================] - 0s 90us/sample - loss: 0.0730 - acc: 0.9979\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0143 - acc: 0.9955 - val_loss: 0.0737 - val_acc: 0.9979\n","Epoch 8/100\n","931/931 [==============================] - 0s 61us/sample - loss: 0.0957 - acc: 0.9957\n","32/32 [==============================] - 3s 89ms/step - loss: 0.0246 - acc: 0.9925 - val_loss: 0.0966 - val_acc: 0.9957\n","Epoch 9/100\n","931/931 [==============================] - 0s 63us/sample - loss: 0.0414 - acc: 0.9979\n","32/32 [==============================] - 13s 408ms/step - loss: 0.0170 - acc: 0.9955 - val_loss: 0.0417 - val_acc: 0.9979\n","Epoch 10/100\n","931/931 [==============================] - 0s 82us/sample - loss: 0.0494 - acc: 0.9946\n","32/32 [==============================] - 2s 70ms/step - loss: 0.0131 - acc: 0.9958 - val_loss: 0.0503 - val_acc: 0.9946\n","Epoch 11/100\n","931/931 [==============================] - 0s 67us/sample - loss: 0.0200 - acc: 0.9979\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0121 - acc: 0.9963 - val_loss: 0.0202 - val_acc: 0.9979\n","max accuracy: 0.99892586\n","Epoch 1/100\n","931/931 [==============================] - 2s 2ms/sample - loss: 0.4562 - acc: 0.9151\n","32/32 [==============================] - 24s 750ms/step - loss: 0.2717 - acc: 0.9314 - val_loss: 0.4568 - val_acc: 0.9151\n","Epoch 2/100\n","931/931 [==============================] - 0s 63us/sample - loss: 0.4053 - acc: 0.9484\n","32/32 [==============================] - 2s 72ms/step - loss: 0.0252 - acc: 0.9917 - val_loss: 0.4060 - val_acc: 0.9484\n","Epoch 3/100\n","931/931 [==============================] - 0s 65us/sample - loss: 0.3398 - acc: 0.9807\n","32/32 [==============================] - 3s 92ms/step - loss: 0.0224 - acc: 0.9934 - val_loss: 0.3404 - val_acc: 0.9807\n","Epoch 4/100\n","931/931 [==============================] - 0s 80us/sample - loss: 0.3187 - acc: 0.9570\n","32/32 [==============================] - 3s 89ms/step - loss: 0.0154 - acc: 0.9951 - val_loss: 0.3194 - val_acc: 0.9570\n","Epoch 5/100\n","931/931 [==============================] - 0s 64us/sample - loss: 0.2922 - acc: 0.9850\n","32/32 [==============================] - 3s 91ms/step - loss: 0.0167 - acc: 0.9948 - val_loss: 0.2930 - val_acc: 0.9850\n","Epoch 6/100\n","931/931 [==============================] - 0s 73us/sample - loss: 0.1868 - acc: 0.9979\n","32/32 [==============================] - 3s 91ms/step - loss: 0.0168 - acc: 0.9947 - val_loss: 0.1876 - val_acc: 0.9979\n","Epoch 7/100\n","931/931 [==============================] - 0s 64us/sample - loss: 0.1339 - acc: 0.9903\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0122 - acc: 0.9953 - val_loss: 0.1348 - val_acc: 0.9903\n","Epoch 8/100\n","931/931 [==============================] - 0s 62us/sample - loss: 0.1312 - acc: 0.9968\n","32/32 [==============================] - 3s 92ms/step - loss: 0.0141 - acc: 0.9950 - val_loss: 0.1316 - val_acc: 0.9968\n","Epoch 9/100\n","931/931 [==============================] - 0s 63us/sample - loss: 0.0921 - acc: 0.9968\n","32/32 [==============================] - 13s 418ms/step - loss: 0.0127 - acc: 0.9955 - val_loss: 0.0925 - val_acc: 0.9968\n","Epoch 10/100\n","931/931 [==============================] - 0s 63us/sample - loss: 0.0761 - acc: 0.9979\n","32/32 [==============================] - 2s 71ms/step - loss: 0.0128 - acc: 0.9967 - val_loss: 0.0767 - val_acc: 0.9979\n","Epoch 11/100\n","931/931 [==============================] - 0s 63us/sample - loss: 0.0646 - acc: 0.9989\n","32/32 [==============================] - 3s 93ms/step - loss: 0.0140 - acc: 0.9951 - val_loss: 0.0649 - val_acc: 0.9989\n","Epoch 12/100\n","931/931 [==============================] - 0s 69us/sample - loss: 0.0340 - acc: 0.9979\n","32/32 [==============================] - 3s 89ms/step - loss: 0.0090 - acc: 0.9967 - val_loss: 0.0340 - val_acc: 0.9979\n","Epoch 13/100\n","931/931 [==============================] - 0s 66us/sample - loss: 0.0322 - acc: 0.9968\n","32/32 [==============================] - 3s 90ms/step - loss: 0.0097 - acc: 0.9974 - val_loss: 0.0329 - val_acc: 0.9968\n","Epoch 14/100\n","931/931 [==============================] - 0s 79us/sample - loss: 0.0183 - acc: 0.9989\n","32/32 [==============================] - 3s 89ms/step - loss: 0.0121 - acc: 0.9968 - val_loss: 0.0184 - val_acc: 0.9989\n","Epoch 15/100\n","931/931 [==============================] - 0s 66us/sample - loss: 0.0134 - acc: 0.9989\n","32/32 [==============================] - 3s 87ms/step - loss: 0.0093 - acc: 0.9969 - val_loss: 0.0134 - val_acc: 0.9989\n","Epoch 16/100\n","931/931 [==============================] - 0s 65us/sample - loss: 0.0101 - acc: 0.9989\n","32/32 [==============================] - 3s 89ms/step - loss: 0.0094 - acc: 0.9964 - val_loss: 0.0102 - val_acc: 0.9989\n","max accuracy: 0.99892586\n","Epoch 1/100\n","931/931 [==============================] - 2s 2ms/sample - loss: 0.4778 - acc: 0.9968\n","32/32 [==============================] - 24s 764ms/step - loss: 0.3005 - acc: 0.9285 - val_loss: 0.4789 - val_acc: 0.9968\n","Epoch 2/100\n","931/931 [==============================] - 0s 111us/sample - loss: 0.4197 - acc: 0.9979\n","32/32 [==============================] - 2s 75ms/step - loss: 0.0293 - acc: 0.9919 - val_loss: 0.4205 - val_acc: 0.9979\n","Epoch 3/100\n","931/931 [==============================] - 0s 65us/sample - loss: 0.3732 - acc: 0.9946\n","32/32 [==============================] - 3s 85ms/step - loss: 0.0194 - acc: 0.9939 - val_loss: 0.3740 - val_acc: 0.9946\n","Epoch 4/100\n","931/931 [==============================] - 0s 62us/sample - loss: 0.3075 - acc: 0.9979\n","32/32 [==============================] - 3s 90ms/step - loss: 0.0154 - acc: 0.9961 - val_loss: 0.3083 - val_acc: 0.9979\n","Epoch 5/100\n","931/931 [==============================] - 0s 65us/sample - loss: 0.2742 - acc: 0.9957\n","32/32 [==============================] - 14s 425ms/step - loss: 0.0147 - acc: 0.9950 - val_loss: 0.2749 - val_acc: 0.9957\n","Epoch 6/100\n","931/931 [==============================] - 0s 94us/sample - loss: 0.1932 - acc: 0.9957\n","32/32 [==============================] - 2s 70ms/step - loss: 0.0138 - acc: 0.9961 - val_loss: 0.1940 - val_acc: 0.9957\n","Epoch 7/100\n","931/931 [==============================] - 0s 63us/sample - loss: 0.1458 - acc: 0.9979\n","32/32 [==============================] - 3s 90ms/step - loss: 0.0120 - acc: 0.9953 - val_loss: 0.1465 - val_acc: 0.9979\n","Epoch 1/100\n","931/931 [==============================] - 2s 2ms/sample - loss: 0.4274 - acc: 0.9807\n","32/32 [==============================] - 25s 773ms/step - loss: 0.3789 - acc: 0.9329 - val_loss: 0.4281 - val_acc: 0.9807\n","Epoch 2/100\n","931/931 [==============================] - 0s 68us/sample - loss: 0.3533 - acc: 0.9936\n","32/32 [==============================] - 2s 71ms/step - loss: 0.0245 - acc: 0.9925 - val_loss: 0.3541 - val_acc: 0.9936\n","Epoch 3/100\n","931/931 [==============================] - 0s 65us/sample - loss: 0.3275 - acc: 0.9882\n","32/32 [==============================] - 3s 90ms/step - loss: 0.0231 - acc: 0.9929 - val_loss: 0.3281 - val_acc: 0.9882\n","Epoch 4/100\n","931/931 [==============================] - 0s 89us/sample - loss: 0.2769 - acc: 0.9989\n","32/32 [==============================] - 3s 92ms/step - loss: 0.0183 - acc: 0.9942 - val_loss: 0.2777 - val_acc: 0.9989\n","Epoch 5/100\n","931/931 [==============================] - 0s 67us/sample - loss: 0.2408 - acc: 0.9914\n","32/32 [==============================] - 3s 89ms/step - loss: 0.0197 - acc: 0.9948 - val_loss: 0.2414 - val_acc: 0.9914\n","Epoch 6/100\n","931/931 [==============================] - 0s 75us/sample - loss: 0.1810 - acc: 0.9979\n","32/32 [==============================] - 3s 89ms/step - loss: 0.0157 - acc: 0.9947 - val_loss: 0.1817 - val_acc: 0.9979\n","Epoch 7/100\n","931/931 [==============================] - 0s 59us/sample - loss: 0.1168 - acc: 0.9989\n","32/32 [==============================] - 14s 429ms/step - loss: 0.0134 - acc: 0.9957 - val_loss: 0.1174 - val_acc: 0.9989\n","Epoch 8/100\n","931/931 [==============================] - 0s 68us/sample - loss: 0.1075 - acc: 0.9989\n","32/32 [==============================] - 2s 70ms/step - loss: 0.0138 - acc: 0.9952 - val_loss: 0.1079 - val_acc: 0.9989\n","Epoch 9/100\n","931/931 [==============================] - 0s 64us/sample - loss: 0.0833 - acc: 0.9968\n","32/32 [==============================] - 3s 89ms/step - loss: 0.0138 - acc: 0.9951 - val_loss: 0.0841 - val_acc: 0.9968\n","Epoch 1/100\n","931/931 [==============================] - 2s 2ms/sample - loss: 0.4846 - acc: 0.9968\n","32/32 [==============================] - 25s 788ms/step - loss: 0.2342 - acc: 0.9365 - val_loss: 0.4854 - val_acc: 0.9968\n","Epoch 2/100\n","931/931 [==============================] - 0s 59us/sample - loss: 0.3902 - acc: 0.9968\n","32/32 [==============================] - 2s 69ms/step - loss: 0.0249 - acc: 0.9937 - val_loss: 0.3912 - val_acc: 0.9968\n","Epoch 3/100\n","931/931 [==============================] - 0s 68us/sample - loss: 0.3754 - acc: 0.9979\n","32/32 [==============================] - 3s 93ms/step - loss: 0.0192 - acc: 0.9942 - val_loss: 0.3763 - val_acc: 0.9979\n","Epoch 4/100\n","931/931 [==============================] - 0s 81us/sample - loss: 0.3158 - acc: 0.9946\n","32/32 [==============================] - 3s 90ms/step - loss: 0.0153 - acc: 0.9952 - val_loss: 0.3165 - val_acc: 0.9946\n","Epoch 5/100\n","931/931 [==============================] - 0s 80us/sample - loss: 0.2583 - acc: 0.9903\n","32/32 [==============================] - 3s 89ms/step - loss: 0.0172 - acc: 0.9947 - val_loss: 0.2591 - val_acc: 0.9903\n","Epoch 6/100\n","931/931 [==============================] - 0s 69us/sample - loss: 0.1786 - acc: 0.9957\n","32/32 [==============================] - 14s 439ms/step - loss: 0.0195 - acc: 0.9941 - val_loss: 0.1794 - val_acc: 0.9957\n","Epoch 7/100\n","931/931 [==============================] - 0s 67us/sample - loss: 0.1809 - acc: 0.9914\n","32/32 [==============================] - 2s 71ms/step - loss: 0.0131 - acc: 0.9961 - val_loss: 0.1817 - val_acc: 0.9914\n","Epoch 8/100\n","931/931 [==============================] - 0s 67us/sample - loss: 0.1402 - acc: 0.9979\n","32/32 [==============================] - 3s 90ms/step - loss: 0.0129 - acc: 0.9953 - val_loss: 0.1403 - val_acc: 0.9979\n","Epoch 1/100\n","931/931 [==============================] - 2s 2ms/sample - loss: 0.4903 - acc: 0.9957\n","32/32 [==============================] - 25s 790ms/step - loss: 0.3159 - acc: 0.9394 - val_loss: 0.4910 - val_acc: 0.9957\n","Epoch 2/100\n","931/931 [==============================] - 0s 72us/sample - loss: 0.4323 - acc: 0.9957\n","32/32 [==============================] - 2s 68ms/step - loss: 0.0248 - acc: 0.9923 - val_loss: 0.4332 - val_acc: 0.9957\n","Epoch 3/100\n","931/931 [==============================] - 0s 63us/sample - loss: 0.3886 - acc: 0.9764\n","32/32 [==============================] - 3s 92ms/step - loss: 0.0236 - acc: 0.9929 - val_loss: 0.3892 - val_acc: 0.9764\n","Epoch 4/100\n","931/931 [==============================] - 0s 68us/sample - loss: 0.3041 - acc: 0.9968\n","32/32 [==============================] - 3s 94ms/step - loss: 0.0182 - acc: 0.9934 - val_loss: 0.3046 - val_acc: 0.9968\n","Epoch 5/100\n","931/931 [==============================] - 0s 68us/sample - loss: 0.2442 - acc: 0.9989\n","32/32 [==============================] - 3s 95ms/step - loss: 0.0154 - acc: 0.9952 - val_loss: 0.2448 - val_acc: 0.9989\n","Epoch 6/100\n","931/931 [==============================] - 0s 67us/sample - loss: 0.1963 - acc: 0.9936\n","32/32 [==============================] - 3s 90ms/step - loss: 0.0107 - acc: 0.9958 - val_loss: 0.1971 - val_acc: 0.9936\n","Epoch 7/100\n","931/931 [==============================] - 0s 71us/sample - loss: 0.1245 - acc: 0.9968\n","32/32 [==============================] - 3s 92ms/step - loss: 0.0161 - acc: 0.9953 - val_loss: 0.1251 - val_acc: 0.9968\n","Epoch 8/100\n","931/931 [==============================] - 0s 79us/sample - loss: 0.1205 - acc: 1.0000\n","32/32 [==============================] - 3s 99ms/step - loss: 0.0149 - acc: 0.9945 - val_loss: 0.1211 - val_acc: 1.0000\n","Epoch 9/100\n","931/931 [==============================] - 0s 80us/sample - loss: 0.0810 - acc: 0.9989\n","32/32 [==============================] - 3s 95ms/step - loss: 0.0128 - acc: 0.9960 - val_loss: 0.0816 - val_acc: 0.9989\n","Epoch 10/100\n","931/931 [==============================] - 0s 82us/sample - loss: 0.0411 - acc: 0.9989\n","32/32 [==============================] - 3s 96ms/step - loss: 0.0103 - acc: 0.9962 - val_loss: 0.0414 - val_acc: 0.9989\n","Epoch 11/100\n","931/931 [==============================] - 0s 77us/sample - loss: 0.0398 - acc: 0.9968\n","32/32 [==============================] - 15s 454ms/step - loss: 0.0138 - acc: 0.9956 - val_loss: 0.0401 - val_acc: 0.9968\n","Epoch 12/100\n","931/931 [==============================] - 0s 68us/sample - loss: 0.0196 - acc: 0.9989\n","32/32 [==============================] - 2s 70ms/step - loss: 0.0115 - acc: 0.9956 - val_loss: 0.0199 - val_acc: 0.9989\n","Epoch 13/100\n","931/931 [==============================] - 0s 61us/sample - loss: 0.0188 - acc: 0.9979\n","32/32 [==============================] - 3s 87ms/step - loss: 0.0102 - acc: 0.9963 - val_loss: 0.0190 - val_acc: 0.9979\n","Epoch 1/100\n","931/931 [==============================] - 2s 2ms/sample - loss: 0.5030 - acc: 0.9936\n","32/32 [==============================] - 25s 791ms/step - loss: 0.3172 - acc: 0.9460 - val_loss: 0.5036 - val_acc: 0.9936\n","Epoch 2/100\n","931/931 [==============================] - 0s 76us/sample - loss: 0.3884 - acc: 0.9968\n","32/32 [==============================] - 2s 68ms/step - loss: 0.0217 - acc: 0.9923 - val_loss: 0.3893 - val_acc: 0.9968\n","Epoch 3/100\n","931/931 [==============================] - 0s 72us/sample - loss: 0.3768 - acc: 0.9979\n","32/32 [==============================] - 3s 89ms/step - loss: 0.0204 - acc: 0.9935 - val_loss: 0.3779 - val_acc: 0.9979\n","Epoch 4/100\n","931/931 [==============================] - 0s 89us/sample - loss: 0.2553 - acc: 0.9925\n","32/32 [==============================] - 3s 90ms/step - loss: 0.0155 - acc: 0.9946 - val_loss: 0.2563 - val_acc: 0.9925\n","Epoch 5/100\n","931/931 [==============================] - 0s 89us/sample - loss: 0.2090 - acc: 0.9968\n","32/32 [==============================] - 3s 90ms/step - loss: 0.0138 - acc: 0.9952 - val_loss: 0.2098 - val_acc: 0.9968\n","Epoch 6/100\n","931/931 [==============================] - 0s 79us/sample - loss: 0.1512 - acc: 0.9968\n","32/32 [==============================] - 14s 453ms/step - loss: 0.0147 - acc: 0.9946 - val_loss: 0.1520 - val_acc: 0.9968\n","Epoch 7/100\n","931/931 [==============================] - 0s 65us/sample - loss: 0.1185 - acc: 1.0000\n","32/32 [==============================] - 2s 68ms/step - loss: 0.0126 - acc: 0.9960 - val_loss: 0.1192 - val_acc: 1.0000\n","Epoch 8/100\n","931/931 [==============================] - 0s 66us/sample - loss: 0.1062 - acc: 0.9989\n","32/32 [==============================] - 3s 85ms/step - loss: 0.0153 - acc: 0.9951 - val_loss: 0.1067 - val_acc: 0.9989\n","Epoch 9/100\n","931/931 [==============================] - 0s 68us/sample - loss: 0.0638 - acc: 0.9979\n","32/32 [==============================] - 3s 86ms/step - loss: 0.0121 - acc: 0.9955 - val_loss: 0.0643 - val_acc: 0.9979\n","Epoch 10/100\n","931/931 [==============================] - 0s 66us/sample - loss: 0.0475 - acc: 0.9979\n","32/32 [==============================] - 3s 86ms/step - loss: 0.0125 - acc: 0.9963 - val_loss: 0.0479 - val_acc: 0.9979\n","Epoch 11/100\n","931/931 [==============================] - 0s 68us/sample - loss: 0.0384 - acc: 0.9989\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0106 - acc: 0.9971 - val_loss: 0.0387 - val_acc: 0.9989\n","Epoch 12/100\n","931/931 [==============================] - 0s 65us/sample - loss: 0.0240 - acc: 0.9989\n","32/32 [==============================] - 3s 86ms/step - loss: 0.0093 - acc: 0.9969 - val_loss: 0.0243 - val_acc: 0.9989\n","max accuracy: 1.0\n","Epoch 1/100\n","931/931 [==============================] - 2s 2ms/sample - loss: 0.5022 - acc: 0.9925\n","32/32 [==============================] - 26s 799ms/step - loss: 0.1980 - acc: 0.9485 - val_loss: 0.5033 - val_acc: 0.9925\n","Epoch 2/100\n","931/931 [==============================] - 0s 63us/sample - loss: 0.4183 - acc: 0.9979\n","32/32 [==============================] - 2s 68ms/step - loss: 0.0225 - acc: 0.9923 - val_loss: 0.4192 - val_acc: 0.9979\n","Epoch 3/100\n","931/931 [==============================] - 0s 81us/sample - loss: 0.3724 - acc: 0.9957\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0207 - acc: 0.9928 - val_loss: 0.3731 - val_acc: 0.9957\n","Epoch 4/100\n","931/931 [==============================] - 0s 71us/sample - loss: 0.3203 - acc: 0.9957\n","32/32 [==============================] - 3s 85ms/step - loss: 0.0180 - acc: 0.9936 - val_loss: 0.3211 - val_acc: 0.9957\n","Epoch 5/100\n","931/931 [==============================] - 0s 76us/sample - loss: 0.2953 - acc: 0.9925\n","32/32 [==============================] - 14s 453ms/step - loss: 0.0143 - acc: 0.9956 - val_loss: 0.2962 - val_acc: 0.9925\n","Epoch 6/100\n","931/931 [==============================] - 0s 59us/sample - loss: 0.2529 - acc: 0.9957\n","32/32 [==============================] - 2s 65ms/step - loss: 0.0144 - acc: 0.9957 - val_loss: 0.2538 - val_acc: 0.9957\n","Epoch 7/100\n","931/931 [==============================] - 0s 70us/sample - loss: 0.1899 - acc: 0.9989\n","32/32 [==============================] - 3s 87ms/step - loss: 0.0109 - acc: 0.9967 - val_loss: 0.1908 - val_acc: 0.9989\n","Epoch 8/100\n","931/931 [==============================] - 0s 64us/sample - loss: 0.1608 - acc: 0.9936\n","32/32 [==============================] - 3s 87ms/step - loss: 0.0088 - acc: 0.9971 - val_loss: 0.1615 - val_acc: 0.9936\n","Epoch 9/100\n","931/931 [==============================] - 0s 64us/sample - loss: 0.1190 - acc: 0.9914\n","32/32 [==============================] - 3s 92ms/step - loss: 0.0115 - acc: 0.9961 - val_loss: 0.1201 - val_acc: 0.9914\n","Epoch 10/100\n","931/931 [==============================] - 0s 73us/sample - loss: 0.0781 - acc: 0.9968\n","32/32 [==============================] - 3s 89ms/step - loss: 0.0083 - acc: 0.9974 - val_loss: 0.0783 - val_acc: 0.9968\n","Epoch 11/100\n","931/931 [==============================] - 0s 67us/sample - loss: 0.0529 - acc: 0.9989\n","32/32 [==============================] - 3s 85ms/step - loss: 0.0079 - acc: 0.9973 - val_loss: 0.0533 - val_acc: 0.9989\n","Epoch 12/100\n","931/931 [==============================] - 0s 64us/sample - loss: 0.0594 - acc: 0.9968\n","32/32 [==============================] - 3s 85ms/step - loss: 0.0091 - acc: 0.9971 - val_loss: 0.0595 - val_acc: 0.9968\n","Epoch 1/100\n","931/931 [==============================] - 2s 2ms/sample - loss: 0.4520 - acc: 0.9936\n","32/32 [==============================] - 26s 810ms/step - loss: 0.3006 - acc: 0.9313 - val_loss: 0.4530 - val_acc: 0.9936\n","Epoch 2/100\n","931/931 [==============================] - 0s 61us/sample - loss: 0.4157 - acc: 0.9946\n","32/32 [==============================] - 2s 69ms/step - loss: 0.0264 - acc: 0.9919 - val_loss: 0.4166 - val_acc: 0.9946\n","Epoch 3/100\n","931/931 [==============================] - 0s 60us/sample - loss: 0.3458 - acc: 0.9968\n","32/32 [==============================] - 3s 86ms/step - loss: 0.0190 - acc: 0.9935 - val_loss: 0.3468 - val_acc: 0.9968\n","Epoch 4/100\n","931/931 [==============================] - 0s 74us/sample - loss: 0.3021 - acc: 0.9979\n","32/32 [==============================] - 3s 91ms/step - loss: 0.0166 - acc: 0.9944 - val_loss: 0.3030 - val_acc: 0.9979\n","Epoch 5/100\n","931/931 [==============================] - 0s 66us/sample - loss: 0.2479 - acc: 0.9957\n","32/32 [==============================] - 3s 84ms/step - loss: 0.0130 - acc: 0.9958 - val_loss: 0.2489 - val_acc: 0.9957\n","Epoch 6/100\n","931/931 [==============================] - 0s 62us/sample - loss: 0.1697 - acc: 0.9936\n","32/32 [==============================] - 3s 85ms/step - loss: 0.0157 - acc: 0.9948 - val_loss: 0.1705 - val_acc: 0.9936\n","Epoch 7/100\n","931/931 [==============================] - 0s 67us/sample - loss: 0.1514 - acc: 0.9871\n","32/32 [==============================] - 15s 453ms/step - loss: 0.0126 - acc: 0.9962 - val_loss: 0.1527 - val_acc: 0.9871\n","Epoch 8/100\n","931/931 [==============================] - 0s 67us/sample - loss: 0.1053 - acc: 0.9989\n","32/32 [==============================] - 3s 83ms/step - loss: 0.0136 - acc: 0.9946 - val_loss: 0.1060 - val_acc: 0.9989\n","Epoch 9/100\n","931/931 [==============================] - 0s 75us/sample - loss: 0.0973 - acc: 0.9989\n","32/32 [==============================] - 3s 86ms/step - loss: 0.0142 - acc: 0.9946 - val_loss: 0.0979 - val_acc: 0.9989\n","Epoch 10/100\n","931/931 [==============================] - 0s 115us/sample - loss: 0.0639 - acc: 0.9989\n","32/32 [==============================] - 3s 93ms/step - loss: 0.0112 - acc: 0.9962 - val_loss: 0.0630 - val_acc: 0.9989\n","Epoch 11/100\n","931/931 [==============================] - 0s 105us/sample - loss: 0.0540 - acc: 0.9989\n","32/32 [==============================] - 3s 89ms/step - loss: 0.0132 - acc: 0.9958 - val_loss: 0.0533 - val_acc: 0.9989\n","Epoch 12/100\n","931/931 [==============================] - 0s 71us/sample - loss: 0.0317 - acc: 0.9989\n","32/32 [==============================] - 3s 84ms/step - loss: 0.0083 - acc: 0.9963 - val_loss: 0.0320 - val_acc: 0.9989\n","Epoch 13/100\n","931/931 [==============================] - 0s 70us/sample - loss: 0.0207 - acc: 0.9989\n","32/32 [==============================] - 3s 88ms/step - loss: 0.0100 - acc: 0.9973 - val_loss: 0.0210 - val_acc: 0.9989\n","Epoch 1/100\n","931/931 [==============================] - 2s 2ms/sample - loss: 0.4752 - acc: 0.9936\n","32/32 [==============================] - 26s 824ms/step - loss: 0.3216 - acc: 0.9318 - val_loss: 0.4761 - val_acc: 0.9936\n","Epoch 2/100\n","931/931 [==============================] - 0s 72us/sample - loss: 0.3957 - acc: 0.9968\n","32/32 [==============================] - 2s 68ms/step - loss: 0.0289 - acc: 0.9919 - val_loss: 0.3967 - val_acc: 0.9968\n","Epoch 3/100\n","931/931 [==============================] - 0s 73us/sample - loss: 0.3801 - acc: 0.9968\n","32/32 [==============================] - 3s 92ms/step - loss: 0.0215 - acc: 0.9936 - val_loss: 0.3809 - val_acc: 0.9968\n","Epoch 4/100\n","931/931 [==============================] - 0s 67us/sample - loss: 0.2899 - acc: 0.9968\n","32/32 [==============================] - 3s 91ms/step - loss: 0.0170 - acc: 0.9944 - val_loss: 0.2907 - val_acc: 0.9968\n","Epoch 5/100\n","931/931 [==============================] - 0s 64us/sample - loss: 0.2583 - acc: 0.9925\n","32/32 [==============================] - 15s 456ms/step - loss: 0.0187 - acc: 0.9936 - val_loss: 0.2592 - val_acc: 0.9925\n","Epoch 6/100\n","931/931 [==============================] - 0s 66us/sample - loss: 0.2096 - acc: 0.9968\n","32/32 [==============================] - 2s 69ms/step - loss: 0.0144 - acc: 0.9947 - val_loss: 0.2105 - val_acc: 0.9968\n","Epoch 7/100\n","931/931 [==============================] - 0s 69us/sample - loss: 0.1732 - acc: 0.9968\n","32/32 [==============================] - 3s 89ms/step - loss: 0.0110 - acc: 0.9961 - val_loss: 0.1741 - val_acc: 0.9968\n"],"name":"stdout"}]},{"metadata":{"id":"zXHSnXFz7cle","colab_type":"text"},"cell_type":"markdown","source":["##Предсказываем классы 4 и 9"]},{"metadata":{"id":"af-DMbTF18vx","colab_type":"code","outputId":"f30acb27-2272-4b95-976c-97e154187ed9","executionInfo":{"status":"ok","timestamp":1551264124129,"user_tz":-180,"elapsed":1287825,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}},"colab":{"base_uri":"https://localhost:8080/","height":8738}},"cell_type":"code","source":["p = params\n","p['nb_neurons'] = 192\n","ix, pred = fit_predict(ix49_train,ix49_val,[4,9], 2, p, 10)\n","\n","\n","conditions = [pred == 0, pred == 1]\n","pred49 = np.select(conditions, [4,9])\n","predictions[ix[0]] = pred49\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["{'activation': 'relu', 'batch_size': 256, 'drop1': 0.5, 'drop2': 0.4, 'nb_neurons': 192, 'optimizer': 'nadam'}\n","Epoch 1/100\n","870/870 [==============================] - 2s 3ms/sample - loss: 0.5723 - acc: 0.9759\n","29/29 [==============================] - 26s 902ms/step - loss: 0.7357 - acc: 0.7364 - val_loss: 0.5724 - val_acc: 0.9759\n","Epoch 2/100\n","870/870 [==============================] - 0s 67us/sample - loss: 0.5052 - acc: 0.9770\n","29/29 [==============================] - 2s 71ms/step - loss: 0.1409 - acc: 0.9528 - val_loss: 0.5055 - val_acc: 0.9770\n","Epoch 3/100\n","870/870 [==============================] - 0s 83us/sample - loss: 0.4452 - acc: 0.9816\n","29/29 [==============================] - 3s 88ms/step - loss: 0.0626 - acc: 0.9801 - val_loss: 0.4450 - val_acc: 0.9816\n","Epoch 4/100\n","870/870 [==============================] - 0s 73us/sample - loss: 0.4290 - acc: 0.9862\n","29/29 [==============================] - 3s 88ms/step - loss: 0.0662 - acc: 0.9789 - val_loss: 0.4288 - val_acc: 0.9862\n","Epoch 5/100\n","870/870 [==============================] - 0s 68us/sample - loss: 0.4168 - acc: 0.9575\n","29/29 [==============================] - 2s 85ms/step - loss: 0.0514 - acc: 0.9842 - val_loss: 0.4174 - val_acc: 0.9575\n","Epoch 6/100\n","870/870 [==============================] - 0s 75us/sample - loss: 0.3559 - acc: 0.9862\n","29/29 [==============================] - 2s 86ms/step - loss: 0.0492 - acc: 0.9848 - val_loss: 0.3561 - val_acc: 0.9862\n","Epoch 7/100\n","870/870 [==============================] - 0s 67us/sample - loss: 0.3457 - acc: 0.9862\n","29/29 [==============================] - 15s 508ms/step - loss: 0.0465 - acc: 0.9844 - val_loss: 0.3453 - val_acc: 0.9862\n","Epoch 8/100\n","870/870 [==============================] - 0s 67us/sample - loss: 0.3004 - acc: 0.9874\n","29/29 [==============================] - 2s 67ms/step - loss: 0.0398 - acc: 0.9873 - val_loss: 0.3007 - val_acc: 0.9874\n","Epoch 9/100\n","870/870 [==============================] - 0s 83us/sample - loss: 0.2374 - acc: 0.9885\n","29/29 [==============================] - 3s 88ms/step - loss: 0.0348 - acc: 0.9892 - val_loss: 0.2376 - val_acc: 0.9885\n","Epoch 10/100\n","870/870 [==============================] - 0s 84us/sample - loss: 0.2206 - acc: 0.9874\n","29/29 [==============================] - 3s 88ms/step - loss: 0.0364 - acc: 0.9888 - val_loss: 0.2211 - val_acc: 0.9874\n","Epoch 11/100\n","870/870 [==============================] - 0s 75us/sample - loss: 0.1911 - acc: 0.9897\n","29/29 [==============================] - 3s 95ms/step - loss: 0.0362 - acc: 0.9885 - val_loss: 0.1913 - val_acc: 0.9897\n","Epoch 12/100\n","870/870 [==============================] - 0s 77us/sample - loss: 0.1743 - acc: 0.9862\n","29/29 [==============================] - 3s 90ms/step - loss: 0.0305 - acc: 0.9919 - val_loss: 0.1751 - val_acc: 0.9862\n","Epoch 13/100\n","870/870 [==============================] - 0s 77us/sample - loss: 0.1224 - acc: 0.9954\n","29/29 [==============================] - 3s 93ms/step - loss: 0.0303 - acc: 0.9909 - val_loss: 0.1225 - val_acc: 0.9954\n","Epoch 14/100\n","870/870 [==============================] - 0s 78us/sample - loss: 0.0992 - acc: 0.9954\n","29/29 [==============================] - 3s 91ms/step - loss: 0.0306 - acc: 0.9903 - val_loss: 0.0998 - val_acc: 0.9954\n","Epoch 15/100\n","870/870 [==============================] - 0s 105us/sample - loss: 0.0779 - acc: 0.9954\n","29/29 [==============================] - 3s 91ms/step - loss: 0.0294 - acc: 0.9897 - val_loss: 0.0783 - val_acc: 0.9954\n","Epoch 16/100\n","870/870 [==============================] - 0s 81us/sample - loss: 0.0604 - acc: 0.9931\n","29/29 [==============================] - 3s 91ms/step - loss: 0.0305 - acc: 0.9900 - val_loss: 0.0605 - val_acc: 0.9931\n","Epoch 17/100\n","870/870 [==============================] - 0s 89us/sample - loss: 0.0459 - acc: 0.9908\n","29/29 [==============================] - 3s 91ms/step - loss: 0.0267 - acc: 0.9919 - val_loss: 0.0469 - val_acc: 0.9908\n","Epoch 18/100\n","870/870 [==============================] - 0s 84us/sample - loss: 0.0374 - acc: 0.9943\n","29/29 [==============================] - 3s 90ms/step - loss: 0.0256 - acc: 0.9922 - val_loss: 0.0375 - val_acc: 0.9943\n","max accuracy: 0.9954023\n","Epoch 1/100\n","870/870 [==============================] - 2s 3ms/sample - loss: 0.4911 - acc: 0.9644\n","29/29 [==============================] - 26s 910ms/step - loss: 0.4617 - acc: 0.8222 - val_loss: 0.4913 - val_acc: 0.9644\n","Epoch 2/100\n","870/870 [==============================] - 0s 67us/sample - loss: 0.4217 - acc: 0.9632\n","29/29 [==============================] - 2s 64ms/step - loss: 0.0794 - acc: 0.9758 - val_loss: 0.4223 - val_acc: 0.9632\n","Epoch 3/100\n","870/870 [==============================] - 0s 66us/sample - loss: 0.4003 - acc: 0.9724\n","29/29 [==============================] - 3s 88ms/step - loss: 0.0942 - acc: 0.9674 - val_loss: 0.4013 - val_acc: 0.9724\n","Epoch 4/100\n","870/870 [==============================] - 0s 67us/sample - loss: 0.3249 - acc: 0.9793\n","29/29 [==============================] - 3s 88ms/step - loss: 0.0627 - acc: 0.9788 - val_loss: 0.3256 - val_acc: 0.9793\n","Epoch 5/100\n","870/870 [==============================] - 0s 80us/sample - loss: 0.2681 - acc: 0.9759\n","29/29 [==============================] - 2s 85ms/step - loss: 0.0477 - acc: 0.9824 - val_loss: 0.2691 - val_acc: 0.9759\n","Epoch 6/100\n","870/870 [==============================] - 0s 66us/sample - loss: 0.2455 - acc: 0.9885\n","29/29 [==============================] - 3s 88ms/step - loss: 0.0458 - acc: 0.9854 - val_loss: 0.2456 - val_acc: 0.9885\n","Epoch 7/100\n","870/870 [==============================] - 0s 70us/sample - loss: 0.2115 - acc: 0.9851\n","29/29 [==============================] - 3s 86ms/step - loss: 0.0425 - acc: 0.9862 - val_loss: 0.2123 - val_acc: 0.9851\n","Epoch 8/100\n","870/870 [==============================] - 0s 64us/sample - loss: 0.1701 - acc: 0.9920\n","29/29 [==============================] - 3s 89ms/step - loss: 0.0381 - acc: 0.9877 - val_loss: 0.1708 - val_acc: 0.9920\n","Epoch 9/100\n","870/870 [==============================] - 0s 81us/sample - loss: 0.1716 - acc: 0.9908\n","29/29 [==============================] - 2s 86ms/step - loss: 0.0422 - acc: 0.9866 - val_loss: 0.1719 - val_acc: 0.9908\n","Epoch 10/100\n","870/870 [==============================] - 0s 67us/sample - loss: 0.1683 - acc: 0.9908\n","29/29 [==============================] - 2s 84ms/step - loss: 0.0397 - acc: 0.9882 - val_loss: 0.1681 - val_acc: 0.9908\n","Epoch 11/100\n","870/870 [==============================] - 0s 73us/sample - loss: 0.1318 - acc: 0.9920\n","29/29 [==============================] - 15s 517ms/step - loss: 0.0355 - acc: 0.9905 - val_loss: 0.1318 - val_acc: 0.9920\n","Epoch 12/100\n","870/870 [==============================] - 0s 65us/sample - loss: 0.0950 - acc: 0.9954\n","29/29 [==============================] - 2s 68ms/step - loss: 0.0290 - acc: 0.9904 - val_loss: 0.0954 - val_acc: 0.9954\n","Epoch 13/100\n","870/870 [==============================] - 0s 74us/sample - loss: 0.0708 - acc: 0.9943\n","29/29 [==============================] - 2s 86ms/step - loss: 0.0264 - acc: 0.9922 - val_loss: 0.0715 - val_acc: 0.9943\n","Epoch 14/100\n","870/870 [==============================] - 0s 74us/sample - loss: 0.0505 - acc: 0.9954\n","29/29 [==============================] - 2s 86ms/step - loss: 0.0265 - acc: 0.9919 - val_loss: 0.0507 - val_acc: 0.9954\n","Epoch 15/100\n","870/870 [==============================] - 0s 77us/sample - loss: 0.0429 - acc: 0.9920\n","29/29 [==============================] - 2s 85ms/step - loss: 0.0244 - acc: 0.9927 - val_loss: 0.0431 - val_acc: 0.9920\n","Epoch 16/100\n","870/870 [==============================] - 0s 74us/sample - loss: 0.0332 - acc: 0.9954\n","29/29 [==============================] - 2s 85ms/step - loss: 0.0209 - acc: 0.9932 - val_loss: 0.0334 - val_acc: 0.9954\n","Epoch 17/100\n","870/870 [==============================] - 0s 75us/sample - loss: 0.0307 - acc: 0.9943\n","29/29 [==============================] - 2s 86ms/step - loss: 0.0215 - acc: 0.9935 - val_loss: 0.0303 - val_acc: 0.9943\n","Epoch 1/100\n","870/870 [==============================] - 2s 3ms/sample - loss: 0.4972 - acc: 0.7977\n","29/29 [==============================] - 27s 922ms/step - loss: 0.6757 - acc: 0.8146 - val_loss: 0.4992 - val_acc: 0.7977\n","Epoch 2/100\n","870/870 [==============================] - 0s 65us/sample - loss: 0.3825 - acc: 0.9793\n","29/29 [==============================] - 2s 64ms/step - loss: 0.0914 - acc: 0.9689 - val_loss: 0.3831 - val_acc: 0.9793\n","Epoch 3/100\n","870/870 [==============================] - 0s 82us/sample - loss: 0.3142 - acc: 0.9851\n","29/29 [==============================] - 3s 88ms/step - loss: 0.0531 - acc: 0.9828 - val_loss: 0.3148 - val_acc: 0.9851\n","Epoch 4/100\n","870/870 [==============================] - 0s 78us/sample - loss: 0.3075 - acc: 0.9908\n","29/29 [==============================] - 3s 90ms/step - loss: 0.0544 - acc: 0.9838 - val_loss: 0.3075 - val_acc: 0.9908\n","Epoch 5/100\n","870/870 [==============================] - 0s 92us/sample - loss: 0.2879 - acc: 0.9920\n","29/29 [==============================] - 3s 92ms/step - loss: 0.0451 - acc: 0.9858 - val_loss: 0.2877 - val_acc: 0.9920\n","Epoch 6/100\n","870/870 [==============================] - 0s 81us/sample - loss: 0.2721 - acc: 0.9897\n","29/29 [==============================] - 3s 90ms/step - loss: 0.0394 - acc: 0.9870 - val_loss: 0.2717 - val_acc: 0.9897\n","Epoch 7/100\n","870/870 [==============================] - 0s 80us/sample - loss: 0.2141 - acc: 0.9920\n","29/29 [==============================] - 3s 96ms/step - loss: 0.0363 - acc: 0.9888 - val_loss: 0.2137 - val_acc: 0.9920\n","Epoch 8/100\n","870/870 [==============================] - 0s 85us/sample - loss: 0.1958 - acc: 0.9862\n","29/29 [==============================] - 16s 536ms/step - loss: 0.0339 - acc: 0.9894 - val_loss: 0.1967 - val_acc: 0.9862\n","Epoch 9/100\n","870/870 [==============================] - 0s 67us/sample - loss: 0.1205 - acc: 0.9931\n","29/29 [==============================] - 2s 67ms/step - loss: 0.0291 - acc: 0.9908 - val_loss: 0.1207 - val_acc: 0.9931\n","Epoch 10/100\n","870/870 [==============================] - 0s 70us/sample - loss: 0.1219 - acc: 0.9920\n","29/29 [==============================] - 2s 86ms/step - loss: 0.0278 - acc: 0.9923 - val_loss: 0.1219 - val_acc: 0.9920\n","Epoch 11/100\n","870/870 [==============================] - 0s 70us/sample - loss: 0.1090 - acc: 0.9920\n","29/29 [==============================] - 2s 85ms/step - loss: 0.0297 - acc: 0.9904 - val_loss: 0.1076 - val_acc: 0.9920\n","Epoch 12/100\n","870/870 [==============================] - 0s 63us/sample - loss: 0.0887 - acc: 0.9931\n","29/29 [==============================] - 2s 84ms/step - loss: 0.0263 - acc: 0.9916 - val_loss: 0.0884 - val_acc: 0.9931\n","Epoch 13/100\n","870/870 [==============================] - 0s 64us/sample - loss: 0.0509 - acc: 0.9931\n","29/29 [==============================] - 2s 84ms/step - loss: 0.0212 - acc: 0.9926 - val_loss: 0.0505 - val_acc: 0.9931\n","Epoch 14/100\n","870/870 [==============================] - 0s 64us/sample - loss: 0.0411 - acc: 0.9908\n","29/29 [==============================] - 2s 84ms/step - loss: 0.0230 - acc: 0.9934 - val_loss: 0.0405 - val_acc: 0.9908\n","Epoch 1/100\n","870/870 [==============================] - 2s 3ms/sample - loss: 0.5342 - acc: 0.8989\n","29/29 [==============================] - 27s 918ms/step - loss: 0.5368 - acc: 0.8367 - val_loss: 0.5348 - val_acc: 0.8989\n","Epoch 2/100\n","870/870 [==============================] - 0s 76us/sample - loss: 0.4129 - acc: 0.9575\n","29/29 [==============================] - 2s 65ms/step - loss: 0.0736 - acc: 0.9770 - val_loss: 0.4135 - val_acc: 0.9575\n","Epoch 3/100\n","870/870 [==============================] - 0s 68us/sample - loss: 0.3968 - acc: 0.9264\n","29/29 [==============================] - 2s 82ms/step - loss: 0.0621 - acc: 0.9793 - val_loss: 0.3980 - val_acc: 0.9264\n","Epoch 4/100\n","870/870 [==============================] - 0s 65us/sample - loss: 0.3371 - acc: 0.9701\n","29/29 [==============================] - 3s 87ms/step - loss: 0.0436 - acc: 0.9863 - val_loss: 0.3374 - val_acc: 0.9701\n","Epoch 5/100\n","870/870 [==============================] - 0s 65us/sample - loss: 0.3526 - acc: 0.9575\n","29/29 [==============================] - 2s 84ms/step - loss: 0.0429 - acc: 0.9858 - val_loss: 0.3528 - val_acc: 0.9575\n","Epoch 6/100\n","870/870 [==============================] - 0s 67us/sample - loss: 0.2908 - acc: 0.9839\n","29/29 [==============================] - 3s 87ms/step - loss: 0.0414 - acc: 0.9858 - val_loss: 0.2902 - val_acc: 0.9839\n","Epoch 7/100\n","870/870 [==============================] - 0s 65us/sample - loss: 0.2214 - acc: 0.9920\n","29/29 [==============================] - 3s 88ms/step - loss: 0.0364 - acc: 0.9890 - val_loss: 0.2208 - val_acc: 0.9920\n","Epoch 8/100\n","870/870 [==============================] - 0s 72us/sample - loss: 0.2453 - acc: 0.9943\n","29/29 [==============================] - 3s 87ms/step - loss: 0.0357 - acc: 0.9894 - val_loss: 0.2446 - val_acc: 0.9943\n","Epoch 9/100\n","870/870 [==============================] - 0s 80us/sample - loss: 0.1771 - acc: 0.9897\n","29/29 [==============================] - 2s 85ms/step - loss: 0.0316 - acc: 0.9916 - val_loss: 0.1762 - val_acc: 0.9897\n","Epoch 10/100\n","870/870 [==============================] - 0s 68us/sample - loss: 0.1244 - acc: 0.9920\n","29/29 [==============================] - 2s 83ms/step - loss: 0.0316 - acc: 0.9896 - val_loss: 0.1235 - val_acc: 0.9920\n","Epoch 11/100\n","870/870 [==============================] - 0s 65us/sample - loss: 0.0962 - acc: 0.9943\n","29/29 [==============================] - 15s 528ms/step - loss: 0.0258 - acc: 0.9919 - val_loss: 0.0957 - val_acc: 0.9943\n","Epoch 12/100\n","870/870 [==============================] - 0s 72us/sample - loss: 0.1089 - acc: 0.9954\n","29/29 [==============================] - 2s 67ms/step - loss: 0.0228 - acc: 0.9931 - val_loss: 0.1084 - val_acc: 0.9954\n","Epoch 13/100\n","870/870 [==============================] - 0s 68us/sample - loss: 0.0667 - acc: 0.9931\n","29/29 [==============================] - 2s 85ms/step - loss: 0.0220 - acc: 0.9931 - val_loss: 0.0669 - val_acc: 0.9931\n","Epoch 14/100\n","870/870 [==============================] - 0s 70us/sample - loss: 0.0554 - acc: 0.9943\n","29/29 [==============================] - 2s 85ms/step - loss: 0.0220 - acc: 0.9924 - val_loss: 0.0547 - val_acc: 0.9943\n","Epoch 15/100\n","870/870 [==============================] - 0s 68us/sample - loss: 0.0381 - acc: 0.9966\n","29/29 [==============================] - 3s 87ms/step - loss: 0.0235 - acc: 0.9934 - val_loss: 0.0370 - val_acc: 0.9966\n","Epoch 16/100\n","870/870 [==============================] - 0s 66us/sample - loss: 0.0364 - acc: 0.9943\n","29/29 [==============================] - 2s 84ms/step - loss: 0.0224 - acc: 0.9935 - val_loss: 0.0359 - val_acc: 0.9943\n","Epoch 17/100\n","870/870 [==============================] - 0s 66us/sample - loss: 0.0335 - acc: 0.9966\n","29/29 [==============================] - 2s 82ms/step - loss: 0.0219 - acc: 0.9936 - val_loss: 0.0325 - val_acc: 0.9966\n","Epoch 18/100\n","870/870 [==============================] - 0s 65us/sample - loss: 0.0215 - acc: 0.9966\n","29/29 [==============================] - 2s 84ms/step - loss: 0.0214 - acc: 0.9923 - val_loss: 0.0206 - val_acc: 0.9966\n","Epoch 19/100\n","870/870 [==============================] - 0s 62us/sample - loss: 0.0184 - acc: 0.9966\n","29/29 [==============================] - 2s 85ms/step - loss: 0.0185 - acc: 0.9943 - val_loss: 0.0176 - val_acc: 0.9966\n","Epoch 20/100\n","870/870 [==============================] - 0s 73us/sample - loss: 0.0162 - acc: 0.9977\n","29/29 [==============================] - 3s 90ms/step - loss: 0.0203 - acc: 0.9947 - val_loss: 0.0150 - val_acc: 0.9977\n","Epoch 21/100\n","870/870 [==============================] - 0s 81us/sample - loss: 0.0178 - acc: 0.9943\n","29/29 [==============================] - 3s 87ms/step - loss: 0.0177 - acc: 0.9947 - val_loss: 0.0177 - val_acc: 0.9943\n","Epoch 22/100\n","870/870 [==============================] - 0s 81us/sample - loss: 0.0174 - acc: 0.9954\n","29/29 [==============================] - 3s 91ms/step - loss: 0.0153 - acc: 0.9961 - val_loss: 0.0158 - val_acc: 0.9954\n","Epoch 23/100\n","870/870 [==============================] - 0s 76us/sample - loss: 0.0158 - acc: 0.9966\n","29/29 [==============================] - 3s 89ms/step - loss: 0.0167 - acc: 0.9949 - val_loss: 0.0141 - val_acc: 0.9966\n","Epoch 24/100\n","870/870 [==============================] - 0s 66us/sample - loss: 0.0156 - acc: 0.9966\n","29/29 [==============================] - 2s 84ms/step - loss: 0.0145 - acc: 0.9954 - val_loss: 0.0141 - val_acc: 0.9966\n","Epoch 25/100\n","870/870 [==============================] - 0s 71us/sample - loss: 0.0141 - acc: 0.9966\n","29/29 [==============================] - 2s 84ms/step - loss: 0.0157 - acc: 0.9946 - val_loss: 0.0126 - val_acc: 0.9966\n","max accuracy: 0.99770117\n","Epoch 1/100\n","870/870 [==============================] - 2s 3ms/sample - loss: 0.5175 - acc: 0.8310\n","29/29 [==============================] - 27s 923ms/step - loss: 0.5776 - acc: 0.8074 - val_loss: 0.5182 - val_acc: 0.8310\n","Epoch 2/100\n","870/870 [==============================] - 0s 78us/sample - loss: 0.4596 - acc: 0.8874\n","29/29 [==============================] - 2s 72ms/step - loss: 0.0847 - acc: 0.9732 - val_loss: 0.4595 - val_acc: 0.8874\n","Epoch 3/100\n","870/870 [==============================] - 0s 65us/sample - loss: 0.3682 - acc: 0.9724\n","29/29 [==============================] - 3s 93ms/step - loss: 0.0542 - acc: 0.9834 - val_loss: 0.3687 - val_acc: 0.9724\n","Epoch 4/100\n","870/870 [==============================] - 0s 71us/sample - loss: 0.3284 - acc: 0.9782\n","29/29 [==============================] - 3s 90ms/step - loss: 0.0433 - acc: 0.9863 - val_loss: 0.3290 - val_acc: 0.9782\n","Epoch 5/100\n","870/870 [==============================] - 0s 67us/sample - loss: 0.2974 - acc: 0.9874\n","29/29 [==============================] - 3s 87ms/step - loss: 0.0461 - acc: 0.9867 - val_loss: 0.2969 - val_acc: 0.9874\n","Epoch 6/100\n","870/870 [==============================] - 0s 68us/sample - loss: 0.2869 - acc: 0.9862\n","29/29 [==============================] - 2s 86ms/step - loss: 0.0362 - acc: 0.9880 - val_loss: 0.2871 - val_acc: 0.9862\n","Epoch 7/100\n","870/870 [==============================] - 0s 79us/sample - loss: 0.2389 - acc: 0.9931\n","29/29 [==============================] - 2s 86ms/step - loss: 0.0347 - acc: 0.9903 - val_loss: 0.2383 - val_acc: 0.9931\n","Epoch 8/100\n","870/870 [==============================] - 0s 71us/sample - loss: 0.1746 - acc: 0.9931\n","29/29 [==============================] - 2s 84ms/step - loss: 0.0285 - acc: 0.9901 - val_loss: 0.1746 - val_acc: 0.9931\n","Epoch 9/100\n","870/870 [==============================] - 0s 67us/sample - loss: 0.1855 - acc: 0.9931\n","29/29 [==============================] - 2s 84ms/step - loss: 0.0321 - acc: 0.9890 - val_loss: 0.1849 - val_acc: 0.9931\n","Epoch 10/100\n","870/870 [==============================] - 0s 67us/sample - loss: 0.1840 - acc: 0.9920\n","29/29 [==============================] - 15s 532ms/step - loss: 0.0369 - acc: 0.9901 - val_loss: 0.1834 - val_acc: 0.9920\n","Epoch 11/100\n","870/870 [==============================] - 0s 68us/sample - loss: 0.0878 - acc: 0.9931\n","29/29 [==============================] - 2s 64ms/step - loss: 0.0267 - acc: 0.9907 - val_loss: 0.0885 - val_acc: 0.9931\n","Epoch 12/100\n","870/870 [==============================] - 0s 69us/sample - loss: 0.0696 - acc: 0.9954\n","29/29 [==============================] - 3s 88ms/step - loss: 0.0266 - acc: 0.9922 - val_loss: 0.0691 - val_acc: 0.9954\n","Epoch 13/100\n","870/870 [==============================] - 0s 71us/sample - loss: 0.0606 - acc: 0.9966\n","29/29 [==============================] - 2s 86ms/step - loss: 0.0236 - acc: 0.9943 - val_loss: 0.0602 - val_acc: 0.9966\n","Epoch 14/100\n","870/870 [==============================] - 0s 71us/sample - loss: 0.0387 - acc: 0.9966\n","29/29 [==============================] - 2s 83ms/step - loss: 0.0208 - acc: 0.9934 - val_loss: 0.0386 - val_acc: 0.9966\n","Epoch 15/100\n","870/870 [==============================] - 0s 65us/sample - loss: 0.0331 - acc: 0.9966\n","29/29 [==============================] - 2s 83ms/step - loss: 0.0212 - acc: 0.9930 - val_loss: 0.0324 - val_acc: 0.9966\n","Epoch 16/100\n","870/870 [==============================] - 0s 68us/sample - loss: 0.0247 - acc: 0.9966\n","29/29 [==============================] - 2s 82ms/step - loss: 0.0229 - acc: 0.9919 - val_loss: 0.0239 - val_acc: 0.9966\n","Epoch 17/100\n","870/870 [==============================] - 0s 68us/sample - loss: 0.0249 - acc: 0.9977\n","29/29 [==============================] - 2s 86ms/step - loss: 0.0221 - acc: 0.9935 - val_loss: 0.0249 - val_acc: 0.9977\n","Epoch 18/100\n","870/870 [==============================] - 0s 67us/sample - loss: 0.0226 - acc: 0.9943\n","29/29 [==============================] - 2s 84ms/step - loss: 0.0223 - acc: 0.9935 - val_loss: 0.0216 - val_acc: 0.9943\n","Epoch 19/100\n","870/870 [==============================] - 0s 65us/sample - loss: 0.0160 - acc: 0.9977\n","29/29 [==============================] - 2s 84ms/step - loss: 0.0187 - acc: 0.9942 - val_loss: 0.0156 - val_acc: 0.9977\n","Epoch 20/100\n","870/870 [==============================] - 0s 67us/sample - loss: 0.0132 - acc: 0.9966\n","29/29 [==============================] - 2s 84ms/step - loss: 0.0209 - acc: 0.9946 - val_loss: 0.0130 - val_acc: 0.9966\n","Epoch 21/100\n","870/870 [==============================] - 0s 66us/sample - loss: 0.0120 - acc: 0.9966\n","29/29 [==============================] - 2s 84ms/step - loss: 0.0157 - acc: 0.9946 - val_loss: 0.0118 - val_acc: 0.9966\n","Epoch 22/100\n","870/870 [==============================] - 0s 69us/sample - loss: 0.0114 - acc: 0.9966\n","29/29 [==============================] - 2s 83ms/step - loss: 0.0182 - acc: 0.9938 - val_loss: 0.0107 - val_acc: 0.9966\n","Epoch 1/100\n","870/870 [==============================] - 2s 3ms/sample - loss: 0.5444 - acc: 0.9736\n","29/29 [==============================] - 27s 940ms/step - loss: 0.5912 - acc: 0.8234 - val_loss: 0.5442 - val_acc: 0.9736\n","Epoch 2/100\n","870/870 [==============================] - 0s 73us/sample - loss: 0.4877 - acc: 0.9701\n","29/29 [==============================] - 2s 64ms/step - loss: 0.0766 - acc: 0.9751 - val_loss: 0.4880 - val_acc: 0.9701\n","Epoch 3/100\n","870/870 [==============================] - 0s 64us/sample - loss: 0.4692 - acc: 0.9839\n","29/29 [==============================] - 2s 85ms/step - loss: 0.0951 - acc: 0.9693 - val_loss: 0.4690 - val_acc: 0.9839\n","Epoch 4/100\n","870/870 [==============================] - 0s 66us/sample - loss: 0.4001 - acc: 0.9931\n","29/29 [==============================] - 2s 86ms/step - loss: 0.0525 - acc: 0.9846 - val_loss: 0.3993 - val_acc: 0.9931\n","Epoch 5/100\n","870/870 [==============================] - 0s 63us/sample - loss: 0.3508 - acc: 0.9839\n","29/29 [==============================] - 2s 82ms/step - loss: 0.0382 - acc: 0.9884 - val_loss: 0.3510 - val_acc: 0.9839\n","Epoch 6/100\n","870/870 [==============================] - 0s 76us/sample - loss: 0.3282 - acc: 0.9920\n","29/29 [==============================] - 2s 83ms/step - loss: 0.0427 - acc: 0.9866 - val_loss: 0.3276 - val_acc: 0.9920\n","Epoch 7/100\n","870/870 [==============================] - 0s 66us/sample - loss: 0.2653 - acc: 0.9931\n","29/29 [==============================] - 16s 541ms/step - loss: 0.0388 - acc: 0.9881 - val_loss: 0.2646 - val_acc: 0.9931\n","Epoch 8/100\n","870/870 [==============================] - 0s 88us/sample - loss: 0.2260 - acc: 0.9931\n","29/29 [==============================] - 2s 65ms/step - loss: 0.0318 - acc: 0.9892 - val_loss: 0.2259 - val_acc: 0.9931\n","Epoch 9/100\n","870/870 [==============================] - 0s 65us/sample - loss: 0.1981 - acc: 0.9908\n","29/29 [==============================] - 2s 84ms/step - loss: 0.0273 - acc: 0.9909 - val_loss: 0.1971 - val_acc: 0.9908\n","Epoch 1/100\n","870/870 [==============================] - 2s 3ms/sample - loss: 0.5393 - acc: 0.9195\n","29/29 [==============================] - 27s 944ms/step - loss: 0.8074 - acc: 0.7548 - val_loss: 0.5397 - val_acc: 0.9195\n","Epoch 2/100\n","870/870 [==============================] - 0s 75us/sample - loss: 0.4312 - acc: 0.9874\n","29/29 [==============================] - 2s 67ms/step - loss: 0.0778 - acc: 0.9765 - val_loss: 0.4306 - val_acc: 0.9874\n","Epoch 3/100\n","870/870 [==============================] - 0s 73us/sample - loss: 0.4268 - acc: 0.9736\n","29/29 [==============================] - 2s 84ms/step - loss: 0.0586 - acc: 0.9823 - val_loss: 0.4266 - val_acc: 0.9736\n","Epoch 4/100\n","870/870 [==============================] - 0s 65us/sample - loss: 0.3742 - acc: 0.9770\n","29/29 [==============================] - 2s 85ms/step - loss: 0.0483 - acc: 0.9846 - val_loss: 0.3735 - val_acc: 0.9770\n","Epoch 5/100\n","870/870 [==============================] - 0s 64us/sample - loss: 0.3033 - acc: 0.9920\n","29/29 [==============================] - 3s 87ms/step - loss: 0.0378 - acc: 0.9882 - val_loss: 0.3025 - val_acc: 0.9920\n","Epoch 6/100\n","870/870 [==============================] - 0s 68us/sample - loss: 0.2722 - acc: 0.9931\n","29/29 [==============================] - 3s 87ms/step - loss: 0.0361 - acc: 0.9873 - val_loss: 0.2713 - val_acc: 0.9931\n","Epoch 7/100\n","870/870 [==============================] - 0s 68us/sample - loss: 0.2117 - acc: 0.9931\n","29/29 [==============================] - 2s 85ms/step - loss: 0.0338 - acc: 0.9901 - val_loss: 0.2111 - val_acc: 0.9931\n","Epoch 8/100\n","870/870 [==============================] - 0s 65us/sample - loss: 0.1829 - acc: 0.9920\n","29/29 [==============================] - 2s 83ms/step - loss: 0.0314 - acc: 0.9899 - val_loss: 0.1815 - val_acc: 0.9920\n","Epoch 9/100\n","870/870 [==============================] - 0s 76us/sample - loss: 0.1340 - acc: 0.9954\n","29/29 [==============================] - 3s 88ms/step - loss: 0.0315 - acc: 0.9892 - val_loss: 0.1333 - val_acc: 0.9954\n","Epoch 10/100\n","870/870 [==============================] - 0s 63us/sample - loss: 0.1350 - acc: 0.9885\n","29/29 [==============================] - 2s 85ms/step - loss: 0.0329 - acc: 0.9900 - val_loss: 0.1350 - val_acc: 0.9885\n","Epoch 11/100\n","870/870 [==============================] - 0s 70us/sample - loss: 0.1048 - acc: 0.9931\n","29/29 [==============================] - 2s 84ms/step - loss: 0.0295 - acc: 0.9912 - val_loss: 0.1045 - val_acc: 0.9931\n","Epoch 12/100\n","870/870 [==============================] - 0s 64us/sample - loss: 0.0946 - acc: 0.9931\n","29/29 [==============================] - 16s 553ms/step - loss: 0.0285 - acc: 0.9922 - val_loss: 0.0940 - val_acc: 0.9931\n","Epoch 13/100\n","870/870 [==============================] - 0s 63us/sample - loss: 0.0663 - acc: 0.9943\n","29/29 [==============================] - 2s 65ms/step - loss: 0.0248 - acc: 0.9917 - val_loss: 0.0662 - val_acc: 0.9943\n","Epoch 14/100\n","870/870 [==============================] - 0s 78us/sample - loss: 0.0518 - acc: 0.9954\n","29/29 [==============================] - 2s 86ms/step - loss: 0.0271 - acc: 0.9917 - val_loss: 0.0517 - val_acc: 0.9954\n","Epoch 1/100\n","870/870 [==============================] - 2s 3ms/sample - loss: 0.5129 - acc: 0.9425\n","29/29 [==============================] - 28s 963ms/step - loss: 0.9504 - acc: 0.8120 - val_loss: 0.5132 - val_acc: 0.9425\n","Epoch 2/100\n","870/870 [==============================] - 0s 80us/sample - loss: 0.4584 - acc: 0.9655\n","29/29 [==============================] - 2s 68ms/step - loss: 0.1039 - acc: 0.9685 - val_loss: 0.4588 - val_acc: 0.9655\n","Epoch 3/100\n","870/870 [==============================] - 0s 67us/sample - loss: 0.4340 - acc: 0.9839\n","29/29 [==============================] - 3s 92ms/step - loss: 0.0682 - acc: 0.9766 - val_loss: 0.4338 - val_acc: 0.9839\n","Epoch 4/100\n","870/870 [==============================] - 0s 76us/sample - loss: 0.3728 - acc: 0.9563\n","29/29 [==============================] - 3s 92ms/step - loss: 0.0564 - acc: 0.9850 - val_loss: 0.3742 - val_acc: 0.9563\n","Epoch 5/100\n","870/870 [==============================] - 0s 86us/sample - loss: 0.2714 - acc: 0.9839\n","29/29 [==============================] - 3s 92ms/step - loss: 0.0375 - acc: 0.9873 - val_loss: 0.2721 - val_acc: 0.9839\n","Epoch 6/100\n","870/870 [==============================] - 0s 79us/sample - loss: 0.2903 - acc: 0.9828\n","29/29 [==============================] - 16s 564ms/step - loss: 0.0444 - acc: 0.9859 - val_loss: 0.2909 - val_acc: 0.9828\n","Epoch 7/100\n","870/870 [==============================] - 0s 78us/sample - loss: 0.2348 - acc: 0.9862\n","29/29 [==============================] - 2s 70ms/step - loss: 0.0361 - acc: 0.9878 - val_loss: 0.2354 - val_acc: 0.9862\n","Epoch 8/100\n","870/870 [==============================] - 0s 71us/sample - loss: 0.2011 - acc: 0.9839\n","29/29 [==============================] - 3s 90ms/step - loss: 0.0314 - acc: 0.9903 - val_loss: 0.2020 - val_acc: 0.9839\n","Epoch 9/100\n","870/870 [==============================] - 0s 69us/sample - loss: 0.1498 - acc: 0.9897\n","29/29 [==============================] - 3s 96ms/step - loss: 0.0278 - acc: 0.9911 - val_loss: 0.1505 - val_acc: 0.9897\n","Epoch 10/100\n","870/870 [==============================] - 0s 72us/sample - loss: 0.1385 - acc: 0.9908\n","29/29 [==============================] - 3s 89ms/step - loss: 0.0317 - acc: 0.9912 - val_loss: 0.1383 - val_acc: 0.9908\n","Epoch 11/100\n","870/870 [==============================] - 0s 68us/sample - loss: 0.0980 - acc: 0.9851\n","29/29 [==============================] - 2s 84ms/step - loss: 0.0289 - acc: 0.9901 - val_loss: 0.0995 - val_acc: 0.9851\n","Epoch 12/100\n","870/870 [==============================] - 0s 64us/sample - loss: 0.0702 - acc: 0.9897\n","29/29 [==============================] - 2s 84ms/step - loss: 0.0282 - acc: 0.9912 - val_loss: 0.0715 - val_acc: 0.9897\n","Epoch 13/100\n","870/870 [==============================] - 0s 70us/sample - loss: 0.0457 - acc: 0.9943\n","29/29 [==============================] - 3s 88ms/step - loss: 0.0260 - acc: 0.9923 - val_loss: 0.0465 - val_acc: 0.9943\n","Epoch 14/100\n","870/870 [==============================] - 0s 72us/sample - loss: 0.0400 - acc: 0.9931\n","29/29 [==============================] - 2s 85ms/step - loss: 0.0294 - acc: 0.9907 - val_loss: 0.0409 - val_acc: 0.9931\n","Epoch 15/100\n","870/870 [==============================] - 0s 69us/sample - loss: 0.0360 - acc: 0.9954\n","29/29 [==============================] - 3s 88ms/step - loss: 0.0236 - acc: 0.9917 - val_loss: 0.0365 - val_acc: 0.9954\n","Epoch 16/100\n","870/870 [==============================] - 0s 68us/sample - loss: 0.0316 - acc: 0.9931\n","29/29 [==============================] - 2s 84ms/step - loss: 0.0230 - acc: 0.9926 - val_loss: 0.0319 - val_acc: 0.9931\n","Epoch 17/100\n","870/870 [==============================] - 0s 69us/sample - loss: 0.0378 - acc: 0.9908\n","29/29 [==============================] - 3s 89ms/step - loss: 0.0236 - acc: 0.9931 - val_loss: 0.0388 - val_acc: 0.9908\n","Epoch 18/100\n","870/870 [==============================] - 0s 79us/sample - loss: 0.0258 - acc: 0.9966\n","29/29 [==============================] - 3s 95ms/step - loss: 0.0283 - acc: 0.9913 - val_loss: 0.0259 - val_acc: 0.9966\n","Epoch 19/100\n","870/870 [==============================] - 0s 82us/sample - loss: 0.0185 - acc: 0.9943\n","29/29 [==============================] - 3s 89ms/step - loss: 0.0227 - acc: 0.9919 - val_loss: 0.0196 - val_acc: 0.9943\n","Epoch 20/100\n","870/870 [==============================] - 0s 80us/sample - loss: 0.0216 - acc: 0.9931\n","29/29 [==============================] - 3s 92ms/step - loss: 0.0234 - acc: 0.9915 - val_loss: 0.0208 - val_acc: 0.9931\n","Epoch 21/100\n","870/870 [==============================] - 0s 84us/sample - loss: 0.0190 - acc: 0.9931\n","29/29 [==============================] - 3s 93ms/step - loss: 0.0232 - acc: 0.9926 - val_loss: 0.0188 - val_acc: 0.9931\n","Epoch 22/100\n","870/870 [==============================] - 0s 81us/sample - loss: 0.0183 - acc: 0.9966\n","29/29 [==============================] - 3s 95ms/step - loss: 0.0243 - acc: 0.9927 - val_loss: 0.0174 - val_acc: 0.9966\n","Epoch 23/100\n","870/870 [==============================] - 0s 79us/sample - loss: 0.0163 - acc: 0.9954\n","29/29 [==============================] - 3s 91ms/step - loss: 0.0199 - acc: 0.9936 - val_loss: 0.0155 - val_acc: 0.9954\n","Epoch 1/100\n","870/870 [==============================] - 2s 3ms/sample - loss: 0.5067 - acc: 0.9678\n","29/29 [==============================] - 28s 966ms/step - loss: 0.5411 - acc: 0.7870 - val_loss: 0.5064 - val_acc: 0.9678\n","Epoch 2/100\n","870/870 [==============================] - 0s 69us/sample - loss: 0.4437 - acc: 0.9885\n","29/29 [==============================] - 2s 72ms/step - loss: 0.0824 - acc: 0.9735 - val_loss: 0.4430 - val_acc: 0.9885\n","Epoch 3/100\n","870/870 [==============================] - 0s 68us/sample - loss: 0.3869 - acc: 0.9920\n","29/29 [==============================] - 3s 94ms/step - loss: 0.0559 - acc: 0.9819 - val_loss: 0.3859 - val_acc: 0.9920\n","Epoch 4/100\n","870/870 [==============================] - 0s 75us/sample - loss: 0.3409 - acc: 0.9897\n","29/29 [==============================] - 3s 88ms/step - loss: 0.0507 - acc: 0.9848 - val_loss: 0.3401 - val_acc: 0.9897\n","Epoch 5/100\n","870/870 [==============================] - 0s 74us/sample - loss: 0.3191 - acc: 0.9885\n","29/29 [==============================] - 3s 88ms/step - loss: 0.0451 - acc: 0.9859 - val_loss: 0.3185 - val_acc: 0.9885\n","Epoch 6/100\n","870/870 [==============================] - 0s 73us/sample - loss: 0.2561 - acc: 0.9885\n","29/29 [==============================] - 17s 582ms/step - loss: 0.0403 - acc: 0.9882 - val_loss: 0.2547 - val_acc: 0.9885\n","Epoch 7/100\n","870/870 [==============================] - 0s 84us/sample - loss: 0.2306 - acc: 0.9897\n","29/29 [==============================] - 2s 66ms/step - loss: 0.0347 - acc: 0.9896 - val_loss: 0.2305 - val_acc: 0.9897\n","Epoch 8/100\n","870/870 [==============================] - 0s 82us/sample - loss: 0.1807 - acc: 0.9920\n","29/29 [==============================] - 3s 91ms/step - loss: 0.0295 - acc: 0.9912 - val_loss: 0.1805 - val_acc: 0.9920\n","Epoch 1/100\n","870/870 [==============================] - 3s 3ms/sample - loss: 0.5050 - acc: 0.9690\n","29/29 [==============================] - 29s 987ms/step - loss: 0.6829 - acc: 0.7913 - val_loss: 0.5048 - val_acc: 0.9690\n","Epoch 2/100\n","870/870 [==============================] - 0s 68us/sample - loss: 0.4715 - acc: 0.9793\n","29/29 [==============================] - 2s 72ms/step - loss: 0.0868 - acc: 0.9691 - val_loss: 0.4715 - val_acc: 0.9793\n","Epoch 3/100\n","870/870 [==============================] - 0s 69us/sample - loss: 0.4154 - acc: 0.9793\n","29/29 [==============================] - 3s 91ms/step - loss: 0.0705 - acc: 0.9766 - val_loss: 0.4157 - val_acc: 0.9793\n","Epoch 4/100\n","870/870 [==============================] - 0s 67us/sample - loss: 0.3851 - acc: 0.9747\n","29/29 [==============================] - 3s 91ms/step - loss: 0.0499 - acc: 0.9831 - val_loss: 0.3854 - val_acc: 0.9747\n","Epoch 5/100\n","870/870 [==============================] - 0s 66us/sample - loss: 0.2854 - acc: 0.9897\n","29/29 [==============================] - 3s 95ms/step - loss: 0.0380 - acc: 0.9894 - val_loss: 0.2850 - val_acc: 0.9897\n","Epoch 6/100\n","870/870 [==============================] - 0s 67us/sample - loss: 0.2720 - acc: 0.9920\n","29/29 [==============================] - 3s 94ms/step - loss: 0.0395 - acc: 0.9880 - val_loss: 0.2718 - val_acc: 0.9920\n","Epoch 7/100\n","870/870 [==============================] - 0s 70us/sample - loss: 0.2004 - acc: 0.9885\n","29/29 [==============================] - 3s 92ms/step - loss: 0.0357 - acc: 0.9890 - val_loss: 0.2009 - val_acc: 0.9885\n","Epoch 8/100\n","870/870 [==============================] - 0s 64us/sample - loss: 0.2064 - acc: 0.9943\n","29/29 [==============================] - 3s 96ms/step - loss: 0.0418 - acc: 0.9876 - val_loss: 0.2056 - val_acc: 0.9943\n","Epoch 9/100\n","870/870 [==============================] - 0s 67us/sample - loss: 0.1505 - acc: 0.9920\n","29/29 [==============================] - 3s 92ms/step - loss: 0.0341 - acc: 0.9892 - val_loss: 0.1505 - val_acc: 0.9920\n","Epoch 10/100\n","870/870 [==============================] - 0s 69us/sample - loss: 0.1754 - acc: 0.9943\n","29/29 [==============================] - 3s 92ms/step - loss: 0.0384 - acc: 0.9881 - val_loss: 0.1752 - val_acc: 0.9943\n","Epoch 11/100\n","870/870 [==============================] - 0s 75us/sample - loss: 0.1072 - acc: 0.9954\n","29/29 [==============================] - 3s 94ms/step - loss: 0.0341 - acc: 0.9907 - val_loss: 0.1070 - val_acc: 0.9954\n","Epoch 12/100\n","870/870 [==============================] - 0s 96us/sample - loss: 0.0669 - acc: 0.9954\n","29/29 [==============================] - 3s 98ms/step - loss: 0.0319 - acc: 0.9897 - val_loss: 0.0669 - val_acc: 0.9954\n","Epoch 13/100\n","870/870 [==============================] - 0s 74us/sample - loss: 0.0715 - acc: 0.9897\n","29/29 [==============================] - 3s 91ms/step - loss: 0.0307 - acc: 0.9904 - val_loss: 0.0735 - val_acc: 0.9897\n","Epoch 14/100\n","870/870 [==============================] - 0s 84us/sample - loss: 0.0730 - acc: 0.9931\n","29/29 [==============================] - 17s 589ms/step - loss: 0.0314 - acc: 0.9900 - val_loss: 0.0720 - val_acc: 0.9931\n","Epoch 15/100\n","870/870 [==============================] - 0s 67us/sample - loss: 0.0367 - acc: 0.9966\n","29/29 [==============================] - 2s 72ms/step - loss: 0.0230 - acc: 0.9928 - val_loss: 0.0370 - val_acc: 0.9966\n","Epoch 16/100\n","870/870 [==============================] - 0s 75us/sample - loss: 0.0440 - acc: 0.9874\n","29/29 [==============================] - 3s 91ms/step - loss: 0.0227 - acc: 0.9931 - val_loss: 0.0420 - val_acc: 0.9874\n","Epoch 17/100\n","870/870 [==============================] - 0s 73us/sample - loss: 0.0237 - acc: 0.9954\n","29/29 [==============================] - 3s 92ms/step - loss: 0.0243 - acc: 0.9920 - val_loss: 0.0235 - val_acc: 0.9954\n","Epoch 18/100\n","870/870 [==============================] - 0s 70us/sample - loss: 0.0252 - acc: 0.9943\n","29/29 [==============================] - 3s 90ms/step - loss: 0.0199 - acc: 0.9954 - val_loss: 0.0260 - val_acc: 0.9943\n","Epoch 19/100\n","870/870 [==============================] - 0s 64us/sample - loss: 0.0181 - acc: 0.9966\n","29/29 [==============================] - 3s 91ms/step - loss: 0.0212 - acc: 0.9946 - val_loss: 0.0185 - val_acc: 0.9966\n","Epoch 20/100\n","870/870 [==============================] - 0s 80us/sample - loss: 0.0157 - acc: 0.9966\n","29/29 [==============================] - 3s 89ms/step - loss: 0.0192 - acc: 0.9949 - val_loss: 0.0165 - val_acc: 0.9966\n"],"name":"stdout"}]},{"metadata":{"id":"dwwIW90u7Qe5","colab_type":"code","outputId":"7cf3f91f-21d4-48b9-e4b4-e35d78e79b82","executionInfo":{"status":"ok","timestamp":1551264249285,"user_tz":-180,"elapsed":744,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}},"colab":{"base_uri":"https://localhost:8080/","height":289}},"cell_type":"code","source":["\n","#p = predictions\n","\n","print(np.count_nonzero(predictions==4))\n","print(np.count_nonzero(predictions==9))\n","p = np.copy(predictions)\n","print(p[ix[0]])\n","print(pred49)\n","p[ix[0]] = pred49\n","print(np.count_nonzero(p==4))\n","print(np.count_nonzero(p==9))\n","\n","print(np.array_equal(predictions,p))\n","print(np.array_equal(p[ix[0]],pred49))\n","print(predictions[0:10])\n","print(p[0:10])\n","params\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2760\n","2763\n","[9 4 4 ... 9 9 9]\n","[9 4 4 ... 9 9 9]\n","2747\n","2776\n","False\n","True\n","[2 0 9 0 3 7 0 3 0 3]\n","[2 0 9 0 3 7 0 3 0 3]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'activation': 'relu',\n"," 'batch_size': 256,\n"," 'drop1': 0.5,\n"," 'drop2': 0.4,\n"," 'nb_neurons': 192,\n"," 'optimizer': 'nadam'}"]},"metadata":{"tags":[]},"execution_count":162}]},{"metadata":{"id":"_tHEf77hjk7G","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"W3XFskeu8A9y","colab_type":"text"},"cell_type":"markdown","source":["#Готовим файл с решением для Kaggle"]},{"metadata":{"id":"RLuN-yIb7tsU","colab_type":"code","outputId":"890c4452-781f-4eb3-9e1b-dfe79c9dafd5","executionInfo":{"status":"ok","timestamp":1551264310672,"user_tz":-180,"elapsed":2441,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"cell_type":"code","source":["out = np.column_stack((range(1, predictions.shape[0]+1), predictions))\n","np.savetxt('submission.csv', out, header=\"ImageId,Label\", comments=\"\", fmt=\"%d,%d\")\n","!head submission.csv"],"execution_count":0,"outputs":[{"output_type":"stream","text":["ImageId,Label\n","1,2\n","2,0\n","3,9\n","4,0\n","5,3\n","6,7\n","7,0\n","8,3\n","9,0\n"],"name":"stdout"}]},{"metadata":{"id":"6nxk7-3-811y","colab_type":"text"},"cell_type":"markdown","source":["#Отправляем решение "]},{"metadata":{"id":"DrRIqKEQ8dtX","colab_type":"code","outputId":"cd937c04-7aee-45d1-fa38-6c2e65d5bc8e","executionInfo":{"status":"ok","timestamp":1551264338128,"user_tz":-180,"elapsed":16009,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"cell_type":"code","source":["!kaggle competitions submit -c digit-recognizer -m \"Submition from Colab\" -f submission.csv"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100% 208k/208k [00:10<00:00, 19.9kB/s]\n","Successfully submitted to Digit Recognizer"],"name":"stdout"}]},{"metadata":{"id":"mXHGK7Sw_KPE","colab_type":"text"},"cell_type":"markdown","source":["#Результат модели с учетом коррекции ошибок неправильно распознанных классов 0.99571"]},{"metadata":{"id":"XQClPDuMBmY5","colab_type":"text"},"cell_type":"markdown","source":["#решение первоначальной модели без учета коррекции, результат 0.99557\n"]},{"metadata":{"id":"WDaQKoYc_Y9R","colab_type":"code","outputId":"02831d42-7558-437b-aa9f-2178cd635273","executionInfo":{"status":"ok","timestamp":1551254834676,"user_tz":-180,"elapsed":5704,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"cell_type":"code","source":["predictions = visualizer.estimator.model.predict_classes(x_test)\n","out = np.column_stack((range(1, predictions.shape[0]+1), predictions))\n","np.savetxt('submission.csv', out, header=\"ImageId,Label\", comments=\"\", fmt=\"%d,%d\")\n","!head submission.csv\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["ImageId,Label\n","1,2\n","2,0\n","3,9\n","4,0\n","5,3\n","6,7\n","7,0\n","8,3\n","9,0\n"],"name":"stdout"}]},{"metadata":{"id":"wq1eMMv3_goF","colab_type":"code","outputId":"b2d8e135-6f42-47e9-e85b-84a6a82fb954","executionInfo":{"status":"ok","timestamp":1551254923042,"user_tz":-180,"elapsed":16534,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"cell_type":"code","source":["!kaggle competitions submit -c digit-recognizer -m \"Submition from Colab\" -f submission.csv"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100% 208k/208k [00:11<00:00, 18.7kB/s]\n","Successfully submitted to Digit Recognizer"],"name":"stdout"}]},{"metadata":{"id":"QfHsTYdpkfQK","colab_type":"text"},"cell_type":"markdown","source":["#Вывод\n","Для распознавание mnist была взята сверточная сеть, структура находится в процедуре create_model.  Произвел подбор гиперпараметров сети в помощью библиотеки hyperopt. Лучший результат дала модель с параметрами params = {'activation': 'relu', 'batch_size': 256, 'drop1': 0.5, 'drop2': 0.4, 'nb_neurons': 128, 'optimizer': 'nadam'}\n","\n","\n","На основе ошибок модели на тренировочных данных произведена попытка предсказывать чаcть классов отдельными моделями под каждый набор неправильно классифицируемых классов.\n","оптимизированная модель неправильно классифицирует 1 классом 7, а также неправильно распознаются между собой классы 4 и 9\n","Отдельно натренированные на данных классах модели дали небольшое улучшение 0.99571 против 0.9957, для тестовых данных на kaggle liderboard\n","\n","Данный метод можно использовать в дальнейшем для улучшения кач-ва распознавания. \n","\n","В целях улучшения данного метода также можно произвести оптимизацию гиперпараметров отдельных моделей.\n","\n","Также не успел пропробовать стандартизацию входных данных, кастомная имплементацию дропаут https://github.com/andry9454/KerasDropconnect , не произвел подбор глубины сети. \n","\n","На kaggle удалось достичь 220 места.\n"]},{"metadata":{"id":"MN_v4IXuDLCV","colab_type":"code","colab":{}},"cell_type":"code","source":["!pip3 list\n"],"execution_count":0,"outputs":[]}]}