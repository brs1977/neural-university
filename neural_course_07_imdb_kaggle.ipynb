{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"neural_course_07_imdb_kaggle.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":["ugC7AEiiG92s"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"FPxvQy87QeZ_","colab_type":"code","outputId":"4ffdc807-e0c8-415f-c8f5-8698518715dc","executionInfo":{"status":"ok","timestamp":1560919922867,"user_tz":-180,"elapsed":24094,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive, files\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dLTJ8zAcPHMQ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P7Tr-eFEFXdG","colab_type":"text"},"source":["#Import"]},{"cell_type":"code","metadata":{"id":"Lmbet41ZFWkO","colab_type":"code","colab":{}},"source":["from tensorflow.keras.datasets import imdb\n","from tensorflow.keras.models import Sequential, load_model, Model\n","from tensorflow.keras.layers import Input, Dense, Dropout, Embedding, Activation, LSTM, GRU, SpatialDropout1D, Flatten, Bidirectional, CuDNNGRU, CuDNNLSTM, GlobalMaxPool1D, Layer, BatchNormalization, TimeDistributed\n","\n","from tensorflow.keras import utils,initializers,regularizers,constraints,activations\n","from tensorflow.keras.preprocessing import sequence\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n","import numpy as np\n","import math\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_UT98KtNE-aZ","colab_type":"text"},"source":["#Kaggle, load data"]},{"cell_type":"code","metadata":{"id":"kGd9Dr0JRzf6","colab_type":"code","outputId":"0995ee71-686b-4c01-a34a-ff091d735fbe","executionInfo":{"status":"ok","timestamp":1560919958770,"user_tz":-180,"elapsed":11033,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["!mkdir ~/.kaggle\n","!cp /content/drive/My\\ Drive/kaggle.json ~/.kaggle\n","!ls ~/.kaggle\n","\n","#Загружаем данные с сайта Kaggle\n","\n","!kaggle competitions download -c neural-university-imdb-spring2019\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["kaggle.json\n","Downloading imdb_sample_submission.csv to /content\n","  0% 0.00/77.1k [00:00<?, ?B/s]\n","100% 77.1k/77.1k [00:00<00:00, 31.9MB/s]\n","Downloading imdb_test.npy.zip to /content\n","  0% 0.00/3.31M [00:00<?, ?B/s]\n","100% 3.31M/3.31M [00:00<00:00, 108MB/s]\n","Downloading imdb_train.npz.zip to /content\n"," 68% 9.00M/13.3M [00:00<00:00, 17.5MB/s]\n","100% 13.3M/13.3M [00:00<00:00, 24.7MB/s]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vMfd8W_VS2Dd","colab_type":"code","outputId":"863c2c14-d06c-40c6-e090-ccbb988d7f3a","executionInfo":{"status":"ok","timestamp":1560919962099,"user_tz":-180,"elapsed":10483,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["!unzip imdb_test.npy.zip\n","!unzip imdb_train.npz.zip"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Archive:  imdb_test.npy.zip\n","  inflating: imdb_test.npy           \n","Archive:  imdb_train.npz.zip\n","  inflating: imdb_train.npz          \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"V_SAGHaYTLuz","colab_type":"code","outputId":"62461206-4dee-453d-ebcf-8a9ee7cc6baa","executionInfo":{"status":"ok","timestamp":1560920321015,"user_tz":-180,"elapsed":3625,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["data = np.load('imdb_train.npz', allow_pickle=True) \n","train_x = data['x'] \n","train_y = data['y']\n","\n","test_x = np.load('imdb_test.npy', allow_pickle=True)\n","\n","maxlen = 1000\n","train_X = pad_sequences(train_x, maxlen=maxlen)\n","test_X = pad_sequences(test_x, maxlen=maxlen)\n","\n","word_index = imdb.get_word_index()\n","index_word = {v: k for k, v in word_index.items()}"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n","1646592/1641221 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"D04_mXyfTLxs","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nWOV9tgPTL0t","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UgvLDWiEUAwc","colab_type":"text"},"source":["##GloVe"]},{"cell_type":"code","metadata":{"id":"-CVFFhVyUAHM","colab_type":"code","outputId":"c2ced7eb-66c6-4d99-b98d-0d153d94ca03","executionInfo":{"status":"ok","timestamp":1560920122596,"user_tz":-180,"elapsed":59254,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}},"colab":{"base_uri":"https://localhost:8080/","height":442}},"source":["!wget http://nlp.stanford.edu/data/glove.6B.zip\n","!unzip glove.6B.zip  "],"execution_count":5,"outputs":[{"output_type":"stream","text":["--2019-06-19 04:54:24--  http://nlp.stanford.edu/data/glove.6B.zip\n","Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n","--2019-06-19 04:54:24--  https://nlp.stanford.edu/data/glove.6B.zip\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n","--2019-06-19 04:54:25--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n","Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n","Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 862182613 (822M) [application/zip]\n","Saving to: ‘glove.6B.zip’\n","\n","glove.6B.zip        100%[===================>] 822.24M  25.8MB/s    in 33s     \n","\n","2019-06-19 04:54:58 (25.0 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n","\n","Archive:  glove.6B.zip\n","  inflating: glove.6B.50d.txt        \n","  inflating: glove.6B.100d.txt       \n","  inflating: glove.6B.200d.txt       \n","  inflating: glove.6B.300d.txt       \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zc_mG9HUTL3T","colab_type":"code","colab":{}},"source":["def glove_embedings(embedding_len):\n","  from tqdm import tqdm\n","  import os, re, csv, math, codecs\n","\n","  #load embeddings\n","  print('loading word embeddings...')\n","  embeddings_index = {}\n","  f = codecs.open('glove.6B.{}d.txt'.format(embedding_len), encoding='utf-8')\n","  for line in tqdm(f):\n","    values = line.split()\n","    word = values[0]\n","    coefs = np.asarray(values[1:], dtype='float32')\n","    embeddings_index[word] = coefs\n","  f.close()\n","  print('found %s word vectors' % len(embeddings_index))\n","  return embeddings_index\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U4329V8sYEPX","colab_type":"code","outputId":"d38d098c-3947-4440-b5c9-938a2cef168a","executionInfo":{"status":"ok","timestamp":1560920373141,"user_tz":-180,"elapsed":41727,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["num_words = 20000\n","embedding_len = 300\n","embeddings_index = glove_embedings(embedding_len)\n","\n","embedding_matrix = np.zeros((num_words, embedding_len))\n","for word, i in word_index.items():\n","    if i < num_words - 3:\n","        embedding_vector = embeddings_index.get(word)\n","        if embedding_vector is not None:\n","            embedding_matrix[i + 3] = embedding_vector"],"execution_count":14,"outputs":[{"output_type":"stream","text":["962it [00:00, 9615.52it/s]"],"name":"stderr"},{"output_type":"stream","text":["loading word embeddings...\n"],"name":"stdout"},{"output_type":"stream","text":["400000it [00:40, 9851.02it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["found 400000 word vectors\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"f02LCy4hFidl","colab_type":"text"},"source":["#AttentionWithContext class"]},{"cell_type":"code","metadata":{"id":"4Kb6aM3UwKJw","colab_type":"code","colab":{}},"source":["#https://gist.github.com/iridiumblue/622a9525189d48e9c00659fea269bfa4\n","\n","# AttentionWithContext adapted for Tensorflow 1.13 with Eager Execution.\n","# IMPORTANT -you can't use regular keras optimizers.  You need to grab one that is subclassed from \n","# tf.train.Optimizer.   Not to worry, your favorite is probably there, for example - \n","# https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer\n","\n","# That's it, now you can use this layer - \n","# Adapted from https://gist.github.com/cbaziotis/7ef97ccf71cbc14366835198c09809d2\n","\n","# Tested using functional API.   Just plop on top of an RNN, like so - \n","\n","# x = Embedding(*embedding_matrix.shape, weights=[embedding_matrix], input_length=max_topic_length, trainable=False)(inputs)\n","# x1 = LSTM(return_sequences=True)(x)\n","# c1 = AttentionWithContext()(x1)\n","\n","import tensorflow as tf\n","from tensorflow.keras import initializers \n","from tensorflow.keras import regularizers\n","from tensorflow.keras import constraints\n","\n","from tensorflow.keras import activations \n","from tensorflow.keras import backend as K\n","\n","from tensorflow.keras.layers import Layer\n","\n","class AttentionWithContext(Layer):\n","    \"\"\"\n","        Attention operation, with a context/query vector, for temporal data.\n","        Supports Masking.\n","        Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n","        \"Hierarchical Attention Networks for Document Classification\"\n","        by using a context vector to assist the attention\n","        # Input shape\n","            3D tensor with shape: `(samples, steps, features)`.\n","        # Output shape\n","            2D tensor with shape: `(samples, features)`.\n","        :param kwargs:\n","        Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n","        The dimensions are inferred based on the output shape of the RNN.\n","        Example:\n","            model.add(LSTM(64, return_sequences=True))\n","            model.add(AttentionWithContext())\n","        \"\"\"\n","\n","    def __init__(self,\n","                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n","                 W_constraint=None, u_constraint=None, b_constraint=None,\n","                 bias=True,\n","                 return_attention=False, **kwargs):\n","\n","        self.supports_masking = True\n","        self.return_attention = return_attention\n","        self.init = initializers.get('glorot_uniform')\n","\n","        self.W_regularizer = regularizers.get(W_regularizer)\n","        self.u_regularizer = regularizers.get(u_regularizer)\n","        self.b_regularizer = regularizers.get(b_regularizer)\n","\n","        self.W_constraint = constraints.get(W_constraint)\n","        self.u_constraint = constraints.get(u_constraint)\n","        self.b_constraint = constraints.get(b_constraint)\n","\n","        self.bias = bias\n","        super(AttentionWithContext, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        assert len(input_shape) == 3\n","        input_shape_list = input_shape.as_list()\n","\n","        self.W = self.add_weight(shape=((input_shape_list[-1], input_shape_list[-1])),\n","                                 initializer=self.init,\n","                                 name='{}_W'.format(self.name),\n","                                 regularizer=self.W_regularizer,\n","                                 constraint=self.W_constraint)\n","        if self.bias:\n","            self.b = self.add_weight(shape=(input_shape_list[-1],),\n","                                     initializer='zero',\n","                                     name='{}_b'.format(self.name),\n","                                     regularizer=self.b_regularizer,\n","                                     constraint=self.b_constraint)\n","\n","        self.u = self.add_weight(shape=(input_shape_list[-1],),\n","                                 initializer=self.init,\n","                                 name='{}_u'.format(self.name),\n","                                 regularizer=self.u_regularizer,\n","                                 constraint=self.u_constraint)\n","\n","        super(AttentionWithContext, self).build(input_shape.as_list())\n","\n","    def compute_mask(self, input, input_mask=None):\n","        # do not pass the mask to the next layers\n","        return None\n","\n","    def call(self, x, mask=None):\n","        uit = tf.tensordot(x, self.W,axes=1)\n","\n","        if self.bias:\n","            uit += self.b\n","\n","        uit = activations.tanh(uit)\n","        # ait = K.dot(uit, self.u)\n","        ait = tf.tensordot(uit, self.u,axes=1)\n","\n","        a = activations.exponential(ait)\n","\n","        # apply mask after the exp. will be re-normalized next\n","        if mask is not None:\n","            # Cast the mask to floatX to avoid float64 upcasting in theano\n","            a *= tf.cast(mask, K.floatx())\n","\n","        # in some cases especially in the early stages of training the sum may be almost zero\n","        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n","        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n","        a /= tf.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n","\n","        a = K.expand_dims(a)\n","        weighted_input = x * a\n","        result = K.sum(weighted_input, axis=1)\n","\n","        if self.return_attention:\n","            return [result, a]\n","        return result\n","\n","    def compute_output_shape(self, input_shape):\n","        if self.return_attention:\n","            #TODO use TensorShape here, as done in the else statement.   I'm not sure\n","            # if this is returning a single tensor, or a list of two so leaving this undone for now.  Suspect this will\n","            # need to complete if using Sequential rather than Functional API\n","            return [(input_shape[0], input_shape[-1]),\n","                    (input_shape[0], input_shape[1])]\n","        else:\n","            return tf.TensorShape([input_shape[0].value,input_shape[-1].value])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jiEII9toYjC2","colab_type":"code","colab":{}},"source":["!ls /content/drive/'My Drive'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_J8UxQpwF7ny","colab_type":"text"},"source":["#Model"]},{"cell_type":"code","metadata":{"id":"1m4vvvTkF5bg","colab_type":"code","colab":{}},"source":["from tensorflow.keras.layers import RepeatVector, Permute, Multiply, Lambda\n","from tensorflow.keras import backend as K\n","\n","def create_model(params):\n","  model = Sequential()\n","  model.add(Embedding(num_words, embedding_len, weights=[embedding_matrix]))\n","  model.add(SpatialDropout1D(0.4))\n","  model.add(Bidirectional(CuDNNLSTM(params['units'], return_sequences=True)))\n","  model.add(AttentionWithContext())\n","  model.add(Dropout(0.3))\n","  model.add(BatchNormalization())\n","  model.add(Dense(1, activation=\"sigmoid\"))\n","  model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n","\n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zAkKm5y5GBcj","colab_type":"text"},"source":["#Fit"]},{"cell_type":"code","metadata":{"id":"3JUxAp4mGAZo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1054},"outputId":"d166f50d-72cf-4cf5-bd1e-941270b8d665","executionInfo":{"status":"ok","timestamp":1560924857844,"user_tz":-180,"elapsed":4497059,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}}},"source":["params = {'units': 256, 'lr': .002, 'drop_lr': .75 }\n","model = create_model(params)\n","\n","#model.load_weights('nlp.hfd5')\n","сheckpoint = ModelCheckpoint('nlp.hfd5', monitor='val_acc', save_best_only=True, verbose=0)\n","def step_decay(epoch):\n","  initial_lrate = params['lr']\n","  drop = params['drop_lr']\n","  epochs_drop = 1\n","  lrate = initial_lrate * math.pow(drop,math.floor((1+epoch)/epochs_drop))\n","  return lrate    \n","lrate = LearningRateScheduler (step_decay,verbose=0)\n","\n","\n","history = model.fit(train_X, \n","                    train_y, \n","                    epochs=30,\n","                    batch_size=128,\n","                    callbacks = [lrate,сheckpoint],\n","                    validation_split=0.1,\n","                    verbose=1)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Train on 36000 samples, validate on 4000 samples\n","Epoch 1/30\n","36000/36000 [==============================] - 151s 4ms/sample - loss: 0.5416 - acc: 0.6865 - val_loss: 0.4141 - val_acc: 0.8687\n","Epoch 2/30\n","36000/36000 [==============================] - 149s 4ms/sample - loss: 0.2466 - acc: 0.8992 - val_loss: 0.2036 - val_acc: 0.9195\n","Epoch 3/30\n","36000/36000 [==============================] - 150s 4ms/sample - loss: 0.1959 - acc: 0.9233 - val_loss: 0.2016 - val_acc: 0.9240\n","Epoch 4/30\n","36000/36000 [==============================] - 149s 4ms/sample - loss: 0.1670 - acc: 0.9348 - val_loss: 0.2058 - val_acc: 0.9268\n","Epoch 5/30\n","36000/36000 [==============================] - 150s 4ms/sample - loss: 0.1478 - acc: 0.9441 - val_loss: 0.1987 - val_acc: 0.9280\n","Epoch 6/30\n","36000/36000 [==============================] - 149s 4ms/sample - loss: 0.1322 - acc: 0.9524 - val_loss: 0.1908 - val_acc: 0.9287\n","Epoch 7/30\n","36000/36000 [==============================] - 150s 4ms/sample - loss: 0.1213 - acc: 0.9556 - val_loss: 0.1994 - val_acc: 0.9327\n","Epoch 8/30\n","36000/36000 [==============================] - 149s 4ms/sample - loss: 0.1128 - acc: 0.9584 - val_loss: 0.2096 - val_acc: 0.9320\n","Epoch 9/30\n","36000/36000 [==============================] - 149s 4ms/sample - loss: 0.1058 - acc: 0.9629 - val_loss: 0.1994 - val_acc: 0.9310\n","Epoch 10/30\n","36000/36000 [==============================] - 149s 4ms/sample - loss: 0.1012 - acc: 0.9644 - val_loss: 0.2122 - val_acc: 0.9315\n","Epoch 11/30\n","36000/36000 [==============================] - 149s 4ms/sample - loss: 0.0972 - acc: 0.9645 - val_loss: 0.2085 - val_acc: 0.9310\n","Epoch 12/30\n","36000/36000 [==============================] - 150s 4ms/sample - loss: 0.0944 - acc: 0.9663 - val_loss: 0.2123 - val_acc: 0.9308\n","Epoch 13/30\n","36000/36000 [==============================] - 149s 4ms/sample - loss: 0.0921 - acc: 0.9678 - val_loss: 0.2150 - val_acc: 0.9312\n","Epoch 14/30\n","36000/36000 [==============================] - 149s 4ms/sample - loss: 0.0880 - acc: 0.9692 - val_loss: 0.2198 - val_acc: 0.9320\n","Epoch 15/30\n","36000/36000 [==============================] - 149s 4ms/sample - loss: 0.0897 - acc: 0.9686 - val_loss: 0.2204 - val_acc: 0.9298\n","Epoch 16/30\n","36000/36000 [==============================] - 149s 4ms/sample - loss: 0.0876 - acc: 0.9688 - val_loss: 0.2220 - val_acc: 0.9315\n","Epoch 17/30\n","36000/36000 [==============================] - 149s 4ms/sample - loss: 0.0875 - acc: 0.9696 - val_loss: 0.2202 - val_acc: 0.9308\n","Epoch 18/30\n","36000/36000 [==============================] - 149s 4ms/sample - loss: 0.0865 - acc: 0.9695 - val_loss: 0.2219 - val_acc: 0.9317\n","Epoch 19/30\n","36000/36000 [==============================] - 149s 4ms/sample - loss: 0.0866 - acc: 0.9693 - val_loss: 0.2223 - val_acc: 0.9312\n","Epoch 20/30\n","36000/36000 [==============================] - 149s 4ms/sample - loss: 0.0847 - acc: 0.9709 - val_loss: 0.2231 - val_acc: 0.9312\n","Epoch 21/30\n","36000/36000 [==============================] - 150s 4ms/sample - loss: 0.0867 - acc: 0.9689 - val_loss: 0.2225 - val_acc: 0.9312\n","Epoch 22/30\n","36000/36000 [==============================] - 149s 4ms/sample - loss: 0.0874 - acc: 0.9690 - val_loss: 0.2228 - val_acc: 0.9317\n","Epoch 23/30\n","36000/36000 [==============================] - 149s 4ms/sample - loss: 0.0851 - acc: 0.9697 - val_loss: 0.2226 - val_acc: 0.9310\n","Epoch 24/30\n","36000/36000 [==============================] - 149s 4ms/sample - loss: 0.0859 - acc: 0.9701 - val_loss: 0.2224 - val_acc: 0.9312\n","Epoch 25/30\n","36000/36000 [==============================] - 149s 4ms/sample - loss: 0.0864 - acc: 0.9686 - val_loss: 0.2224 - val_acc: 0.9308\n","Epoch 26/30\n","36000/36000 [==============================] - 149s 4ms/sample - loss: 0.0852 - acc: 0.9692 - val_loss: 0.2229 - val_acc: 0.9310\n","Epoch 27/30\n","36000/36000 [==============================] - 149s 4ms/sample - loss: 0.0877 - acc: 0.9691 - val_loss: 0.2228 - val_acc: 0.9317\n","Epoch 28/30\n","36000/36000 [==============================] - 149s 4ms/sample - loss: 0.0844 - acc: 0.9706 - val_loss: 0.2225 - val_acc: 0.9310\n","Epoch 29/30\n","36000/36000 [==============================] - 149s 4ms/sample - loss: 0.0858 - acc: 0.9695 - val_loss: 0.2228 - val_acc: 0.9315\n","Epoch 30/30\n","36000/36000 [==============================] - 150s 4ms/sample - loss: 0.0861 - acc: 0.9701 - val_loss: 0.2225 - val_acc: 0.9310\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Pr_CQUwlGswq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":283},"outputId":"8dbfb297-de5e-46f9-d900-7685dcaeb345","executionInfo":{"status":"ok","timestamp":1560924857846,"user_tz":-180,"elapsed":4477108,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}}},"source":["plt.plot(history.history['acc'], \n","         label='Доля верных ответов на обучающем наборе')\n","plt.plot(history.history['val_acc'], \n","         label='Доля верных ответов на проверочном наборе')\n","plt.xlabel('Эпоха обучения')\n","plt.ylabel('Доля верных ответов')\n","plt.legend()\n","plt.show()"],"execution_count":16,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf12H0sSyOpcxAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"33lEMBEzG2BK","colab_type":"text"},"source":["#Kaggle submit"]},{"cell_type":"code","metadata":{"id":"MnNrDNlMGySc","colab_type":"code","colab":{}},"source":["\n","#model = create_model(params)\n","model.load_weights('nlp.hfd5')\n","predictions = model.predict(test_X)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"J--5VpfrG5M5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"outputId":"8bdfebb2-13a6-4643-9fac-9ad252e06374","executionInfo":{"status":"ok","timestamp":1560924982690,"user_tz":-180,"elapsed":21774,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}}},"source":["predictions = predictions.round()\n","out = np.column_stack((range(1, predictions.shape[0]+1), predictions))\n","np.savetxt('submission.csv', out, header=\"Id,Category\", comments=\"\", fmt=\"%d,%d\")\n","!head submission.csv"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Id,Category\n","1,1\n","2,1\n","3,0\n","4,0\n","5,1\n","6,0\n","7,0\n","8,1\n","9,0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nUoTjvT5G8dL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"outputId":"62e7fac9-ca62-4f41-df45-45a243277273","executionInfo":{"status":"ok","timestamp":1560924994899,"user_tz":-180,"elapsed":10001,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}}},"source":["!kaggle competitions submit -c neural-university-imdb-spring2019 -m \"Baseline submition from Colab\" -f submission.csv"],"execution_count":19,"outputs":[{"output_type":"stream","text":["100% 67.3k/67.3k [00:05<00:00, 12.1kB/s]\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/kaggle\", line 10, in <module>\n","    sys.exit(main())\n","  File \"/usr/local/lib/python2.7/dist-packages/kaggle/cli.py\", line 64, in main\n","    print(out, end='')\n","UnicodeEncodeError: 'latin-1' codec can't encode characters in position 26-36: ordinal not in range(256)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"65i2RWToHcOL","colab_type":"text"},"source":["#Conclusion\n","\n","[colab](https://colab.research.google.com/drive/1-BPvHSCm1GA2Oal-8axrReWvwqAWamsC)\n","\n","Второе место в соревновании. В качестве архитектуры использована двунаправленная сеть с LSTM слоем и слоем внимания.  В качестве признаков использовано векторное представление слов GloVe длиной 300,  с 20000 словами. "]},{"cell_type":"markdown","metadata":{"id":"ugC7AEiiG92s","colab_type":"text"},"source":["#Хлам"]},{"cell_type":"code","metadata":{"id":"VrMiAxn0cGj0","colab_type":"code","outputId":"ffb8ac82-5a3d-4d26-8a8b-11704281fdad","colab":{"base_uri":"https://localhost:8080/","height":773}},"source":["from tensorflow.keras.layers import RepeatVector, Permute, Multiply, Lambda\n","from tensorflow.keras import backend as K\n","\n","def create_model2(params):\n","  model = Sequential()\n","  model.add(Embedding(num_words, embedding_len, weights=[embedding_matrix]))\n","  model.add(SpatialDropout1D(0.4))\n","  #model.add(LSTM(100, return_sequences=True))\n","  model.add(Bidirectional(CuDNNLSTM(128, return_sequences=True)))\n","  model.add(AttentionWithContext())\n","  model.add(Dropout(0.3))\n","  model.add(BatchNormalization())\n","  model.add(Dense(1, activation=\"sigmoid\"))\n","  model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n","\n","  return model\n","\n","def create_model1(params):\n","  inp = Input(shape=(maxlen,))\n","  x = Embedding(num_words, embedding_len, weights=[embedding_matrix])(inp)\n","  x = Bidirectional(CuDNNLSTM(64, return_sequences=True))(x)\n","  max_pool = GlobalMaxPool1D()(x)\n","  atten = AttentionLSTM(maxlen)(x)\n","  #atten = AttentionLayer(name='attention')(x)\n","  #atten = Attention((maxlen,))(x)\n","  x = Concatenate(axis=-1)([max_pool, atten])\n","  \n","  x = Dense(8, activation=\"relu\")(x)\n","  x = Dropout(0.4)(x)\n","  x = BatchNormalization()(x)\n","\n","  x = Dense(1, activation=\"sigmoid\")(x)\n","  model = Model(inputs=inp, outputs=x)\n","  model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n","  return model\n","\n","def create_model(params):\n","  inp = Input(shape=(maxlen,))\n","  x = Embedding(num_words, embedding_len, weights=[embedding_matrix])(inp)\n","  x = Bidirectional(CuDNNLSTM(params['units'], return_sequences=True))(x)\n","  \n","  attention = TimeDistributed(Dense(1, activation='tanh'))(x) \n","  attention = Flatten()(attention)\n","  attention = Activation('softmax')(attention)\n","  attention = RepeatVector(params['units']*2)(attention)\n","  attention = Permute([2, 1])(attention)\n","\n","  # apply the attention\n","  merged = Multiply()([x, attention])\n","  x = Lambda(lambda xin: K.sum(xin, axis=1))(merged)  \n","  \n","  x = Dense(16, activation=\"relu\")(x)\n","  x = Dropout(0.4)(x)\n","  x = BatchNormalization()(x)\n","\n","  preds = Dense(1, activation=\"sigmoid\")(x)\n","  model = Model(inputs=inp, outputs=preds)\n","  model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n","  return model\n","\n","\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 36000 samples, validate on 4000 samples\n","Epoch 1/30\n","36000/36000 [==============================] - 76s 2ms/sample - loss: 0.4130 - acc: 0.8048 - val_loss: 0.4278 - val_acc: 0.8303\n","Epoch 2/30\n","36000/36000 [==============================] - 72s 2ms/sample - loss: 0.2669 - acc: 0.8898 - val_loss: 0.3089 - val_acc: 0.8692\n","Epoch 3/30\n","36000/36000 [==============================] - 72s 2ms/sample - loss: 0.2263 - acc: 0.9086 - val_loss: 0.2026 - val_acc: 0.9220\n","Epoch 4/30\n","36000/36000 [==============================] - 72s 2ms/sample - loss: 0.2034 - acc: 0.9200 - val_loss: 0.2097 - val_acc: 0.9193\n","Epoch 5/30\n","36000/36000 [==============================] - 72s 2ms/sample - loss: 0.1893 - acc: 0.9260 - val_loss: 0.2097 - val_acc: 0.9227\n","Epoch 6/30\n","36000/36000 [==============================] - 72s 2ms/sample - loss: 0.1803 - acc: 0.9293 - val_loss: 0.1963 - val_acc: 0.9265\n","Epoch 7/30\n","36000/36000 [==============================] - 72s 2ms/sample - loss: 0.1721 - acc: 0.9330 - val_loss: 0.1927 - val_acc: 0.9245\n","Epoch 8/30\n","36000/36000 [==============================] - 72s 2ms/sample - loss: 0.1678 - acc: 0.9358 - val_loss: 0.1964 - val_acc: 0.9298\n","Epoch 9/30\n","36000/36000 [==============================] - 72s 2ms/sample - loss: 0.1604 - acc: 0.9380 - val_loss: 0.1935 - val_acc: 0.9268\n","Epoch 10/30\n","36000/36000 [==============================] - 72s 2ms/sample - loss: 0.1596 - acc: 0.9394 - val_loss: 0.1939 - val_acc: 0.9270\n","Epoch 11/30\n","36000/36000 [==============================] - 72s 2ms/sample - loss: 0.1572 - acc: 0.9395 - val_loss: 0.1916 - val_acc: 0.9285\n","Epoch 12/30\n","36000/36000 [==============================] - 72s 2ms/sample - loss: 0.1570 - acc: 0.9399 - val_loss: 0.1941 - val_acc: 0.9302\n","Epoch 13/30\n","36000/36000 [==============================] - 72s 2ms/sample - loss: 0.1525 - acc: 0.9413 - val_loss: 0.1910 - val_acc: 0.9285\n","Epoch 14/30\n","36000/36000 [==============================] - 72s 2ms/sample - loss: 0.1526 - acc: 0.9427 - val_loss: 0.1922 - val_acc: 0.9302\n","Epoch 15/30\n","36000/36000 [==============================] - 72s 2ms/sample - loss: 0.1546 - acc: 0.9419 - val_loss: 0.1912 - val_acc: 0.9285\n","Epoch 16/30\n","36000/36000 [==============================] - 72s 2ms/sample - loss: 0.1513 - acc: 0.9423 - val_loss: 0.1926 - val_acc: 0.9287\n","Epoch 17/30\n","36000/36000 [==============================] - 72s 2ms/sample - loss: 0.1527 - acc: 0.9424 - val_loss: 0.1924 - val_acc: 0.9295\n","Epoch 18/30\n","36000/36000 [==============================] - 72s 2ms/sample - loss: 0.1511 - acc: 0.9409 - val_loss: 0.1920 - val_acc: 0.9290\n","Epoch 19/30\n","36000/36000 [==============================] - 72s 2ms/sample - loss: 0.1516 - acc: 0.9411 - val_loss: 0.1915 - val_acc: 0.9287\n","Epoch 20/30\n","36000/36000 [==============================] - 72s 2ms/sample - loss: 0.1505 - acc: 0.9438 - val_loss: 0.1917 - val_acc: 0.9290\n","Epoch 21/30\n","36000/36000 [==============================] - 72s 2ms/sample - loss: 0.1491 - acc: 0.9433 - val_loss: 0.1917 - val_acc: 0.9290\n","Epoch 22/30\n"," 2944/36000 [=>............................] - ETA: 1:03 - loss: 0.1535 - acc: 0.9361"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kksDv-CBSn-1","colab_type":"code","colab":{}},"source":["plt.plot(history.history['acc'], \n","         label='Доля верных ответов на обучающем наборе')\n","plt.plot(history.history['val_acc'], \n","         label='Доля верных ответов на проверочном наборе')\n","plt.xlabel('Эпоха обучения')\n","plt.ylabel('Доля верных ответов')\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"N6dGsxOfLrRE","colab_type":"code","colab":{}},"source":["!cp nlp.hfd5 ./drive/'My Drive'/nlp_9x.hfd5"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zkGYWlanUlwk","colab_type":"code","colab":{}},"source":["\n","def create_model(params):\n","  model = Sequential()\n","  #model.add(Embedding(num_words, embedding_matrix, input_length=maxlen))\n","  model.add(Embedding(num_words, embedding_len, weights=[embedding_matrix], input_length=maxlen, trainable=False))\n","  model.add(SpatialDropout1D(0.4))\n","  model.add(Bidirectional(LSTM(400, dropout=0.2, recurrent_dropout=0.2)))\n","  model.add(Dense(128, activation='relu'))\n","  model.add(Dropout(0.25))\n","  model.add(Dense(256, activation='relu'))\n","  model.add(Dropout(0.25))\n","  model.add(Dense(1, activation='sigmoid'))\n","  model.compile(optimizer='rmsprop', \n","              loss='binary_crossentropy', \n","              metrics=['accuracy'])  \n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PL7i9VFwwi3m","colab_type":"code","outputId":"fb8217c0-ac13-4ce3-d450-277e25bb669e","executionInfo":{"status":"ok","timestamp":1560832245032,"user_tz":-180,"elapsed":6088,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}},"colab":{"base_uri":"https://localhost:8080/","height":360}},"source":["params = {'lr': .001, 'drop_lr': .7 }\n","model = create_model(params)\n","model.load_weights('/content/drive/My Drive/nlpbd.hfd5')\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0618 04:30:39.156525 139842466908032 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","W0618 04:30:42.111627 139842466908032 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","W0618 04:30:42.116964 139842466908032 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","W0618 04:30:42.118344 139842466908032 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","W0618 04:30:42.123047 139842466908032 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","W0618 04:30:42.926708 139842466908032 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"TFbvrT3cw8k0","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CxatS2hbVoVM","colab_type":"code","outputId":"5b356118-0612-49ed-ecee-a925363b77b3","colab":{"base_uri":"https://localhost:8080/","height":374}},"source":["# params = {'lr': .001, 'drop_lr': .7 }\n","# model = create_model(params)\n","\n","def step_decay(epoch):\n","  initial_lrate = params['lr']\n","  drop = params['drop_lr']\n","  epochs_drop = 5.0\n","  lrate = initial_lrate * math.pow(drop,math.floor((1+epoch)/epochs_drop))\n","  return lrate    \n","lrate = LearningRateScheduler (step_decay,verbose=0)\n","сheckpoint = ModelCheckpoint('nlp.hfd5', monitor='val_acc', save_best_only=True, verbose=0)\n","\n","\n","\n","history = model.fit(train_X, \n","                    train_y, \n","                    epochs=10,\n","                    batch_size=64,\n","                    callbacks = [lrate,сheckpoint],\n","                    validation_split=0.1,\n","                    verbose=1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 36000 samples, validate on 4000 samples\n","Epoch 1/10\n","36000/36000 [==============================] - 2318s 64ms/sample - loss: 0.2556 - acc: 0.8984 - val_loss: 0.3098 - val_acc: 0.8752\n","Epoch 2/10\n","36000/36000 [==============================] - 2321s 64ms/sample - loss: 0.2394 - acc: 0.9041 - val_loss: 0.2494 - val_acc: 0.9062\n","Epoch 3/10\n","36000/36000 [==============================] - 2313s 64ms/sample - loss: 0.2603 - acc: 0.8910 - val_loss: 0.2241 - val_acc: 0.9130\n","Epoch 4/10\n","36000/36000 [==============================] - 2296s 64ms/sample - loss: 0.2543 - acc: 0.8971 - val_loss: 0.2394 - val_acc: 0.9097\n","Epoch 5/10\n","36000/36000 [==============================] - 2309s 64ms/sample - loss: 0.2365 - acc: 0.9036 - val_loss: 0.2287 - val_acc: 0.9100\n","Epoch 6/10\n","36000/36000 [==============================] - 2298s 64ms/sample - loss: 0.2174 - acc: 0.9129 - val_loss: 0.2190 - val_acc: 0.9097\n","Epoch 7/10\n","36000/36000 [==============================] - 2287s 64ms/sample - loss: 0.2043 - acc: 0.9190 - val_loss: 0.2304 - val_acc: 0.9107\n","Epoch 8/10\n","36000/36000 [==============================] - 2293s 64ms/sample - loss: 0.1959 - acc: 0.9227 - val_loss: 0.2255 - val_acc: 0.9153\n","Epoch 9/10\n","36000/36000 [==============================] - 2289s 64ms/sample - loss: 0.1878 - acc: 0.9253 - val_loss: 0.2286 - val_acc: 0.9145\n","Epoch 10/10\n","23104/36000 [==================>...........] - ETA: 13:02 - loss: 0.1705 - acc: 0.9313"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XTLymATw2q3D","colab_type":"text"},"source":["##predict"]},{"cell_type":"code","metadata":{"id":"vb8ohndWMMRq","colab_type":"code","colab":{}},"source":["#model = create_model(params)\n","model.load_weights('nlp.hfd5')\n","predictions = model.predict(test_X)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ax4jkZ7i24fK","colab_type":"code","colab":{}},"source":["predictions = predictions.round()\n","out = np.column_stack((range(1, predictions.shape[0]+1), predictions))\n","np.savetxt('submission.csv', out, header=\"Id,Category\", comments=\"\", fmt=\"%d,%d\")\n","!head submission.csv"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UA05HZ4e3JR8","colab_type":"code","colab":{}},"source":["!kaggle competitions submit -c neural-university-imdb-spring2019 -m \"Baseline submition from Colab\" -f submission.csv"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rDzGQYqTLovx","colab_type":"code","colab":{}},"source":["!cp nlp.hfd5 /content/drive/'My Drive'/nlpbd.hfd5"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4SylOkBkWROi","colab_type":"code","colab":{}},"source":["class AttentionLSTM(LSTM):\n","    \"\"\"LSTM with attention mechanism\n","    This is an LSTM incorporating an attention mechanism into its hidden states.\n","    Currently, the context vector calculated from the attended vector is fed\n","    into the model's internal states, closely following the model by Xu et al.\n","    (2016, Sec. 3.1.2), using a soft attention model following\n","    Bahdanau et al. (2014).\n","    The layer expects two inputs instead of the usual one:\n","        1. the \"normal\" layer input; and\n","        2. a 3D vector to attend.\n","    Args:\n","        attn_activation: Activation function for attentional components\n","        attn_init: Initialization function for attention weights\n","        output_alpha (boolean): If true, outputs the alpha values, i.e.,\n","            what parts of the attention vector the layer attends to at each\n","            timestep.\n","    References:\n","        * Bahdanau, Cho & Bengio (2014), \"Neural Machine Translation by Jointly\n","          Learning to Align and Translate\", <https://arxiv.org/pdf/1409.0473.pdf>\n","        * Xu, Ba, Kiros, Cho, Courville, Salakhutdinov, Zemel & Bengio (2016),\n","          \"Show, Attend and Tell: Neural Image Caption Generation with Visual\n","          Attention\", <http://arxiv.org/pdf/1502.03044.pdf>\n","    See Also:\n","        `LSTM`_ in the Keras documentation.\n","        .. _LSTM: http://keras.io/layers/recurrent/#lstm\n","    \"\"\"\n","    def __init__(self, *args, attn_activation='tanh', attn_init='orthogonal',\n","                 output_alpha=False, **kwargs):\n","        self.attn_activation = activations.get(attn_activation)\n","        #self.attn_init = initializations.get(attn_init)\n","        self.attn_init = initializers.get(attn_init)\n","        self.output_alpha = output_alpha\n","        super().__init__(*args, **kwargs)\n","\n","    def build(self, input_shape):\n","        if not (isinstance(input_shape, list) and len(input_shape) == 2):\n","            raise Exception('Input to AttentionLSTM must be a list of '\n","                            'two tensors [lstm_input, attn_input].')\n","\n","        input_shape, attn_input_shape = input_shape\n","        super().build(input_shape)\n","        self.input_spec.append(InputSpec(shape=attn_input_shape))\n","\n","        # weights for attention model\n","        self.U_att = self.inner_init((self.output_dim, self.output_dim),\n","                                     name='{}_U_att'.format(self.name))\n","        self.W_att = self.attn_init((attn_input_shape[-1], self.output_dim),\n","                                    name='{}_W_att'.format(self.name))\n","        self.v_att = self.init((self.output_dim, 1),\n","                               name='{}_v_att'.format(self.name))\n","        self.b_att = K.zeros((self.output_dim,), name='{}_b_att'.format(self.name))\n","        self.trainable_weights += [self.U_att, self.W_att, self.v_att, self.b_att]\n","\n","        # weights for incorporating attention into hidden states\n","        if self.consume_less == 'gpu':\n","            self.Z = self.init((attn_input_shape[-1], 4 * self.output_dim),\n","                               name='{}_Z'.format(self.name))\n","            self.trainable_weights += [self.Z]\n","        else:\n","            self.Z_i = self.attn_init((attn_input_shape[-1], self.output_dim),\n","                                      name='{}_Z_i'.format(self.name))\n","            self.Z_f = self.attn_init((attn_input_shape[-1], self.output_dim),\n","                                      name='{}_Z_f'.format(self.name))\n","            self.Z_c = self.attn_init((attn_input_shape[-1], self.output_dim),\n","                                      name='{}_Z_c'.format(self.name))\n","            self.Z_o = self.attn_init((attn_input_shape[-1], self.output_dim),\n","                                      name='{}_Z_o'.format(self.name))\n","            self.trainable_weights += [self.Z_i, self.Z_f, self.Z_c, self.Z_o]\n","            self.Z = K.concatenate([self.Z_i, self.Z_f, self.Z_c, self.Z_o])\n","\n","        # weights for initializing states based on attention vector\n","        if not self.stateful:\n","            self.W_init_c = self.attn_init((attn_input_shape[-1], self.output_dim),\n","                                           name='{}_W_init_c'.format(self.name))\n","            self.W_init_h = self.attn_init((attn_input_shape[-1], self.output_dim),\n","                                           name='{}_W_init_h'.format(self.name))\n","            self.b_init_c = K.zeros((self.output_dim,),\n","                                    name='{}_b_init_c'.format(self.name))\n","            self.b_init_h = K.zeros((self.output_dim,),\n","                                    name='{}_b_init_h'.format(self.name))\n","            self.trainable_weights += [self.W_init_c, self.b_init_c,\n","                                       self.W_init_h, self.b_init_h]\n","\n","        if self.initial_weights is not None:\n","            self.set_weights(self.initial_weights)\n","            del self.initial_weights\n","\n","    def get_output_shape_for(self, input_shape):\n","        # output shape is not affected by the attention component\n","        return super().get_output_shape_for(input_shape[0])\n","\n","    def compute_mask(self, input, input_mask=None):\n","        if input_mask is not None:\n","            input_mask = input_mask[0]\n","        return super().compute_mask(input, input_mask=input_mask)\n","\n","    def get_initial_states(self, x_input, x_attn, mask_attn):\n","        # set initial states from mean attention vector fed through a dense\n","        # activation\n","        mean_attn = K.mean(x_attn * K.expand_dims(mask_attn), axis=1)\n","        h0 = K.dot(mean_attn, self.W_init_h) + self.b_init_h\n","        c0 = K.dot(mean_attn, self.W_init_c) + self.b_init_c\n","        return [self.attn_activation(h0), self.attn_activation(c0)]\n","\n","    def call(self, x, mask=None):\n","        assert isinstance(x, list) and len(x) == 2\n","        x_input, x_attn = x\n","        if mask is not None:\n","            mask_input, mask_attn = mask\n","        else:\n","            mask_input, mask_attn = None, None\n","        # input shape: (nb_samples, time (padded with zeros), input_dim)\n","        input_shape = self.input_spec[0].shape\n","        if K._BACKEND == 'tensorflow':\n","            if not input_shape[1]:\n","                raise Exception('When using TensorFlow, you should define '\n","                                'explicitly the number of timesteps of '\n","                                'your sequences.\\n'\n","                                'If your first layer is an Embedding, '\n","                                'make sure to pass it an \"input_length\" '\n","                                'argument. Otherwise, make sure '\n","                                'the first layer has '\n","                                'an \"input_shape\" or \"batch_input_shape\" '\n","                                'argument, including the time axis. '\n","                                'Found input shape at layer ' + self.name +\n","                                ': ' + str(input_shape))\n","        if self.stateful:\n","            initial_states = self.states\n","        else:\n","            initial_states = self.get_initial_states(x_input, x_attn, mask_attn)\n","        constants = self.get_constants(x_input, x_attn, mask_attn)\n","        preprocessed_input = self.preprocess_input(x_input)\n","\n","        last_output, outputs, states = K.rnn(self.step, preprocessed_input,\n","                                             initial_states,\n","                                             go_backwards=self.go_backwards,\n","                                             mask=mask_input,\n","                                             constants=constants,\n","                                             unroll=self.unroll,\n","                                             input_length=input_shape[1])\n","        if self.stateful:\n","            self.updates = []\n","            for i in range(len(states)):\n","                self.updates.append((self.states[i], states[i]))\n","\n","        if self.return_sequences:\n","            return outputs\n","        else:\n","            return last_output\n","\n","    def step(self, x, states):\n","        h_tm1 = states[0]\n","        c_tm1 = states[1]\n","        B_U = states[2]\n","        B_W = states[3]\n","        x_attn = states[4]\n","        mask_attn = states[5]\n","        attn_shape = self.input_spec[1].shape\n","\n","        #### attentional component\n","        # alignment model\n","        # -- keeping weight matrices for x_attn and h_s separate has the advantage\n","        # that the feature dimensions of the vectors can be different\n","        h_att = K.repeat(h_tm1, attn_shape[1])\n","        att = time_distributed_dense(x_attn, self.W_att, self.b_att)\n","        energy = self.attn_activation(K.dot(h_att, self.U_att) + att)\n","        energy = K.squeeze(K.dot(energy, self.v_att), 2)\n","        # make probability tensor\n","        alpha = K.exp(energy)\n","        if mask_attn is not None:\n","            alpha *= mask_attn\n","        alpha /= K.sum(alpha, axis=1, keepdims=True)\n","        alpha_r = K.repeat(alpha, attn_shape[2])\n","        alpha_r = K.permute_dimensions(alpha_r, (0, 2, 1))\n","        # make context vector -- soft attention after Bahdanau et al.\n","        z_hat = x_attn * alpha_r\n","        z_hat = K.sum(z_hat, axis=1)\n","\n","        if self.consume_less == 'gpu':\n","            z = K.dot(x * B_W[0], self.W) + K.dot(h_tm1 * B_U[0], self.U) \\\n","                + K.dot(z_hat, self.Z) + self.b\n","\n","            z0 = z[:, :self.output_dim]\n","            z1 = z[:, self.output_dim: 2 * self.output_dim]\n","            z2 = z[:, 2 * self.output_dim: 3 * self.output_dim]\n","            z3 = z[:, 3 * self.output_dim:]\n","        else:\n","            if self.consume_less == 'cpu':\n","                x_i = x[:, :self.output_dim]\n","                x_f = x[:, self.output_dim: 2 * self.output_dim]\n","                x_c = x[:, 2 * self.output_dim: 3 * self.output_dim]\n","                x_o = x[:, 3 * self.output_dim:]\n","            elif self.consume_less == 'mem':\n","                x_i = K.dot(x * B_W[0], self.W_i) + self.b_i\n","                x_f = K.dot(x * B_W[1], self.W_f) + self.b_f\n","                x_c = K.dot(x * B_W[2], self.W_c) + self.b_c\n","                x_o = K.dot(x * B_W[3], self.W_o) + self.b_o\n","            else:\n","                raise Exception('Unknown `consume_less` mode.')\n","\n","            z0 = x_i + K.dot(h_tm1 * B_U[0], self.U_i) + K.dot(z_hat, self.Z_i)\n","            z1 = x_f + K.dot(h_tm1 * B_U[1], self.U_f) + K.dot(z_hat, self.Z_f)\n","            z2 = x_c + K.dot(h_tm1 * B_U[2], self.U_c) + K.dot(z_hat, self.Z_c)\n","            z3 = x_o + K.dot(h_tm1 * B_U[3], self.U_o) + K.dot(z_hat, self.Z_o)\n","\n","        i = self.inner_activation(z0)\n","        f = self.inner_activation(z1)\n","        c = f * c_tm1 + i * self.activation(z2)\n","        o = self.inner_activation(z3)\n","\n","        h = o * self.activation(c)\n","        if self.output_alpha:\n","            return alpha, [h, c]\n","        else:\n","            return h, [h, c]\n","\n","    def get_constants(self, x_input, x_attn, mask_attn):\n","        constants = super().get_constants(x_input)\n","        attn_shape = self.input_spec[1].shape\n","        if mask_attn is not None:\n","            if K.ndim(mask_attn) == 3:\n","                mask_attn = K.all(mask_attn, axis=-1)\n","        constants.append(x_attn)\n","        constants.append(mask_attn)\n","        return constants\n","\n","    def get_config(self):\n","        cfg = super().get_config()\n","        cfg['output_alpha'] = self.output_alpha\n","        cfg['attn_activation'] = self.attn_activation.__name__\n","        return cfg\n","\n","    @classmethod\n","    def from_config(cls, config):\n","        instance = super(AttentionLSTM, cls).from_config(config)\n","        if 'output_alpha' in config:\n","            instance.output_alpha = config['output_alpha']\n","        if 'attn_activation' in config:\n","            instance.attn_activation = activations.get(config['attn_activation'])\n","        return instance"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IRNbYSTXmXgX","colab_type":"code","colab":{}},"source":["\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dtsk2uTUlJUq","colab_type":"code","colab":{}},"source":["# не работает\n","class Attention(Layer):\n","    def __init__(self, step_dim,\n","                 W_regularizer=None, b_regularizer=None,\n","                 W_constraint=None, b_constraint=None,\n","                 bias=True, **kwargs):\n","        self.supports_masking = True\n","        self.init = initializers.get('glorot_uniform')\n","        self.W_regularizer = regularizers.get(W_regularizer)\n","        self.b_regularizer = regularizers.get(b_regularizer)\n","        self.W_constraint = constraints.get(W_constraint)\n","        self.b_constraint = constraints.get(b_constraint)\n","        self.bias = bias\n","        self.step_dim = step_dim\n","        self.features_dim = 0\n","        super(Attention, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        assert len(input_shape) == 3\n","        self.W = self.add_weight(shape=(input_shape[-1],),\n","                                 initializer=self.init,\n","                                 name='{}_W'.format(self.name),\n","                                 regularizer=self.W_regularizer,\n","                                 constraint=self.W_constraint)\n","        self.features_dim = input_shape[-1]\n","        if self.bias:\n","            self.b = self.add_weight(shape=(input_shape[1],),\n","                                     initializer='zero',\n","                                     name='{}_b'.format(self.name),\n","                                     regularizer=self.b_regularizer,\n","                                     constraint=self.b_constraint)\n","        else:\n","            self.b = None\n","        self.built = True\n","\n","    def compute_mask(self, input, input_mask=None):\n","        return None\n","\n","    def call(self, x, mask=None):\n","        features_dim = self.features_dim\n","        step_dim = self.step_dim\n","        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)), K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n","        if self.bias:\n","            eij += self.b\n","        eij = K.tanh(eij)\n","        a = K.exp(eij)\n","        if mask is not None:\n","            a *= K.cast(mask, K.floatx())\n","        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n","        a = K.expand_dims(a)\n","        weighted_input = x * a\n","        return K.sum(weighted_input, axis=1)\n","\n","    def compute_output_shape(self, input_shape):\n","        return input_shape[0],  self.features_dim\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KWZCbsUEmOly","colab_type":"code","colab":{}},"source":["#--\n","import tensorflow as tf\n","import os\n","from tensorflow.python.keras.layers import Layer\n","from tensorflow.python.keras import backend as K\n","\n","\n","class AttentionLayer(Layer):\n","    \"\"\"\n","    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n","    There are three sets of weights introduced W_a, U_a, and V_a\n","     \"\"\"\n","\n","    def __init__(self, **kwargs):\n","        super(AttentionLayer, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        assert isinstance(input_shape, list)\n","        # Create a trainable weight variable for this layer.\n","\n","        self.W_a = self.add_weight(name='W_a',\n","                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n","                                   initializer='uniform',\n","                                   trainable=True)\n","        self.U_a = self.add_weight(name='U_a',\n","                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n","                                   initializer='uniform',\n","                                   trainable=True)\n","        self.V_a = self.add_weight(name='V_a',\n","                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n","                                   initializer='uniform',\n","                                   trainable=True)\n","\n","        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n","\n","    def call(self, inputs, verbose=False):\n","        \"\"\"\n","        inputs: [encoder_output_sequence, decoder_output_sequence]\n","        \"\"\"\n","        assert type(inputs) == list\n","        encoder_out_seq, decoder_out_seq = inputs\n","        if verbose:\n","            print('encoder_out_seq>', encoder_out_seq.shape)\n","            print('decoder_out_seq>', decoder_out_seq.shape)\n","\n","        def energy_step(inputs, states):\n","            \"\"\" Step function for computing energy for a single decoder state \"\"\"\n","\n","            assert_msg = \"States must be a list. However states {} is of type {}\".format(states, type(states))\n","            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n","\n","            \"\"\" Some parameters required for shaping tensors\"\"\"\n","            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n","            de_hidden = inputs.shape[-1]\n","\n","            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n","            # <= batch_size*en_seq_len, latent_dim\n","            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n","            # <= batch_size*en_seq_len, latent_dim\n","            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n","            if verbose:\n","                print('wa.s>',W_a_dot_s.shape)\n","\n","            \"\"\" Computing hj.Ua \"\"\"\n","            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n","            if verbose:\n","                print('Ua.h>',U_a_dot_h.shape)\n","\n","            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n","            # <= batch_size*en_seq_len, latent_dim\n","            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n","            if verbose:\n","                print('Ws+Uh>', reshaped_Ws_plus_Uh.shape)\n","\n","            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n","            # <= batch_size, en_seq_len\n","            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n","            # <= batch_size, en_seq_len\n","            e_i = K.softmax(e_i)\n","\n","            if verbose:\n","                print('ei>', e_i.shape)\n","\n","            return e_i, [e_i]\n","\n","        def context_step(inputs, states):\n","            \"\"\" Step function for computing ci using ei \"\"\"\n","            # <= batch_size, hidden_size\n","            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n","            if verbose:\n","                print('ci>', c_i.shape)\n","            return c_i, [c_i]\n","\n","        def create_inital_state(inputs, hidden_size):\n","            # We are not using initial states, but need to pass something to K.rnn funciton\n","            fake_state = K.zeros_like(inputs)  # <= (batch_size, enc_seq_len, latent_dim\n","            fake_state = K.sum(fake_state, axis=[1, 2])  # <= (batch_size)\n","            fake_state = K.expand_dims(fake_state)  # <= (batch_size, 1)\n","            fake_state = K.tile(fake_state, [1, hidden_size])  # <= (batch_size, latent_dim\n","            return fake_state\n","\n","        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n","        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  # <= (batch_size, enc_seq_len, latent_dim\n","\n","        \"\"\" Computing energy outputs \"\"\"\n","        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n","        last_out, e_outputs, _ = K.rnn(\n","            energy_step, decoder_out_seq, [fake_state_e],\n","        )\n","\n","        \"\"\" Computing context vectors \"\"\"\n","        last_out, c_outputs, _ = K.rnn(\n","            context_step, e_outputs, [fake_state_c],\n","        )\n","\n","        return c_outputs, e_outputs\n","\n","    def compute_output_shape(self, input_shape):\n","        \"\"\" Outputs produced by the layer \"\"\"\n","        return [\n","            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n","            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n","        ]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GKkwDWfVl-BU","colab_type":"code","colab":{}},"source":["#--\n","import tensorflow as tf\n","import os\n","from tensorflow.python.keras.layers import Layer\n","from tensorflow.python.keras import backend as K\n","\n","\n","class AttentionLayer(Layer):\n","    \"\"\"\n","    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n","    There are three sets of weights introduced W_a, U_a, and V_a\n","     \"\"\"\n","\n","    def __init__(self, **kwargs):\n","        super(AttentionLayer, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        assert isinstance(input_shape, list)\n","        # Create a trainable weight variable for this layer.\n","\n","        self.W_a = self.add_weight(name='W_a',\n","                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n","                                   initializer='uniform',\n","                                   trainable=True)\n","        self.U_a = self.add_weight(name='U_a',\n","                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n","                                   initializer='uniform',\n","                                   trainable=True)\n","        self.V_a = self.add_weight(name='V_a',\n","                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n","                                   initializer='uniform',\n","                                   trainable=True)\n","\n","        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n","\n","    def call(self, inputs, verbose=False):\n","        \"\"\"\n","        inputs: [encoder_output_sequence, decoder_output_sequence]\n","        \"\"\"\n","        assert type(inputs) == list\n","        encoder_out_seq, decoder_out_seq = inputs\n","        if verbose:\n","            print('encoder_out_seq>', encoder_out_seq.shape)\n","            print('decoder_out_seq>', decoder_out_seq.shape)\n","\n","        def energy_step(inputs, states):\n","            \"\"\" Step function for computing energy for a single decoder state \"\"\"\n","\n","            assert_msg = \"States must be a list. However states {} is of type {}\".format(states, type(states))\n","            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n","\n","            \"\"\" Some parameters required for shaping tensors\"\"\"\n","            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n","            de_hidden = inputs.shape[-1]\n","\n","            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n","            # <= batch_size*en_seq_len, latent_dim\n","            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n","            # <= batch_size*en_seq_len, latent_dim\n","            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n","            if verbose:\n","                print('wa.s>',W_a_dot_s.shape)\n","\n","            \"\"\" Computing hj.Ua \"\"\"\n","            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n","            if verbose:\n","                print('Ua.h>',U_a_dot_h.shape)\n","\n","            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n","            # <= batch_size*en_seq_len, latent_dim\n","            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n","            if verbose:\n","                print('Ws+Uh>', reshaped_Ws_plus_Uh.shape)\n","\n","            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n","            # <= batch_size, en_seq_len\n","            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n","            # <= batch_size, en_seq_len\n","            e_i = K.softmax(e_i)\n","\n","            if verbose:\n","                print('ei>', e_i.shape)\n","\n","            return e_i, [e_i]\n","\n","        def context_step(inputs, states):\n","            \"\"\" Step function for computing ci using ei \"\"\"\n","            # <= batch_size, hidden_size\n","            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n","            if verbose:\n","                print('ci>', c_i.shape)\n","            return c_i, [c_i]\n","\n","        def create_inital_state(inputs, hidden_size):\n","            # We are not using initial states, but need to pass something to K.rnn funciton\n","            fake_state = K.zeros_like(inputs)  # <= (batch_size, enc_seq_len, latent_dim\n","            fake_state = K.sum(fake_state, axis=[1, 2])  # <= (batch_size)\n","            fake_state = K.expand_dims(fake_state)  # <= (batch_size, 1)\n","            fake_state = K.tile(fake_state, [1, hidden_size])  # <= (batch_size, latent_dim\n","            return fake_state\n","\n","        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n","        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  # <= (batch_size, enc_seq_len, latent_dim\n","\n","        \"\"\" Computing energy outputs \"\"\"\n","        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n","        last_out, e_outputs, _ = K.rnn(\n","            energy_step, decoder_out_seq, [fake_state_e],\n","        )\n","\n","        \"\"\" Computing context vectors \"\"\"\n","        last_out, c_outputs, _ = K.rnn(\n","            context_step, e_outputs, [fake_state_c],\n","        )\n","\n","        return c_outputs, e_outputs\n","\n","    def compute_output_shape(self, input_shape):\n","        \"\"\" Outputs produced by the layer \"\"\"\n","        return [\n","            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n","            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n","        ]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rWSiniAhNj_J","colab_type":"code","colab":{}},"source":["from tensorflow.keras import backend as K\n","from tensorflow.keras.layers import Layer\n","from tensorflow.keras import initializers, regularizers, constraints\n","\n","\n","class Attention(Layer):\n","    def __init__(self, step_dim,\n","                 W_regularizer=None, b_regularizer=None,\n","                 W_constraint=None, b_constraint=None,\n","                 bias=True, **kwargs):\n","        self.supports_masking = True\n","        self.init = initializers.get('glorot_uniform')\n","\n","        self.W_regularizer = regularizers.get(W_regularizer)\n","        self.b_regularizer = regularizers.get(b_regularizer)\n","\n","        self.W_constraint = constraints.get(W_constraint)\n","        self.b_constraint = constraints.get(b_constraint)\n","\n","        self.bias = bias\n","        self.step_dim = step_dim\n","        self.features_dim = 0\n","        super(Attention, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        assert len(input_shape) == 3\n","\n","#         self.W_a = self.add_weight(name='W_a',\n","#                                    shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n","#                                    initializer='uniform',\n","#                                    trainable=True)\n","#         self.U_a = self.add_weight(name='U_a',\n","#                                    shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n","#                                    initializer='uniform',\n","#                                    trainable=True)\n","#         self.V_a = self.add_weight(name='V_a',\n","#                                    shape=tf.TensorShape((input_shape[0][2], 1)),\n","#                                    initializer='uniform',\n","#                                    trainable=True)\n","        \n","        print(input_shape)\n","        self.W = self.add_weight(shape=tf.TensorShape(input_shape),\n","                                 initializer=self.init,\n","                                 name='{}_W'.format(self.name),\n","                                 regularizer=self.W_regularizer,\n","                                 constraint=self.W_constraint)\n","        self.features_dim = input_shape[-1]\n","\n","        if self.bias:\n","            self.b = self.add_weight(shape=tf.TensorShape(input_shape[2], )),\n","                                     initializer='zero',\n","                                     name='{}_b'.format(self.name),\n","                                     regularizer=self.b_regularizer,\n","                                     constraint=self.b_constraint)\n","        else:\n","            self.b = None\n","\n","        self.built = True\n","\n","    def compute_mask(self, input, input_mask=None):\n","        return None\n","\n","    def call(self, x, mask=None):\n","        features_dim = self.features_dim\n","        step_dim = self.step_dim\n","\n","        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n","                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n","\n","        if self.bias:\n","            eij += self.b\n","\n","        eij = K.tanh(eij)\n","\n","        a = K.exp(eij)\n","\n","        if mask is not None:\n","            a *= K.cast(mask, K.floatx())\n","\n","        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n","\n","        a = K.expand_dims(a)\n","        weighted_input = x * a\n","        return K.sum(weighted_input, axis=1)\n","\n","    def compute_output_shape(self, input_shape):\n","        return input_shape[0],  self.features_dim"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8_l0TqjbkMHx","colab_type":"code","outputId":"d2dc6ad8-1065-43ec-84bf-3bb19e6b9c78","executionInfo":{"status":"error","timestamp":1560862548057,"user_tz":-180,"elapsed":3904,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}},"colab":{"base_uri":"https://localhost:8080/","height":302}},"source":["from tensorflow.keras.layers import RepeatVector, Permute, Multiply, Lambda\n","def create_model1(params):\n","  inp = Input(shape=(maxlen,))\n","  x = Embedding(num_words, embedding_len, weights=[embedding_matrix])(inp)\n","  x = Bidirectional(CuDNNLSTM(64, return_sequences=True))(x)\n","  max_pool = GlobalMaxPool1D()(x)\n","  atten = AttentionLSTM(maxlen)(x)\n","  #atten = AttentionLayer(name='attention')(x)\n","  #atten = Attention((maxlen,))(x)\n","  x = Concatenate(axis=-1)([max_pool, atten])\n","  \n","  x = Dense(8, activation=\"relu\")(x)\n","  x = Dropout(0.4)(x)\n","  x = BatchNormalization()(x)\n","\n","  x = Dense(1, activation=\"sigmoid\")(x)\n","  model = Model(inputs=inp, outputs=x)\n","  model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n","  return model\n","\n","def create_model(params):\n","  inp = Input(shape=(maxlen,))\n","  x = Embedding(num_words, embedding_len, weights=[embedding_matrix])(inp)\n","  x = Bidirectional(CuDNNLSTM(64, return_sequences=True))(x)\n","  \n","  attention = TimeDistributed(Dense(1, activation='tanh'))(x) \n","  attention = Flatten()(attention)\n","  attention = Activation('softmax')(attention)\n","  attention = RepeatVector(128)(attention)\n","  attention = Permute([2, 1])(attention)\n","\n","  # apply the attention\n","  merged = Multiply()([x, attention])\n","  merged = Lambda(lambda xin: K.sum(xin, axis=1))(merged)  \n","  \n","#   # attention\n","#   attention = TimeDistributed(Dense(1, activation='tanh'))(x) \n","#   attention = Flatten()(attention)\n","#   attention = Activation('softmax')(attention)\n","\n","#   merged = Merge([x, attention], mode='mul')  \n","#   merged = BatchNormalization()(merged)\n","\n","  preds = Dense(1, activation=\"sigmoid\")(merged)\n","  model = Model(inputs=inp, outputs=preds)\n","  model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n","  return model\n","\n","\n","\n","\n","params = {'lr': .002, 'drop_lr': .75 }\n","model = create_model(params)\n","\n","#model.load_weights('nlp92.hfd5')\n","сheckpoint = ModelCheckpoint('nlp.hfd5', monitor='val_acc', save_best_only=True, verbose=0)\n","def step_decay(epoch):\n","  initial_lrate = params['lr']\n","  drop = params['drop_lr']\n","  epochs_drop = 1\n","  lrate = initial_lrate * math.pow(drop,math.floor((1+epoch)/epochs_drop))\n","  return lrate    \n","lrate = LearningRateScheduler (step_decay,verbose=0)\n","\n","\n","history = model.fit(train_X, \n","                    train_y, \n","                    epochs=10,\n","                    batch_size=128,\n","                    callbacks = [lrate,сheckpoint],\n","                    validation_split=0.1,\n","                    verbose=1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 36000 samples, validate on 4000 samples\n","Epoch 1/10\n","36000/36000 [==============================] - 52s 1ms/sample - loss: 0.3804 - acc: 0.8256 - val_loss: 0.2285 - val_acc: 0.9107\n","Epoch 2/10\n","36000/36000 [==============================] - 46s 1ms/sample - loss: 0.1993 - acc: 0.9223 - val_loss: 0.2058 - val_acc: 0.9222\n","Epoch 3/10\n","36000/36000 [==============================] - 46s 1ms/sample - loss: 0.1480 - acc: 0.9452 - val_loss: 0.2162 - val_acc: 0.9185\n","Epoch 4/10\n","36000/36000 [==============================] - 46s 1ms/sample - loss: 0.1123 - acc: 0.9592 - val_loss: 0.2118 - val_acc: 0.9197\n","Epoch 5/10\n","36000/36000 [==============================] - 46s 1ms/sample - loss: 0.0856 - acc: 0.9706 - val_loss: 0.2426 - val_acc: 0.9145\n","Epoch 6/10\n","36000/36000 [==============================] - 47s 1ms/sample - loss: 0.0666 - acc: 0.9779 - val_loss: 0.2606 - val_acc: 0.9160\n","Epoch 7/10\n","36000/36000 [==============================] - 46s 1ms/sample - loss: 0.0532 - acc: 0.9828 - val_loss: 0.2839 - val_acc: 0.9150\n","Epoch 8/10\n"," 1920/36000 [>.............................] - ETA: 41s - loss: 0.0403 - acc: 0.9891"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mS6JtkJ0b6If","colab_type":"code","outputId":"72c2b249-1359-475d-c1ec-b04ccdaf7d2d","executionInfo":{"status":"ok","timestamp":1560875617196,"user_tz":-180,"elapsed":1659,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!ls"],"execution_count":0,"outputs":[{"output_type":"stream","text":["sample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IOdpZaKuW_X9","colab_type":"code","colab":{}},"source":["class Attention(Layer):\n","    def __init__(self, step_dim,\n","                 W_regularizer=None, b_regularizer=None,\n","                 W_constraint=None, b_constraint=None,\n","                 bias=True, **kwargs):\n","        self.supports_masking = True\n","        self.init = initializers.get('glorot_uniform')\n","        self.W_regularizer = regularizers.get(W_regularizer)\n","        self.b_regularizer = regularizers.get(b_regularizer)\n","        self.W_constraint = constraints.get(W_constraint)\n","        self.b_constraint = constraints.get(b_constraint)\n","        self.bias = bias\n","        self.step_dim = step_dim\n","        self.features_dim = 0\n","        super(Attention, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        assert len(input_shape) == 3\n","        self.W = self.add_weight((input_shape[-1],),\n","                                 initializer=self.init,\n","                                 name='{}_W'.format(self.name),\n","                                 regularizer=self.W_regularizer,\n","                                 constraint=self.W_constraint)\n","        self.features_dim = input_shape[-1]\n","        if self.bias:\n","            self.b = self.add_weight((input_shape[1],),\n","                                     initializer='zero',\n","                                     name='{}_b'.format(self.name),\n","                                     regularizer=self.b_regularizer,\n","                                     constraint=self.b_constraint)\n","        else:\n","            self.b = None\n","        self.built = True\n","\n","    def compute_mask(self, input, input_mask=None):\n","        return None\n","\n","    def call(self, x, mask=None):\n","        features_dim = self.features_dim\n","        step_dim = self.step_dim\n","        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)), K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n","        if self.bias:\n","            eij += self.b\n","        eij = K.tanh(eij)\n","        a = K.exp(eij)\n","        if mask is not None:\n","            a *= K.cast(mask, K.floatx())\n","        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n","        a = K.expand_dims(a)\n","        weighted_input = x * a\n","        return K.sum(weighted_input, axis=1)\n","\n","    def compute_output_shape(self, input_shape):\n","        return input_shape[0],  self.features_dim"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Me3aibGKiiK8","colab_type":"code","colab":{}},"source":["\n","      \n","def create_model2(params):\n","  features_input = Input(shape=(train_X.shape[1],))\n","  inp = Input(shape=(maxlen, ))\n","  x = Embedding(num_words, embedding_len, weights=[embedding_matrix], input_length=maxlen, trainable=False)(inp)\n","\n","  x = SpatialDropout1D(.1)(x)\n","  x = Bidirectional(CuDNNLSTM(120, return_sequences=True))(x)\n","  y = Bidirectional(CuDNNGRU(120, return_sequences=True))(x)\n","  atten_1 = Attention(maxlen)(x) # skip connect\n","  atten_2 = Attention(maxlen)(y)\n","  avg_pool = GlobalAveragePooling1D()(y)\n","  max_pool = GlobalMaxPooling1D()(y)\n","  x = concatenate([atten_1, atten_2, avg_pool, max_pool,features_input])\n","  x = Dense(720, activation=\"relu\")(x)\n","  x = Dropout(0.2)(x)\n","  x = Dense(16, activation=\"relu\")(x)\n","  x = Dropout(0.1)(x)\n","  \n","  # Output dense layer with one output for our Binary Classification problem.\n","  outp = Dense(1, activation=\"sigmoid\")(x)\n","  # Some keras model creation and compiling\n","  model = Model(inputs=[inp,features_input], outputs=outp)\n","  \n","  model.compile(optimizer='adam', \n","              loss='binary_crossentropy', \n","              metrics=['accuracy'])  \n","  \n","  return model\n","\n","params = {'lr': .001, 'drop_lr': .7 }\n","model = create_model2(params)\n","сheckpoint = ModelCheckpoint('nlp.hfd5', monitor='val_acc', save_best_only=True, verbose=0)\n","\n","\n","\n","history = model.fit(train_X, \n","                    train_y, \n","                    epochs=10,\n","                    batch_size=128,\n","                    callbacks = [сheckpoint],\n","                    validation_split=0.1,\n","                    verbose=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1eJcUfuJ5Smd","colab_type":"code","outputId":"afcc7545-f28d-454c-f2ad-b708effa3192","executionInfo":{"status":"ok","timestamp":1560860969634,"user_tz":-180,"elapsed":447417,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}},"colab":{"base_uri":"https://localhost:8080/","height":374}},"source":["def create_model(params):\n","  inp = Input(shape=(maxlen,))\n","  x = Embedding(num_words, embedding_len, weights=[embedding_matrix])(inp)\n","  x = Bidirectional(CuDNNLSTM(64, return_sequences=True))(x)\n","  x = GlobalMaxPool1D()(x)\n","  \n","  x = Dense(8, activation=\"relu\")(x)\n","  x = Dropout(0.4)(x)\n","  x = BatchNormalization()(x)\n","\n","  x = Dense(1, activation=\"sigmoid\")(x)\n","  model = Model(inputs=inp, outputs=x)\n","  model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n","  return model\n","\n","params = {'lr': .002, 'drop_lr': .75 }\n","model = create_model(params)\n","\n","#model.load_weights('nlp92.hfd5')\n","сheckpoint = ModelCheckpoint('nlp.hfd5', monitor='val_acc', save_best_only=True, verbose=0)\n","def step_decay(epoch):\n","  initial_lrate = params['lr']\n","  drop = params['drop_lr']\n","  epochs_drop = 1\n","  lrate = initial_lrate * math.pow(drop,math.floor((1+epoch)/epochs_drop))\n","  return lrate    \n","lrate = LearningRateScheduler (step_decay,verbose=0)\n","\n","\n","history = model.fit(train_X, \n","                    train_y, \n","                    epochs=10,\n","                    batch_size=128,\n","                    callbacks = [lrate,сheckpoint],\n","                    validation_split=0.1,\n","                    verbose=1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 36000 samples, validate on 4000 samples\n","Epoch 1/10\n","36000/36000 [==============================] - 46s 1ms/sample - loss: 0.4150 - acc: 0.8120 - val_loss: 0.2732 - val_acc: 0.8945\n","Epoch 2/10\n","36000/36000 [==============================] - 44s 1ms/sample - loss: 0.2534 - acc: 0.9021 - val_loss: 0.2059 - val_acc: 0.9205\n","Epoch 3/10\n","36000/36000 [==============================] - 44s 1ms/sample - loss: 0.1880 - acc: 0.9332 - val_loss: 0.2741 - val_acc: 0.8838\n","Epoch 4/10\n","36000/36000 [==============================] - 44s 1ms/sample - loss: 0.1350 - acc: 0.9556 - val_loss: 0.2356 - val_acc: 0.9038\n","Epoch 5/10\n","36000/36000 [==============================] - 44s 1ms/sample - loss: 0.0959 - acc: 0.9701 - val_loss: 0.2447 - val_acc: 0.9158\n","Epoch 6/10\n","36000/36000 [==============================] - 44s 1ms/sample - loss: 0.0723 - acc: 0.9794 - val_loss: 0.2407 - val_acc: 0.9190\n","Epoch 7/10\n","36000/36000 [==============================] - 44s 1ms/sample - loss: 0.0592 - acc: 0.9842 - val_loss: 0.2649 - val_acc: 0.9195\n","Epoch 8/10\n","36000/36000 [==============================] - 44s 1ms/sample - loss: 0.0518 - acc: 0.9859 - val_loss: 0.2817 - val_acc: 0.9158\n","Epoch 9/10\n","36000/36000 [==============================] - 44s 1ms/sample - loss: 0.0499 - acc: 0.9868 - val_loss: 0.2795 - val_acc: 0.9172\n","Epoch 10/10\n","36000/36000 [==============================] - 44s 1ms/sample - loss: 0.0429 - acc: 0.9897 - val_loss: 0.2917 - val_acc: 0.9162\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_bxYFdDLTZ_J","colab_type":"code","colab":{}},"source":["!cp nlp.hfd5 nlp92.hfd5"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GJcrOBa_uuT_","colab_type":"code","outputId":"af9397bb-9ce7-4d46-b239-6d0c25cf1947","executionInfo":{"status":"ok","timestamp":1560860970535,"user_tz":-180,"elapsed":37529,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}},"colab":{"base_uri":"https://localhost:8080/","height":283}},"source":["plt.plot(history.history['acc'], \n","         label='Доля верных ответов на обучающем наборе')\n","plt.plot(history.history['val_acc'], \n","         label='Доля верных ответов на проверочном наборе')\n","plt.xlabel('Эпоха обучения')\n","plt.ylabel('Доля верных ответов')\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xd4lFX2wPHvSYc0WuhVQFoCAUJA\nqVIEBcHGAgKCqNjAVXexLyriz467a10RrEgRFRFQAQHBQgkSQhOkCYQAIbT0en9/vJNhEhIyJBkm\n5XyeZ56Zt86ZlPfMLe+9YoxBKaWUKi4PdweglFKqfNNEopRSqkQ0kSillCoRTSRKKaVKRBOJUkqp\nEtFEopRSqkQ0kSillCoRTSRKKaVKRBOJUkqpEvFydwCXQ61atUzTpk3dHYZSSpUrmzdvPmmMCSlq\nv0qRSJo2bUpUVJS7w1BKqXJFRP5yZj+t2lJKKVUimkiUUkqViCYSpZRSJaKJRCmlVIloIlFKKVUi\nmkiUUkqViCYSpZRSJVIp7iNRSqmKLiUjixPn0olPSic+0XqcSExjQvdm1Azwdel7ayJRSqkyKjvH\nkJCcmxTOJwjHx4nENOIT00nOyL7geE8P4brQeppIlFKqoklOz8qTGHKTQZ6EkZROQlI6OebC4wP9\nvAgJ9CUkwJewhtUICfAlJNCX2oHWc+7r6lV98PAQl38eTSRKKeUkYwyZ2YaM7BzSM7NJz8ohIyuH\n9Kwc0rPOL6dmZHMqOeN8gkjKmyRSCig9eHkItWwJoV6wH+0bBudLDn7UDvSlVoAvVXw83fDpC6eJ\nRClVLhljSMnIJjk9i8T0LJLSskhKzyLNdoFPz8o+f5HPzLec7+KfnpmTJzlYCcHx9fl9TQElhIsJ\n9POyJ4P2DaudTwwBvtQOOv/6cpUeXEETiVLqssrIyiE53broJ9ou/nmTQabtOdt6nW+/pDRr3+T0\nrAKrfYri6+VhPbw98fH0wNfbA18vT3y9PPDx8iDQz4tatmVrP2u7T+6ybT/HY3Jf+3p72M7pSU1/\nH0ICffHzLlulB1fQRKKUKrYzKRnsPZHEvvgk4hPT85QM7M/p55cT07PIyMop8rwi4O/jRYCvFwF+\n1nOgnxd1Av3yLAf4euGf73VVH88CLvTWsrenIFI+v/WXZZpIlFIXlZNjiD2Tyt74JPbZksa+E8ns\ni08iITkjz74+Xh4EOlz8/X29qBt0/uIf4OdFgI9XvmTgjb+vp/11gJ8XVb09y201T2WkiUQpBUBa\nZjb745PzJIy9J5I4cDKZdIdSRA1/H5qH+DOgbR2ahwTQonYAzUMCqBPsi69Xxa/GURfSRKJUJWKM\nISE5w5Yoku3JYl98ErFnUu0NySLQqHpVWtQOoGfLWjQPCaC5LWHU8Pdx74dQZY4mEqUqoKzsHI6c\nTrUnCethJY4zKZn2/fy8PWgeEkCnxtUZ3rmRVbqo7U/Tmv6VopFYlQ5NJEqVYxlZOew+lmhPFrmJ\n4+DJFDKyz1dH1QrwpXmIP4PD6jmULvypH1xF2yJUiWkiUaqcOZuSyerdJ1ix6zg/7Y4nKT0LsIbD\naFKjKleEBHBN69rn2y9qBRBc1dvNUauKTBOJUuXAoYQUVuw6zsqdx9l48BTZOYaQQF9u6FCPHi1C\nuLJOAI1rVtXGbuUWLk0kIjII+A/gCXxgjHkp3/YmwGwgBDgFjDHGHBGRa4A3HHZtDYw0xiwSkY+A\n3sBZ27bxxphoV34OpS63nBxDTOxZVuw8xsqdJ9h9PBGAK+sEcG/vK+jfpg4dGlbTailVJrgskYiI\nJ/A2MAA4AmwSkcXGmJ0Ou70GfGKM+VhE+gIvAmONMauBcNt5agB7geUOx00xxix0VexKuUNaZja/\n7jvJip0n+HHXcU4kpuPpIXRpWp1/DWlL/za1aVLT391hKnUBV5ZIIoG9xpj9ACIyDxgGOCaStsAj\nttergUUFnOdW4DtjTIoLY1XKLRKS0ln1xwlW7jrO2j0nSc3Mxt/Hkz6tatO/bW2uaVWbalW1u60q\n21yZSBoAhx2WjwBd8+2zFbgZq/rrJiBQRGoaYxIc9hkJzMh33AsiMhX4EXjcGJNeqpEr5UL745NY\nsfM4K3cdZ/Nfp8kxUC/Yj1s7N6R/2zp0u6KGtnWocsXdje3/BN4SkfHAWiAWsI+vLCL1gDDgB4dj\nngCOAT7A+8BjwLT8JxaRicBEgMaNG7smeqWckJ1j2HLoNCt2HmfFruPsj08GoG29ICb3bcmAtnVo\nVz9Ix4BS5ZYrE0ks0MhhuaFtnZ0x5ihWiQQRCQBuMcaccdjlb8DXxphMh2PibC/TReRDrGR0AWPM\n+1iJhoiIiGKMEapU8aVkZLHuz5Os3HmcVX+cICE5A29PodsVNRl/dVP6talDg2pV3B2mUqXClYlk\nE9BSRJphJZCRwG2OO4hILeCUMSYHq6QxO985RtnWOx5TzxgTJ9bXtxuB7S6KX6lLciIxjR93nWDl\nzuP8vPck6Vk5BPl5cU3r2vRvU4ferUII8tP7OVTF47JEYozJEpFJWNVSnsBsY8wOEZkGRBljFgN9\ngBdFxGBVbT2Qe7yINMUq0fyU79RzRCQEECAauNdVn0GpizHG8OcJq71jxc7jRB+2CtMNq1fhtq6N\nGdCmDl2a1cDb08PNkSrlWmIudbqvcigiIsJERUW5OwxVQSSlZ/HZ+r+Yu/EQfyVYnQk7NAxmQNs6\n9G9bh1Z1ArW9Q1UIIrLZGBNR1H7ubmxXqtw4nZzBh78e5ONfD3I2NZOrrqjJxF7WzYF1gvzcHZ5S\nbqOJRKkinDiXxsx1+5mz4RApGdkMaFuHB65pQXijau4OTakyQROJUoU4fCqF/63dx4KoI2Rl53BD\nh/rc36cFreoGujs0pcoUTSRK5bP3RCLvrNnHN9FH8RC4tXND7u3dXIcnUaoQmkiUstkee5a3V+/l\n+x3H8PXyYNxVTbm7VzPqBev9HkpdjCYSVeltOniKt1bt5ac98QT6evFAnxbc0b0pNQN83R2aUuWC\nJhJVKRljWPvnSd5etZeNB09Rw9+HKQNbMfaqJnrToFKXSBOJqlRycgzLdx7j7dX72BZ7lrpBfkwd\n0pZRkY2p4qMDJSpVHJpIVKWQlZ3D4q1HeWfNPvaeSKJJzaq8dHMYN3VqoCPtKlVCmkhUhZaWmc2X\nvx/hvZ/2cfhUKq3qBPKfkeEMDquHlw5dolSp0ESiKqTk9CzmbjzE+2v3cyIxnQ6NqjF1SDv6ta6t\n09MqVco0kagK5WxKJh//dpAPfznA6RRrGJMZfwune4uaOv6VUi6iiURVCPGJ6cz6+QCfrf+LpPQs\n+rWuzf3XtKBzk+ruDk2pCk8TiSrXYs+k8v5P+5i36TAZ2TlcH1aPB/q0oG39IHeHplSloYlElUv7\n45N4d80+vt5iTbp5U8cG3NenOVeEBLg5MqUqH00kqlw5cS6N55fuYmnMUbw9PRjdtTETezfXaWuV\nciNNJKrcWLP7BP9YsJXkjCwm9mrOnT2aERKow5go5W6aSFSZl5GVw+vLd/O/tftpXTeQ+bd1o0Vt\nHcpdqbJCE4kq0w4lpDB53ha2Hj7DmG6NeXpwW/y89U50pcoSl97aKyKDRGS3iOwVkccL2N5ERH4U\nkRgRWSMiDR22ZYtItO2x2GF9MxHZYDvnfBHxceVnUO6zNCaOwf9dx/74JN4Z3YnpN4ZpElGqDHJZ\nIhERT+Bt4DqgLTBKRNrm2+014BNjTHtgGvCiw7ZUY0y47THUYf3LwBvGmBbAaeBOV30G5R6pGdk8\n8dU2Hvj8d1rUCWDZgz25Pqyeu8NSShXClSWSSGCvMWa/MSYDmAcMy7dPW2CV7fXqArbnIdatyX2B\nhbZVHwM3llrEyu32HE9k2Ns/M3fjIe7t3ZwF91xFoxpV3R2WUuoiXJlIGgCHHZaP2NY52grcbHt9\nExAoIjVty34iEiUi60UkN1nUBM4YY7Iuck4ARGSi7fio+Pj4kn4W5WLGGOZtPMTQt37mVHIGn0yI\n5PHrWuOtAysqVeYV+V8qIiNEZKGI9BORP0TkhIiMKaX3/yfQW0S2AL2BWCDbtq2JMSYCuA34t4g0\nv5QTG2PeN8ZEGGMiQkJCSilc5Qrn0jKZPHcLj3+1jYgmNVj29570ulJ/Z0qVF8702noeeBL4EogA\nkoAfgc+KOC4WaOSw3NC2zs4YcxRbiUREAoBbjDFnbNtibc/7RWQN0NEWQzUR8bKVSi44pypfth4+\nw+S5W4g9k8qUga24r3dzHZ1XqXLGmXqDZGPMQuAvY8xeY8wxIN2J4zYBLW29rHyAkcBixx1EpJaI\n5MbwBDDbtr66iPjm7gN0B3YaYwxWW8qttmPGAd84EYsqY3JyDDPX7ueWd38lO8ew4J5uPHBNC00i\nSpVDzpRIGojIf4F6tmehkHYJR8aYLBGZBPwAeAKzjTE7RGQaEGWMWQz0AV4UEQOsBR6wHd4G+J+I\n5GAlu5eMMTtt2x4D5onIdGALMMvJz6rKiISkdP75xVZW745nYLs6vHxLe6pV1V7cSpVXYn3Jv8gO\nIuMKWm+M+dglEblARESEiYqKcncYCvh130kemhfNmdRM/jW4DWO6NdF5QpQqo0Rks62t+qKKLJEY\nYz62VU1daVu12xiTWdIAVeWSlZ3Df1ft5c1Vf9Kslj8f3tGFdvWD3R2WUqoUFJlIRKQP1v0aB7Gq\ntRqJyDhjzFrXhqYqirizqfx9bjQbD57i1s4NeW5oO/x9dXQepSoKZ/6bXweuNcbsBhCRK4G5QGdX\nBqYqhpU7j/PPhVvJyMrhjREduKljw6IPUkqVK84kEu/cJAJgjNkjIt4ujElVAOlZ2bz03R98+MtB\n2tUP4s1RHXXSKaUqKGcSSZSIfMD5+0ZGA9pyrQp14GQyk+f+zvbYc4y/uilPXN8aXy8dbFGpisqZ\nRHIfVrfcB23L64B3XBaRKtcWbYnlqa+34e3lwczbIxjQto67Q1JKuZgziWScMWYGMMPVwajyKyUj\ni6nf7GDh5iN0aVqd/4zsSH2d/lapSsGZRHIv8L6rA1Hl186j55g093cOnEzmwb4teLBfS7x0sEWl\nKg1nEkk1Ebk5/0pjzFcuiEeVI8YYPlv/F88v3UW1Kt7MuasrVzev5e6wlFKXmTOJJBgYgnUPSS4D\naCKpxM6mZPLYlzF8v+MYfVqF8NrwDtQK8HV3WEopN3AmkRwyxkxweSSq3Nj81ykenBvN8XNpPHV9\nG+7s0UwHW1SqEnMmkexweRSqXMjJMbz70z5mrNhD/Wp+LLzvasIbVXN3WEopN3NmrK0xItIEaGmM\nWSkiVQAvY0yi68NTZUVyehb3zfmdtXviGdy+Hi/eHEaQn96XqpRybqytu4GJQA2gOdZkUu8B/Vwb\nmiorUjOyufPjTWw6eJoXbgrltsjGOmKvUsrOmT6aD2BNLHUOwBjzJ1DblUGpsiMtM5u7P4li44FT\nzPhbB0Z31WHflVJ5OZNI0o0xGbkLIuKF1WtLVXDpWdnc+9lmftl3kldu7cCw8CLnM1NKVULOJJKf\nRORJoIqIDAC+AL51bVjK3TKycnhgzhbW7I7n/24K49bOOmqvUqpgziSSx4F4YBtwD7AMeNqVQSn3\nysrO4e/ztrBy13GeH9aOUZGN3R2SUqoMc6bXVg4wE5hpmynR1xQ1P68qt7JzDA8v2Mp324/xryFt\nGXtVU3eHpJQq44oskYjIwyISJSK3A3uAP0VkijMnF5FBIrJbRPaKyOMFbG8iIj+KSIyIrBGRhrb1\n4SLym4jssG0b4XDMRyJyQESibY9w5z+uupicHMOUhVv5dutRHr+uNXf2aObukJRS5YAzNyQ+AIwE\nVgFNgTSs+UhevdhBIuIJvA0MAI4Am0RksTFmp8NurwGf2OaF7wu8CIwFUoDbjTF/ikh9YLOI/GCM\nOWM7booxZqGzH1IVLSfH8OTX2/jq91j+MeBK7u3d3N0hKaXKCWfaSM4ZY6KAfcaYU8aYFKxkUpRI\nYK8xZr+t19c8YFi+fdpiJSiA1bnbjTF7bN2MMcYcBU4AIU68pyoGYwxTF29n3qbDPNi3BZP7tXR3\nSEqpcsSZRHKFiCwGmonIYhH5FnCmzqMBcNhh+YhtnaOtQO7IwjcBgSJS03EHEYkEfIB9DqtfsFV5\nvSEiBY4UKCITbVVyUfHx8U6EWzkZY5i2ZCefrT/EPb2v4OEBV7o7JKVUOeNMIhkGvO7w/BpwYym9\n/z+B3iKyBegNxALZuRtFpB7wKXCHrdEf4AmgNdAF6277xwo6sTHmfWNMhDEmIiRECzMFMcbY51Wf\n0L0Zjw9qrTcbKqUumTNtJNcYY54txrljgUYOyw1t6+xs1VY3A4hIAHBLbjuIiAQBS4GnjDHrHY6J\ns71MF5EPsZKRKoYZK/bwv7X7GdutCf8a0kaTiFKqWJwpkQwt5rk3AS1FpJmt2/BIYLHjDiJSS0Ry\nY3gCmG1b7wN8jdUQvzDfMfVsz4JVMtpezPgqtf/++CdvrtrLyC6NeG5oO00iSqlic6ZEUltEHsm/\n0jaPe6GMMVkiMgn4AfAEZhtjdojINCDKGLMY6AO8KCIGWIvVQwzgb0AvoKaIjLetG2+MiQbmiEgI\n1kRb0VhTAVdcxkDMAqjRDBpFlsop311jDQV/S6eG/N9NYTqXiFKqRKSoewtFJA54l7wzJGKMec6F\ncZWqiIgIExUV5e4wLl12Jiz9B/z+MfgEwl0roHabEp3yg3X7mb50F8PC6zPjb+F4ahKp2HJyICcr\n3yMbcjLzLWdZf2+OyzlZtv2y8x6fnf98todPAFRrBNUaQ1BD8PJx96dXJSQim40xEUXt50yJ5Jgx\nZlopxKQuRdpZWDAO9q+GrvfCjq9h7ki4axX41yz6+AJ88ttBpi/dxfVhdXl9eAdNIuWBMZB6Gs4d\nhcQ46/ncUUg8Cudsy6mnC76w52SBvY/K5SYQWM9KKrnJJdj2XK0JBDcEbz83xaZKmzOJZIXLo1B5\nnf4LPv8bJOyFYW9DxzEQNhw+vB6+GAdjvwbPS5tUau7GQ0z9ZgcD2tbhPyM74uXpTPOYcqnsLEg6\nbksQsVZiSLQlCsfXWflv2xLwD4GgelC9CTToCB7e4OFle3hafx+Oyx5eDvvYlp3Zx76fw3KBD09I\nPwdnDsGZw7bnQ3D2MBzeANu/ApOd92ME1HFILrkJp4ltXSPw8b9svwpVMkVWbQGISAegp21xnTFm\nq0ujKmXlqmrrSJRV8sjOgBGfQbNe57fFLICv7obOd8CQN8DJBvIvog7z6Jcx9LkyhPfGdsbXy9NF\nwSu7jJRCEsTR86WLpOMXlhg8faxv8kH1zz/nPgLrW8kjoG75qzbKzrI+81mHJOOYbM4ctqrRHFWt\neT7JBNuSjGPpxi+odGM0BjKSISPJek5PPL+c53WSbZ/c18mQYdtu35ZsJWAvv/MP79zXvgWsK2i/\nwvbxBe8qtvNUOb/s4eX0NcFZpVa1JSIPYs2Q+JVt1Wci8r4x5s0Sxqjy27EIvr4HAuvCbcsgJN/N\nge3/Bid2ws9vQJ12EHl3kaf8JjqWR7+MoUeLWrw7RpNIqUlPgkO/wdkj+aqcbMkj7eyFx/gGW4kg\nqD7Ubnv+daBDsqhas9QvBmWCp5ctCTSCJldfuD0nx0qs9uRy6Hzp5vhO2PPDhSUzv2oOpZnG50sy\n4nnxi7/9gl/Axd/ZqZa8/KwSk0+A9fANsOIJagC+geBd1apazEqzPdIhM9V6TknIu5y7T2aq8+9f\nEPE4n1gcE9DwjyCkVfHP6wRnqrbuAroaY5IBRORl4DdAE0lpMcZKDj8+B426wsjPwb9Wwfv2nQon\n/oDvHoOaLaD5NYWedmlMHI8s2ErXZjV4f2wEft6aRErEGDi6xer8sG2hdfEBQKxqmqB6UL0ZNOlu\nSxIN8pYufAPcGn6Z5uFh+5nVg8ZdL9xuDCTHF1CSOQQJ+2DfashMLvz83v7Whd834PzFP6CO7bW/\ndfHPTQyO+1zw2rbPJVYtO8UYq8NDbuLJSs2XcBwST2aaQ5IqYNlxnZfr26KcSSSCw93mttcV8CuT\nm2RlwNJHYMunEHoLDHvn4o2QHh5wy0yYda3VXnL3aqh54QCLP+w4xt/nbaFT42rMGteFKj6aRIot\n7axVrfj7x3Bsm/Wtr91N0GGElcwD6rjmwqLOE4GA2tajYQE1LcZAyimrJAPnL/4+tgTiUQ7+/kWs\nKsvyVm2Jc4nkQ2CDiHxtW74RmOW6kCqR1NOw4HY4sBZ6PQrXPOlctYZvIIyaCzP7wucj4K6VUKWa\nffOqP44z6fPfCW0QzOzxXfD3debXrPIwxmok3vyx1WMuKxXqhsH1r1kdHxx+3qoMELF6MxazR6Mq\nGWcmtpohImuAHrZVdxhjtrg0qsrg1AGrZ9apA3DjexA+6tKOr94U/vYpfDIUFk6A2xaApxdr98Rz\n76e/07puEB9PiCTQT78pX5KUU7B1Lvz+CcT/YX2r7TACOo2D+h0rZvuFUiXk1FdVY8zvwO8ujqXy\nOLQB5t1mNcbdvgia9ij6mII07Q6DZ8C3D8KKqfza4hHu/iSK5rUD+PTOSIKraBJxSk4OHFxnVV3t\n+tbqMdcgAoa+Ce1u1rYNpYqgdR6X27aFsOh+CG4At30BtVqU7Hydx8GJXbD+bZb9mkWTmoOZc1dX\nqlUtf/Wsl13SCYieY1VfnT4AfsFW1+rO46xecUopp2giuVyMgXWvwarp0PgqGDGn1OpzN7f+B2nr\nf+EZj1kkDRpMdX9NIoXKybZ6+Pz+Eez+zioVNr4a+jwBbYda/fGVUpfEmftI2uabHhcR6WOMWeOy\nqCqarAz49u+w9XNoP8KqMvEqcD6uSxZz5AzjP/qdJv6Pssj3Gap/OwHqrrLueFbnnY2FLZ9ZvePO\nHrbu1+h6r9X2kf9+HaXUJXGmRLJARD4FXgH8bM8RwFWuDKzCSDkF88fCXz9b33p7P1ZqDbbbY88y\n5oMNVPP35v2JvfDKagMf9IW5o+DO5Vq3n50Ff/5gVV3tXWHdRX5FHxgwDVoPLrVkrlRl50wi6Qq8\nDPwKBAJzgO6uDKrCSNhn9cw6cwhunmndmV5K/jh2jrGzNhDg68Xnd3WjfrUqQAvrLtbPboWvJlpD\nrHhUwjG1Th+0el1tmQNJx6whRXo8DB3HWsPxK6VKlTOJJBNIBapglUgOOEx7qwrz129WzyyA278p\neFiIYtp7IpExH2zAx8uDuRO70ahG1fMbm/eFgf8H3z8Gq6dDv6ml9r5lWlYG7F4Kmz+C/Wus4SJa\nDIDOM6DlQGuIDqWUSzjz37UJ+AZrjvRawHsicosxZrhLIyvPYhbANw9Y4//ctqDAO8+La398EqNm\nbkBE+PzubjSpWcAIqV3vscbkWvc6hLSB9hX4V3XyT6vbbvRcSDlpjbfU50noONoaqlwp5XLOJJI7\njTG5Q+fGAcNEZKwLYyq/jIGfXoY1L0KTHjDiU6hao9ROfyghhdtmbiAnxzBvYjeahxTSBiJi3YGd\nsNdKaDWugIadSy0Ot8tMhZ2LrQTy1y/WqKetroNO462xx8rDcBhKVSDOJJITItI437qfXBFMuZaV\nDosnQ8x86DAKbvhvqY6Zc+R0CqNmrictK5u5d3ejZZ3Aix/g5WPd+T6zj1XFNnG1NXhgeWaM1fax\n8hlreJnqzaDfMxA+GgLruDs6pSotZ1pilwJLCngukogMEpHdIrJXRB4vYHsTEflRRGJEZI2INHTY\nNk5E/rQ9xjms7ywi22zn/K9IGRizIuUUfHKjlUT6Pg03vluqSSTubCq3zdxAYlomn93ZlTb1nJyH\nwb8mjJpnjVI77zbbMNXl1Om/4NMbrbv4a7eD2xfD5N+h5yOaRJRyM2fG2goDsF2w+wPewPKijhMR\nT+BtYABwBNgkIovz3ZPyGvCJMeZjEekLvAiMFZEawDNY3YwNsNl27Gms+ePvBjYAy4BBwHdOft7S\nd3IvfD7cuk/hllkQdmupv8W9n27mVHIGn93VldAGwZd2cJ12Vo+xebdZ1Vy3zCpf40Xl5EDULFjx\njBX34BnW3eeVsTeaUmXUpfw3vgE8iTXJ1SdO7B8J7DXG7DfGZADzgGH59mkLrLK9Xu2wfSCwwhhz\nypY8VgCDRKQeEGSMWW+sqR0/wRqN2D0O/gKz+lvDjI/71iVJ5M/jiWw9cpZ/Xnsl4Y2KOeJs6+uh\n/zOw/Uvr7vryImEffDwElv3TmqPi/t+gy52aRJQqYy6lT2QfoJMxJkdE1juxfwPgsMPyEax7Uhxt\nBW4G/gPcBASKSM1Cjm1gexwpYP3lFz3XahOp3hRGL7AatF1gSUwcHgLXt69XshN1f8gak2vVdAhp\nDW1uKJ0AXSEnGza8Bz8+b009O/Qta9768lSSUqoSuZSvdjkO949klNL7/xPoLSJbgN5ALHkn0So2\nEZkoIlEiEhUfH18ap7QYA6tegEX3QuNucNcKlyURYwxLYo7StVlNageWcJYzEasDQIPO1s2Kx7aV\nTpClLX4PzB4EPzwJV/SGB9ZDp7GaRJQqw4pMJCKSKCLngPYick5EEnFueJRYoJHDckPbOjtjzFFj\nzM3GmI7AU7Z1Zy5ybKztdaHndDj3+8aYCGNMREhIiBPhOiEzDb68C9a+Yn1DHvMVVKleOucuwO7j\nieyLT2ZwSUsjubz9rGl8/apZw6gklWKCLansLFg3A97rAQl/Wu06o+aV/55mSlUCRSYSY0ygMSbI\nGONlew40xjgz0cUmoKWINBMRH2AksNhxBxGpJSK5MTwBzLa9/gG4VkSqi0h14FrgB2NMHHBORLrZ\nGv9vx7pZ0vWST8Inw2D7Qutu8aFvuXxKzKW2aq3rQuuW3kkD68Koz63PM3+M1W3Z3Y7vgA/6WXPW\nX3kt3L/BGk5GSyFKlQvOjP7bq6D1xpi1FzvOGJMlIpOwkoInMNsYs0NEpgFRxpjFWO0uL4qIAdYC\nD9iOPSUiz2MlI4BpxphTttf3Ax9hDdnyHZejx1b8HqtnVuIxayyrdje5/C2taq04rm5ei5oBpTy4\nYP2OcOM7sPAOWPIIDHvLPRftrAz4eQasfc2aC+Qy/WyVUqXLmcb2KbbnHsDPtte5F/6LMsYsw+qi\n67huqsPrhcDCQo6dzfkSiuMSiCY1AAAgAElEQVT6KCDUibhLx4G11jd3Tx8YtwQadbksb7sz7hwH\nTiYzsZdr2l8IvdmaSvanl6F2G7h6kmvepzBHt8A3k+D4dgi9Fa57RefbVqqccuY+khsARGRL7utK\nY8tn1jwiNZpbPbOqN71sb70kJg5PD2FQu1Ks1sqv9+NWT64V/4KQVtBygOveK1dmmpW8fvkP+IdY\nbTatB7v+fZVSLnMpvbaMy6Ioq45EWfOp37n8siYRYwxLY+Lo3qKWa2c79PCAm96zblpcOAHid7vu\nvQAOb4L/9bKqszqMtHpkaRJRqtxzpo3kEdvL2g6vMcbMcFlUZcX1r1rPns70LSg922PPcehUCpP6\nlnA+d2f4+MPIuTDzGvh8BNy9qlQHmgQgIwVWvwDr34HAejD6S2jZv3TfQynlNs6USAJtj5kOr4sY\nMbCC8PS+7EkEYEnMUbw9hYFtXVit5ahaI2sO+XOx8MU4yM4svXP/9Su81x1+e8ua1vb+9ZpElKpg\nnGkjeQ5ARIKsRZPo8qgqsdzeWj1a1CK46mVMYo27wg3/gUX3wfdPwOASDqWSnmR15934vjUvy+3f\nWNPcKqUqHGeqtiKAD7GVQkTkLDDBGLPZxbFVStGHzxB7JpVHBlx5+d88/DZrQqxf34TaraHLXcU7\nz/411vAxZw5B5D3WfTeVff54pSowZ7r/zgbuN8asAxCRHliJpb0rA6uslsbE4ePpwYB2bhoavf9z\nVqP7skehZktrmBJnpZ2FFVOt6W5rNIc7vivVKYaVUmWTM20k2blJBMAY8zOQ5bqQKq+cHMOybXH0\nujKEIL/L3zYDWLML3jILarW02ktO7XfuuD9XwDtXWRNPXT0Z7v1Zk4hSlYQzieQnEfmfiPQRkd4i\n8g6wRkQ6iUgnVwdYmWw5fJqjZ9MYUlpjaxWXXxCMmmu9/nwkpJ0rfN/U0/D1fTDnVvAJgDtXwLXT\nwafq5YlVKeV2zlRtdbA9P5NvfUese0v6lmpEldiSmDh8vDzo16a2u0OxRjT+2yfw6U3w5Z3WAIr5\n50L/Yyksedgat6vnP6D3Y+BVysO5KKXKPGd6bV1zOQKp7HKrta5pFUKgu6q18mvWyxq6ZOkj1jzp\n10631icnwHdTrImy6oTCbQugfrh7Y1VKuY0zvbbqAP8H1DfGXCcibYGrjDGzXB5dJRL112mOn0tn\ncPsyNmx6lzutYVR+fRNqtwUvP1g2xWpY7/Mk9HjY5aMgK6XKNmeqtj7C6qX1lG15DzAf0ERSipbE\nHMXP24N+rctAtVZ+g16Ek3tg0f2AgXrhMG6xNbSKUqrSc6axvZYxZgGQA9bw8JTSLIbKkp1jWLbt\nGH1b18bf91JmP75MPL2tId5bDoD+z8JdP2oSUUrZOXPVSrbNo24ARKQbcNalUVUyGw+c4mRSOoPD\nyli1lqOqNWD0F+6OQilVBjmTSB7BmtmwuYj8AoQAt7o0qkpmScxRqnh70rcsVmsppVQRnOm19buI\n9AZaAQLsNsaU4qh+lVtWdg7fbz9Gvza1qeLjWfQBSilVxhTZRiIidYFBwD7gBqypcZu4OrDKYv3+\nUyQkZzCkrPXWUkopJznT2P4VMBFYD1QFjgOfuzKoymTptqP4+3jSp1WIu0NRSqlicSaRBBljhgLB\nxph/GWNexUooRRKRQSKyW0T2isjjBWxvLCKrRWSLiMSIyPW29aNFJNrhkSMi4bZta2znzN1WbhsW\nMm3VWv3b1sHPW6u1lFLlkzON7Z62MbXSRaQjVvLxK+ogEfEE3gYGAEeATSKy2Biz02G3p4EFxph3\nbTc6LgOaGmPmAHNs5wkDFhljoh2OG22MiXIi9jLt130JnE7J1GotpVS55kwiOQa8DsQBMxzWFSUS\n2GuM2Q8gIvOAYYBjIjFAkO11MHC0gPOMAuY58X7lztKYowT6etHrylruDkUppYrNlWNtNQAOOywf\nAbrm2+dZYLmITAb8gYLmYB2BlYAcfSgi2cCXwHRjjClmjG6TkWVVaw1oVwdfL63WUkqVX860kbjS\nKOAjY0xD4HrgUxGxxyQiXYEUY8x2h2NGG2PCgJ62x9iCTiwiE0UkSkSi4uPjXfcJiumXvSc5l5bl\n/iHjlVKqhFyZSGKBRg7LDW3rHN0JLAAwxvyG1fbiWM8zEpjreIAxJtb2nIjVeyyyoDc3xrxvjIkw\nxkSEhJS9HlFLYuII8vOiR4uyF5tSSl0KVyaSTUBLEWkmIj5YSWFxvn0OAf0ARKQNViKJty17AH/D\noX1ERLxEpJbttTcwBNhOOZOelc3ynccY2K4uPl7uLhQqpVTJODOM/O0FrTfGfHKx44wxWSIyCfgB\n8ARmG2N2iMg0IMoYsxj4BzBTRB7Gangf79De0Qs4nNtYb+ML/GBLIp7ASmBmUZ+hrFm35ySJaVkM\n1motpVQF4EyvrdewSgWCVUJYgHXRv2giATDGLMPq0uu4bqrD651A90KOXQN0y7cuGejsRMxl2pKY\no1Sr6k33FtpbSylV/jmTSGKNMQ8CiEh/4DFjTIprw6q40jKzWbHzODd0qI+3p1ZrKaXKP2euZN4i\n0tE2cKMfsEJEWrs4rgrrpz3xJGdka7WWUqrCcKZE8hhWO0QWVlfbo1izJvZyXVgV15KYOGr4+3DV\nFTXdHYpSSpUKZ25IXAosdVxnq+JSlyg1I5sfdx3nxo4N8NJqLaVUBeFMr61HCtk0o5D1qhCrd58g\nJSObIWFaraWUqjic+Vo8BQgs4KEu0dKYOGoF+NBVq7WUUhWIM20kccaY51weSQWXkpHFj38cZ3jn\nRnh6iLvDUUqpUuNMIrlCRBYBaVgN7b8YY750bVgVz4+7TpCWmaNjaymlKhxnEskwrLvIqwD1gbtE\npJcx5u8ujayCWRoTR+1AXyKa1nB3KEopVaqc6bX1k+OyiMzGibva1XlJ6Vms3n2CUZGNtVpLKVXh\nOFMiQUTqAF1sixuNMaNdF1LF8+Ou46RnabWWUqpiKrLXloj8DdgIDMcaa2uDiNzq6sAqkm+3xlE3\nyI9Ojau7OxSllCp1zpRIngK6GGNOAIhICNaouwtdGVhFcS4tk7V74hl7VRM8tFpLKVUBOXMfiUdu\nErFJcPI4BazceZyM7BwdW0spVWE5UyL5XkR+4PxMhSOA71wXUsWyJCaOBtWq0LFRNXeHopRSLuFM\nr60pInIz0MO26n1jzNeuDatiOJuSybo/47mjezNEtFpLKVUxOdVryxjzFfBV7rKIDAFyb4j41GFW\nQ+Xgh53HyMw2DNaxtZRSFVihiUREpha2DbgX+F/urlgzJqp8lsbE0ahGFdo3DHZ3KEop5TIXK5FM\nBN4oZFu2jr91caeTM/hl70nu6nmFVmsppSq0iyWSeGPM6wVtEJExzpxcRAYB/8EaYuUDY8xL+bY3\nBj4Gqtn2edwYs0xEmgK7gN22XdcbY+61HdMZa2KtKljzwf+9LFat/bDjGFk5Rm9CVEpVeBfrxust\nIg1FpLaIVMm3rcgLt4h4Am8D1wFtgVEi0jbfbk8DC4wxHYGRwDsO2/YZY8Jtj3sd1r8L3A20tD0G\nFRWLOyzdFkfTmlVpVz/I3aEopZRLFXU/yDJgLbBXRM6KyCYR+S9WCaIokcBeY8x+Y0wGMA9rAEhH\nBsi90gZjjS5cKBGpBwQZY9bbSiGfADc6EctllZCUzq/7Ehjcvp5WaymlKrxCq7aMMaGOyyLiAVyB\ndR9JUxG53bapsF5bDYDDDstHgK759nkWWC4ikwF/wHEK32YisgU4BzxtjFlnO+eRfOdsUNhncJfv\ndxwjO8cwpH19d4eilFIu51T3XwBjTA6wF3hBRBKAZlglipL02hoFfGSMeV1ErgI+FZFQIA5obIxJ\nsLWJLBKRdpdyYhGZiNVhgMaNGxczvOJZGhPHFSH+tK6rE0kqpSo+pxOJI2PMe07sFgs0clhuaFvn\n6E5sbRzGmN9ExA+oZRuSJd22frOI7AOutB3fsIhz5sb4PvA+QERExGVrjI9PTGf9/gQmXdNCq7WU\nUpWCK8fM2gS0FJFmIuKD1Zi+ON8+h4B+ACLSBvAD4kUkxNZYj4hcgdWovt8YEwecE5FuYl2lbwe+\nceFnuGTfb48jx8CQDlqtpZSqHIpVInGGMSZLRCYBP2B17Z1tjNkhItOAKGPMYuAfwEwReRiremy8\nMcaISC9gmohkAjnAvcaYU7ZT38/57r/fUcbG/fo2Jo6WtQO4so5WaymlKgeXJRIAY8wyrJ5fjuum\nOrzeCXQv4LgvgQLnhTfGRAGhBW1zt+Pn0th08BQP9bvS3aEopdRlo8PBl6LvtsVhDAxuX9fdoSil\n1GWjiaQULYmJo3XdQFrU1motpVTloYmklMSdTSXqr9M6JIpSqtLRRFJKlsbEATBYb0JUSlUymkhK\nydJtcbSrH0SzWv7uDkUppS4rTSSl4MjpFLYcOqPzsiulKiVNJKVg2TarWmtImFZrKaUqH00kpWBp\nTBztGwbTuGZVd4eilFKXnSaSEjqUkMLWI2d1XnalVKXl0jvbK4Ol23J7a13eRJKZmcmRI0dIS0u7\nrO+rlKp4/Pz8aNiwId7e3sU6XhNJCS2JOUp4o2o0rH55q7WOHDlCYGAgTZs21VGGlVLFZowhISGB\nI0eO0KxZs2KdQ6u2SuDAyWR2HD3nlpsQ09LSqFmzpiYRpVSJiAg1a9YsUe2GJpISyO2tdb2b2kc0\niSilSkNJryWaSErg261H6dykOvWrVXF3KG4TGhpK27ZtCQ8Pp0GDBjz77LPuDkmVMR988AE9e/Yk\nIiJC/z7yOXToEGPHjiUyMpLQ0FBOnjzp7pCKRdtIimnviST+OJbI1CFt3R2K23333Xc0adKE1157\njaSkJHeHo8qQWbNmsX79epYsWUJwcLC7wylT0tLSGDVqFC+88AK9e/cu1zUMWiIppqUxcYi4r1qr\nrMjMzMTX1/eC9cYYpkyZQmhoKGFhYcyfP9++bc2aNQQHBxMeHk7dunV57bXXAFi6dCnt2rUjPDyc\nkJAQPvroowvO26dPH1q1akXbtm3p1q0bR48eBWDz5s307t2bzp07M3DgQOLi4uz7//3vfyc8PJzQ\n0FA2btwIwLPPPmt/X4AhQ4awZs0aAAICAi5439DQUA4ePMimTZto3749aWlpJCcn065dO7Zv337B\n/jNmzCA0NJTQ0FD+/e9/AzBlyhT7Z27QoAHh4eFMnTo1z8/jiiuuYMaMGQBkZ2czZcoUunTpQvv2\n7fnf//4HwOjRowkPD6dGjRo0a9aM8PBw3nvvPdLS0rjjjjsICwujY8eOrF69GoCPPvqIkJAQOnTo\nQIsWLZg7d+4F8X700UdMmjTJvjxp0iT7z3/atGl06dKF0NBQJk6ciDEXzlx98OBB+vbtS/v27enX\nrx+HDh0C4P333+fw4cP06NGDbt26ERMTQ05ODi1btiQ+Ph6AnJwcWrRoQXx8PH369CEqKuqCmL79\n9lu6du1Kx44d6d+/P8ePH79gnxdeeIErr7yS0NBQnnvuOXtsjr/P3N9j/s+YnJzMhAkTiIyMpGPH\njnzzzTf284sIf/zxBwC7du1CRAr928yN3fF9k5KS6NevH506dSIsLMx+7lWrVpGamsqkSZMICwvj\nsccesx87d+5cwsLCCA0NzbM+ICCAhx9+mHbt2tGvXz/7z3Dfvn0MGjSIzp0707NnT3u8l4uWSIpp\n6bajdGlSg7rBfu4Ohee+3cHOo+dK9Zxt6wfxzA3titwvMTGRwMALh83/6quviI6OZuvWrZw8eZIu\nXbrQq1cv6tWrR3Z2Nr1792bx4sV5qjqmTp3Kxx9/TERERJ6LWn5z5syhc+fODB06lKioKK677jom\nT57MN998Q0hICPPnz+epp55i9uzZAKSkpBAdHc3atWuZMGFCgRd+Z3Xp0oWhQ4fy9NNPk5qaypgx\nYwgNzTvP2ubNm/nwww/ZsGEDxhi6du1K7969efXVVwEriQUEBPDPf/4TsBJrz549WbJkCZs2beKe\ne+7hkUceYdasWQQHB7Np0ybS09Pp3r071157LXPmzAFg/PjxDBkyhFtvvRWA119/HRFh27Zt/PHH\nH1x77bXs2bMHgBEjRvDWW2/xxRdfMHfuXEaNGuX0Z540aRJTp1rz0Y0dO5YlS5Zwww035Nln8uTJ\njBs3jnHjxjF79mwefPBBFi1axIkTJ7j++ut55plnWLVqFbfffjvR0dGMGTOGOXPm8NBDD7Fy5Uo6\ndOhASEgIHh4eBSaqHj16sH79ekSEDz74gFdeeYXXX3/dvv2nn35i1qxZbNmyBT8/P/r06UP37t3p\n37+/U5/xhRdeoG/fvsyePZszZ84QGRlpPzYyMpLZs2fzyiuvMHv2bLp27er0zw6srrVff/01QUFB\nnDx5km7dujF06FDi4+OJjY1l+/btVK9enWuvvZZFixYRGRnJY489xubNm/Osv/HGG0lOTiYiIoI3\n3niDadOm8dxzz/HWW28xceJE3nvvPVq2bMmGDRu4//77WbVq1SXFWRKaSIphz/FE9hxPYtqwoi+0\nFVl2djaJiYn4+184UOXPP//MqFGj8PT0pE6dOvTu3ZtNmzYxdOhQUlNT8fO7MAF7enqSmJhY5PuO\nHj2a9PR0goKC6N+/P7t372b79u0MGDDAHle9eudLirkXzV69enHu3DnOnDkDwBtvvMFnn30GwIED\nB+wX9tTUVMLDwzHG0Lt3b3uJItfUqVPp0qULfn5+/Pe//y3ws9900032n8vNN9/MunXr6NixY6Gf\nad26dYSHh7N3717eeustAJYvX05MTAwLFy4E4OzZs/z555+FdtH8+eefmTx5MgCtW7emSZMm9kQy\nf/581q5dy8GDB/nyywInH2X+/Pn8/PPPAMTGxhIREQHA6tWreeWVV0hJSeHUqVO0a9fugkTy22+/\n8dVXXwFWsnn00UcBq2Q6duxYAPr27UtCQgLnzp1jwoQJDBs2jIceeojZs2dzxx13ANCwYUO2bNlC\nly5d8pz/yJEjjBgxgri4ODIyMvL8DObPn8+iRYsYPny4vfps5MiRrF271ulEsnz5chYvXmwvpaal\npdlLVV26dGHLli2kpaURHR1t/7kUZPTo0VSpYrWZpqam2n8GTz75JGvXrsXDw4PY2FiOHz+OMYaB\nAwcSEhJiP3bt2rWICH369Llg/Y033oiHhwcjRowAYMyYMdx8880kJSXx66+/Mnz4cHsc6enpTn3u\n0qKJpBiW2Kq1BoWWjZkQnSk5uML+/fu58spLn1b46NGj1K9/4bhkr7/+OmPHjsXPz4+EhIRC/2Hn\nzJlDREQETz/9NP/+97+54YYbaNeuHb/99luB++eve85dfvjhh+3JY8iQIfbtVapUITo6mqysLPr3\n78/KlSvzHJ+QkEBSUhKZmZmkpaUVmEgvVW6J5OTJk3Tu3JmRI0dijOHNN99k4MCBJT5/bonkzz//\nZMiQIezevbvQfQB7iTAtLY3777+fqKgoGjVqxLPPPntJ3USDgoIKXN+oUSPq1KnDqlWr2Lhxo72U\n9eSTTzJu3DjefvttTp8+zdChQwGrxPPII48wdOhQ1qxZk6ckO2LECDp37kxMTIzTceVnjOHLL7+k\nVatWedZv2LABgEGDBjF58mSuu+469u/fX+h5cv824XzV1pw5c4iPj2fz5s14e3vTtGlT0tLSCv3Z\nXAoRIScnh2rVqhEdHV3i8xWXS9tIRGSQiOwWkb0i8ngB2xuLyGoR2SIiMSJyvW39ABHZLCLbbM99\nHY5ZYztntO1R25WfIT9jDEtjjtK1WQ1qB7q/WsudFixYwFVXXVXgtp49ezJ//nyys7OJj49n7dq1\nREZGkp2dzVdffUX37t0vOKZBgwbUq1ePqKgo+7eui8mtKmjVqhXx8fH2RJKZmcmOHTvs++W2z/z8\n888EBwc73ejr5eVFcHAwGRkZedbfc889PP/884wePTpP/bXjZ1+0aBEpKSkkJyfz9ddf07NnT6fe\ns2rVqqSmppKens7AgQN59913yczMBGDPnj0kJycXemzPnj3tF+Q9e/Zw6NChCy6MgYGBJCQkOBUL\nYE8atWrVIikpyV46yu/qq69m3rx5gHXhzP28Xbt2tce0Zs0aatWqZb+A3nXXXYwZM4bhw4fj6ekJ\nWCWpDRs2sHXrVqZNm2Y//9mzZ2nQoAEAH3/88QXv36tXL5YuXcrZs2fJyMhg/vz59OnTx+nPOXDg\nQN588017tdqWLVvybB87diy//vorY8aMcfqcjrHXrl0bb29vVq9ezV9//QVA586dWbVqFSdPniQ7\nO5u5c+fSu3dvIiMj+emnny5YD1Z7Uu7v4PPPP6dHjx4EBQXRrFkzvvjiC8C6Rm3duvWS4ywJl5VI\nRMQTeBsYABwBNonIYmPMTofdngYWGGPeFZG2wDKgKXASuMEYc1REQoEfgAYOx402xkThBn8cS2Rf\nfDJ3dC/eHaAVxbvvvsvTTz9NkyZN7NUh8fHxZGdn06lTJ2666SZ+++03OnTogIjwyiuvULduXW67\n7TZatmzJLbfckud86enpjBs3jg8++KDAxm5HudUHVapU4fPPP8fHx4eFCxfy4IMPcvbsWbKysnjo\noYdo184qqfn5+dGxY0cyMzPt7SYXk5qaSo8ePcjMzKRp06YMHDiQxx+3vgd98skneHt7c9ttt5Gd\nnc3VV1/NqlWr6NvX/l2HTp06MX78eCIjIwHrgnmxai04X7WVlpbGI488QnBwMHfddRcHDx6kU6dO\nGGMICQlh0aJFhZ7j/vvv57777iMsLAwvLy8++ugje0eI3Gqr9PT0PG0LRalWrRp33303oaGh1K1b\n94Iqp1xvvvkmd9xxB6+++iohISF8+OGHADz//POMHz+e9u3bExAQkCcJDB06lDvuuMNerXUxzz77\nLMOHD6d69er07duXAwcO5NnevHlzpkyZQvfu3RERRowYYf+d5P4+warCHD58OL6+vuzfv5/ly5cz\naNAg/vWvf/HQQw/Rvn17cnJyaNasGUuWLLGfv3bt2nm+nFyK0aNHc8MNNxAWFkZERAStW7cGoEmT\nJjz77LP06tULT09PBg8ezLBhwwB46aWXuOaaazDG5Fnv7+/Pxo0bmT59OrVr17Z/SZozZw733Xcf\n06dPJzMzk5EjR9KhQ4dixVssxhiXPICrgB8clp8Ansi3z/+Axxz2/7WA8whwCvC1La8BIi4lls6d\nO5vS8ur3f5hmjy8x8YlppXbO4ti5c6db3/+ZZ54xH374odPr3aV3795m06ZN7g5DFWDTpk2mR48e\nbo1h3Lhx5sCBA26N4VL4+/u77NwFXVOAKOPENdaVVVsNgMMOy0fIW6oAeBYYIyJHsEojkws4zy3A\n78YYx9ajD23VWv+SQjpfi8hEEYkSkajcLnIlZYxh6bY4rm5ei1oBF3Z5VUo556WXXuKWW27hxRdf\ndGsct9xyC9WrV3drDBWBmAK62pXKiUVuBQYZY+6yLY8FuhpjJjns84gthtdF5CpgFhBqjMmxbW8H\nLAauNcbss61rYIyJFZFA4EvgM2PMJxeLJSIiwjj27y6u7bFnGfLmz7x4cxijIhuX+HwlsWvXLtq0\naeO298/KykJE7HXbRa1XSpVtBV1TRGSzMabwbmo2riyRxAKNHJYb2tY5uhNYAGCM+Q3wA2oBiEhD\n4Gvg9twkYtsv1vacCHwORLoo/gss3RaHp4cwsF3Z6K3lTl5eXgUmi8LWK6UqLlcmkk1ASxFpJiI+\nwEis0oWjQ0A/ABFpg5VI4kWkGrAUeNwY80vuziLiJSK5icYbGAIU/+6yS2CMYUnMUbq3qEUNf5/L\n8ZZKKVUuuCyRGGOygElYPa52YfXO2iEi00RkqG23fwB3i8hWYC4w3tbAMwloAUzN183XF/hBRGKA\naKwSzkxXfQZH22LPcvhUKkMq+ZAoSimVn0tvSDTGLMNqRHdcN9Xh9U7gghsKjDHTgemFnLZzacbo\nrKUxcXh7arWWUkrlp4M2OsGq1oqjR4taBFct3lSUFZUOI6+Ua6SmpvLEE0/QrVs3wsPDWbZsWdEH\nuYkOkeKE6MNniD2TysMDLn04kMpAh5FXqvTdc8899OjRg2nTphV7LvXLRUskTlgSE4ePpwcD2tZx\ndyhljg4jr8PIgzUScW4s4eHhVKlShYMHD3Lw4EFat27N6NGjadOmDbfeeispKSkA/Pjjj3Ts2JGw\nsDAmTJhgH2iwadOmhIWF0bp1a6699lr7sDDLly/nqquuolOnTgwfPtz+paVp06Y8+uijhIWFERkZ\nyd69e4HCh7YvbKj68ePH5xkCxnHI+YJ+nwcPHkREeO+99+y/rwYNGjB+/PgLfj4X+3u77777iIiI\noF27djzzzDOANfT8mjVrmD17tn2kiNOnTwMQHR1Nt27daN++fZ71hf2tFzZEfmnSRFKEnBzDsm1x\n9LqyFsFVyui3gu8ehw8Hl+7juwuGRiuQM8PIr1y5kilTptgv7rnDyEdHR3Pvvffaj8kdRj46Ovqi\nY23NmTOHHTt2EBISQlRUFJmZmUyePJmFCxeyefNmJkyYwFNPPWXfP3cY+XfeeYcJEyY4+1MtkOMw\n8o8++miRw8ivX7+emTNnsmXLFl599VX7Z3744YeJjo62jyfVs2dPoqOjmT9/vn1EYsdh5Ddt2sTM\nmTM5cOAAc+bMITo6mqFDh+Y559tvv20fRn7u3LmMGzfOPlbWiBEj2Lp1Ky+++KJ9TCZnTZo0iU2b\nNrF9+3ZSU1PzDB3iKDeW6Ohomjdvbl+/e/du7r//fnbt2kVQUBDvvPMOaWlpjB8/nvnz57Nt2zay\nsrJ499137cesXr2aHTt2cPz4cfbt28fJkyeZPn06K1eu5PfffyciIsKecAGCg4PZtm0bkyZN4qGH\nHgLOD20fExPD6NGjefDBBwEKHaq+MIX9PgFatGhhH7bm+++/p1GjRhc7VYFeeOEFoqKiiImJ4aef\nfiImJoaEhAQOHz7MyywE5HwAAAsQSURBVC+/zLZt2wgLC7PPsXL77bfz8ssvExMTk2c9FPy3njtE\n/saNG1m9ejVTpky56JhtxaGJpAhbDp8m7mwaQ9pfOFptZVecYeSBUhlGvlmzZvz1118XDCMfHh7O\n9OnTOXLkiH3/iw0jn/sNet26dfb9c4eR79ChAw8++CA5OTl53n/q1KmsWLGCqKgo+3Dp+T977jDy\nAQEB9mHkLyZ3rK1rrrnGfsFbvnz5/7d3/7FVlXccx98ffqxVrKUgI5mtWMYsg7Xcoqw65gKKiUay\nJdtMVuU3ZqFh/srm5tx0bnGMINM5YSZORKiO4dQtzujGMlBBhdSp/GiVIcKwTgEZPxTjpPrdH+e5\nt7e1ty3cdqft/b4SknsP55z7vc897fc+z9PzfVi5ciWJRIKqqioOHDjAjh07Mp5jw4YNqaKCbZWR\nr6ioYO7cudTU1LR5/OrVq1Ptkd6DXLduHVVVVZSXl7N27drjrjlVUlKSKtI5bdo0NmzYwPbt2ykt\nLU1Vj545cybPPPNM6pjJkyenKgSXl5ezceNGGhoamDhxIolEghUrVqSKH0LzZ1xdXZ0q3vn8889z\n+eWXA1HRxWRNuGSp+rYke42JRIKdO6Pb19r7PPPy8hg1ahT19fXU1tamSua3JdP19tBDDzF+/Hgq\nKyupr6+noaEBM6OkpCRVrDHZPocPH+bQoUOf2N66HdKv9TVr1rBw4UISiQSTJk1qUSK/q/gcSQf+\nvPktPjWgHxd+/v9aZPj4XLIwlpf1MvJeRr4zMrV/e9atW8fQoUOZMWMGq1atoqCggIsuuqjNYbnW\n5+zo/JlK1UPUq0ouFNa6p5nJ7NmzWbRoEU1NTQwfnnn4u63rbdeuXSxevJi6ujqKioqYNWtWViXm\n22pry1Aivyt5j6QdyWGtSWcNoyC/hw5rxcjLyHsZ+c7Ys2dP6rNJlj4vKytj9+7dqfmM2tra1Lfs\nJEkUFBSkVhV89tlnU/sfPXo01duC5s949erVqWsyU2n7TKXqM+no8zz77LPZt29fp6oYt3bkyBEG\nDRpEYWEhe/fu5cknnwRgyJAh5OXlpXouyfYpLCykqKjoE9tbt0P6td5Rifyu4D2SdtTt/g/73v0v\nU8f5sFZrXkbey8h3VllZGUuXLmXOnDmMGTOGmpoa8vPzWb58OZdddhlNTU1MmDChxXzZ5MmTkcTw\n4cNZsGABgwcP5v7776e6ujo1KX/rrbemesQHDx6koqKCvLy8VK8lU2n745Xp80xOxAOpBHC8iXbc\nuHFUVlYyevToFkOAECWJ+fPnc+zYMUaNGsWyZcuAaD2WefPm8f777zNy5MgW76uta72jEvldojMl\ngnv7vxMtI3/Tn7Za2Y+fsPc+OHZCx3cnLyPfOV5GPl67du2ysWPHdutrjBgxwvbv39+tr9EbZHut\n99Qy8r3eGUNOZlrVCAblecfNOecy6bYy8j1JV5WR70m8jLxzritlU0bev2q7EzJgQNuXTqbtzrm+\ny4e2erFc6E0657pftr9LPJH0Usl7LTyZOOeyYWYcOHCgzZuEO8vHIXqp4uJiGhsb6ar16J1zuSs/\nP5/i4uITPt4TSS81cOBASktL4w7DOed8aMs551x2PJE455zLiicS55xzWcmJGxIl7Qf+1eGObTsN\neKcLw+ntvD2aeVu05O3RUl9ojxFmNqyjnXIikWRD0gudubMzV3h7NPO2aMnbo6Vcag8f2nLOOZcV\nTyTOOeey4omkY/fEHUAP4+3RzNuiJW+PlnKmPXyOxDnnXFa8R+Kccy4rnkjaIeliSdslvSbphrjj\niYukEknrJDVIqpd0Tdwx9QSS+kt6SVIXr1va+0gaLOlhSa9KekXSeXHHFBdJ14Wfk22SVkk68WqI\nvYQnkgwk9QeWApcAY4BqSWPijSo2TcB3zWwMcC4wP4fbIt01wCtxB9FD3An8xcxGA+PI0XaRdDpw\nNXCOmX0B6A98K96oup8nksy+CLxmZq+b2YfA74GvxRxTLMzsLTN7MTx+l+iXxOnxRhUvScXApcC9\ncccSN0mFwFeAZQBm9qGZHYo3qlgNAE6SNAA4Gfh3zPF0O08kmZ0OvJH2vJEc/+UJIOlMoBLYFG8k\nsfsV8H3g47gD6QFKgf3A8jDUd6+kQXEHFQczexNYDOwB3gIOm9maeKPqfp5IXKdJOgV4BLjWzI7E\nHU9cJE0F9pnZP+KOpYcYAIwH7jazSuAokJNzipKKiEYuSoHPAIMkTYs3qu7niSSzN4GStOfFYVtO\nkjSQKIk8aGaPxh1PzCYCX5W0m2jI8wJJD8QbUqwagUYzS/ZSHyZKLLloCrDLzPab2THgUeBLMcfU\n7TyRZFYHfE5SqaRPEU2YPRZzTLGQJKLx71fM7Pa444mbmf3QzIrN7Eyi62KtmfX5b52ZmNnbwBuS\nysKmC4GGGEOK0x7gXEknh5+bC8mBPzzwFRIzMLMmSd8B/kr0lxf3mVl9zGHFZSIwHdgq6eWw7UYz\neyLGmFzPchXwYPjS9TowO+Z4YmFmmyQ9DLxI9NeOL5EDd7j7ne3OOeey4kNbzjnnsuKJxDnnXFY8\nkTjnnMuKJxLnnHNZ8UTinHMuK55IXJ8kqSpULN4cqtHeE+7M71EkXSlpvaQXJN0SdzzOnQi/j8T1\nVfnAdDNrBJBUQ1RgscdUYpU0l6ia8lQzOxx3PM6dKO+RuD7JzJ5OJpHw/G7gLEmflTRJ0mFJL4d/\nbyZ7A5ISkjZK2iLpj5KKJA2QVCdpUtjnF5J+Hh7fHP5vW+j1qHUsks6UtDac8++Szgj/9W2iMjwb\nwmtWSOonaYekYeHYfmE9nGGSnpJ0Ttg+S9KS8HiYpEdCHHWSJobtt0j6Xlocj6e9h/fStq9Prqki\naUh4nc1hLZ6nuuLzcH2bJxLXZ0m6Pi1ZvAyMJFpbBmC9mSXMLAHckXbYSuAHZlYBbAV+YmZNwCzg\nbklTgIuBn4b9l5jZhLD2xEnA1DZCuQtYEc75IPDrsP3TwHNmVg7cCKw0s4+BB4Arwj5TgM1mtp+o\n0vAnEhXRWiB3mNkE4BscR2l7SZcChWmbrgC2mdm4tBica5cnEtdnmdltyWQREsaW9vYP62oMNrOn\nw6YVROtsEMrj1AKPA3PCGjUAkyVtkrQVuAAY28apzwN+Fx7XAl9OvmR4jpmtBYZKOhW4D5gR9pkD\nLA+PG4lK+Lc2BVgSkuVjwKlp80HXpSXS81u9XwE/Ahakbf4IKGjjNZzLyOdIXE4Iv6ATRMUESzrY\nPZNy4BBRT4KwhOpviFbDeyMMjx3PsqptluIP59or6QKiBdaSPYMFwApJ84EimouI9gPONbMP0s8T\nRtnuMLPF4XnrJYGrgaeAt9O21QKXSHobOEy0poZz7fIeieuTwhxCZXjcH/gl0VKwOzMdEya8D0pK\nfnOfDjwdzvF1YAhRD+UuSYNpThrvhB7ANzOc+jmaJ/mvANaHx5vCc8LcxTtp67zcSzTE9Qcz+yjE\n96qZVYVhp5vTzr+GqGhi8r0nMr3HNP2Aa4FFrba/R1RscDo+tOU6yROJ66vqgdslvQjsJBpGurIT\nx80EbpO0hagH8zNJpwELgSvN7J/AEuDOsJzsb4FtRFWi6zKc8ypgdjjndKK13gFuAiaG7QvCayc9\nBpxC87BWe64GzgmT+Q3AvE4ccxLwSBtL4l4PbDGzv3XiHM4BXv3XuR4p/HXWHWZ2foc7OxcznyNx\nroeRdANQgw8tuV7CeyTOOeey4nMkzjnnsuKJxDnnXFY8kTjnnMuKJxLnnHNZ8UTinHMuK55InHPO\nZeV/7WAn8OnjyVAAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"HAe56AwcvF_7","colab_type":"code","colab":{}},"source":["#!cp nlp.hfd5 ./drive/'My Drive'/nlp_bd.hfd5"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uJ0A-HfckUu_","colab_type":"code","colab":{}},"source":["def create_model3(params):\n","    input_layer = Input(shape=(maxlen, ), name='input')\n","\n","    input_dim = embedding_matrix.shape[0]\n","    output_dim = embedding_matrix.shape[1]\n","    \n","    x = Embedding(\n","        input_dim=input_dim,\n","        output_dim=output_dim,\n","        weights=[embedding_matrix],\n","        trainable=False,\n","        name='embedding'\n","    )(input_layer)\n","\n","    # 2. dropout\n","    x = SpatialDropout1D(rate=0.2)(x)\n","\n","    # 3. bidirectional lstm & gru\n","    x = Bidirectional(\n","        layer=CuDNNLSTM(128, return_sequences=True),\n","        name='bidirectional_lstm'\n","    )(x)\n","    # (optional), get hidden states\n","    x = Bidirectional(\n","        layer=CuDNNGRU(128, return_sequences=True),\n","        name='bidirectional_gru'\n","    )(x)\n","    # 4. concat global_max_pooling1d and attention\n","    max_pool = GlobalMaxPool1D(name='global_max_pooling1d')(x)\n","    atten = Attention(step_dim=maxlen, name='attention')(x)\n","    x = Concatenate(axis=-1)([max_pool, atten])\n","\n","    # 5. dense\n","    x = Dense(units=128, activation='relu', name='dense_1')(x)\n","    x = Dropout(rate=0.15)(x)\n","    x = Dense(units=16, activation='relu', name='dense_2')(x)\n","    # 6. output (sigmoid)\n","    output_layer = Dense(units=1, activation='sigmoid', name='output')(x)\n","    model = Model(inputs=input_layer, outputs=output_layer)\n","    # compile model\n","    model.compile(loss='binary_crossentropy', optimizer='adam')\n","    return model\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"A8PE3v0QvCT-","colab_type":"code","outputId":"8dbd2850-09fe-4e7d-aaf1-abfcf11ba580","executionInfo":{"status":"error","timestamp":1560849722351,"user_tz":-180,"elapsed":1221,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}},"colab":{"base_uri":"https://localhost:8080/","height":351}},"source":["modfel = create_model3(params)\n","\n","сheckpoint = ModelCheckpoint('nlp.hfd5', monitor='val_acc', save_best_only=True, verbose=0)\n","\n","history = model.fit(train_X, \n","                    train_y, \n","                    epochs=10,\n","                    batch_size=128,\n","                    callbacks = [сheckpoint],\n","                    validation_split=0.1,\n","                    verbose=1)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-1b39ccc59b0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodfel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mсheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nlp.hfd5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m history = model.fit(train_X, \n","\u001b[0;32m<ipython-input-16-b7048085115c>\u001b[0m in \u001b[0;36mcreate_model3\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# 4. concat global_max_pooling1d and attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mmax_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGlobalMaxPool1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'global_max_pooling1d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0matten\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'attention'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matten\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'Attention' is not defined"]}]}]}